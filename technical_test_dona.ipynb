{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e754120",
   "metadata": {},
   "source": [
    "# **TECHNICAL DS TEST: Jérémie DONA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4de88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "848f7f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremiedona/Documents/venv/dl/lib/python3.9/site-packages/statsmodels/compat/pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (confusion_matrix, recall_score, precision_score, accuracy_score)\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "## Train-Test Split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c61b5d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4afe5fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['INDEX', 'TARGET_FLAG', 'TARGET_AMT', 'KIDSDRIV', 'AGE', 'HOMEKIDS',\n",
      "       'YOJ', 'INCOME', 'PARENT1', 'HOME_VAL', 'MSTATUS', 'SEX', 'EDUCATION',\n",
      "       'JOB', 'TRAVTIME', 'CAR_USE', 'BLUEBOOK', 'TIF', 'CAR_TYPE', 'RED_CAR',\n",
      "       'OLDCLAIM', 'CLM_FREQ', 'REVOKED', 'MVR_PTS', 'CAR_AGE', 'URBANICITY'],\n",
      "      dtype='object')\n",
      "(8161, 26)\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"/Users/jeremiedona/Documents/Descartes/data-scientist-technical-test/data/auto-insurance-fall-2017/train_auto.csv\")\n",
    "print(train_set.columns)\n",
    "print(train_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19148ec",
   "metadata": {},
   "source": [
    "since there is no \"target_flag\" value in the other file, we will only use this one and split it accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87d7bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>TARGET_FLAG</th>\n",
       "      <th>KIDSDRIV</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HOMEKIDS</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>PARENT1</th>\n",
       "      <th>HOME_VAL</th>\n",
       "      <th>MSTATUS</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>JOB</th>\n",
       "      <th>TRAVTIME</th>\n",
       "      <th>CAR_USE</th>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <th>TIF</th>\n",
       "      <th>CAR_TYPE</th>\n",
       "      <th>RED_CAR</th>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <th>CLM_FREQ</th>\n",
       "      <th>REVOKED</th>\n",
       "      <th>MVR_PTS</th>\n",
       "      <th>CAR_AGE</th>\n",
       "      <th>URBANICITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>$67,349</td>\n",
       "      <td>No</td>\n",
       "      <td>$0</td>\n",
       "      <td>z_No</td>\n",
       "      <td>M</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Professional</td>\n",
       "      <td>14</td>\n",
       "      <td>Private</td>\n",
       "      <td>$14,230</td>\n",
       "      <td>11</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>yes</td>\n",
       "      <td>$4,461</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>$91,449</td>\n",
       "      <td>No</td>\n",
       "      <td>$257,252</td>\n",
       "      <td>z_No</td>\n",
       "      <td>M</td>\n",
       "      <td>z_High School</td>\n",
       "      <td>z_Blue Collar</td>\n",
       "      <td>22</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>$14,940</td>\n",
       "      <td>1</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>yes</td>\n",
       "      <td>$0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>$16,039</td>\n",
       "      <td>No</td>\n",
       "      <td>$124,191</td>\n",
       "      <td>Yes</td>\n",
       "      <td>z_F</td>\n",
       "      <td>z_High School</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>5</td>\n",
       "      <td>Private</td>\n",
       "      <td>$4,010</td>\n",
       "      <td>4</td>\n",
       "      <td>z_SUV</td>\n",
       "      <td>no</td>\n",
       "      <td>$38,690</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>$306,251</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M</td>\n",
       "      <td>&lt;High School</td>\n",
       "      <td>z_Blue Collar</td>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>$15,440</td>\n",
       "      <td>7</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>yes</td>\n",
       "      <td>$0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$114,986</td>\n",
       "      <td>No</td>\n",
       "      <td>$243,925</td>\n",
       "      <td>Yes</td>\n",
       "      <td>z_F</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>36</td>\n",
       "      <td>Private</td>\n",
       "      <td>$18,000</td>\n",
       "      <td>1</td>\n",
       "      <td>z_SUV</td>\n",
       "      <td>no</td>\n",
       "      <td>$19,217</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Highly Urban/ Urban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDEX  TARGET_FLAG  KIDSDRIV   AGE  HOMEKIDS   YOJ    INCOME PARENT1  \\\n",
       "0      1            0         0  60.0         0  11.0   $67,349      No   \n",
       "1      2            0         0  43.0         0  11.0   $91,449      No   \n",
       "2      4            0         0  35.0         1  10.0   $16,039      No   \n",
       "3      5            0         0  51.0         0  14.0       NaN      No   \n",
       "4      6            0         0  50.0         0   NaN  $114,986      No   \n",
       "\n",
       "   HOME_VAL MSTATUS  SEX      EDUCATION            JOB  TRAVTIME     CAR_USE  \\\n",
       "0        $0    z_No    M            PhD   Professional        14     Private   \n",
       "1  $257,252    z_No    M  z_High School  z_Blue Collar        22  Commercial   \n",
       "2  $124,191     Yes  z_F  z_High School       Clerical         5     Private   \n",
       "3  $306,251     Yes    M   <High School  z_Blue Collar        32     Private   \n",
       "4  $243,925     Yes  z_F            PhD         Doctor        36     Private   \n",
       "\n",
       "  BLUEBOOK  TIF CAR_TYPE RED_CAR OLDCLAIM  CLM_FREQ REVOKED  MVR_PTS  CAR_AGE  \\\n",
       "0  $14,230   11  Minivan     yes   $4,461         2      No        3     18.0   \n",
       "1  $14,940    1  Minivan     yes       $0         0      No        0      1.0   \n",
       "2   $4,010    4    z_SUV      no  $38,690         2      No        3     10.0   \n",
       "3  $15,440    7  Minivan     yes       $0         0      No        0      6.0   \n",
       "4  $18,000    1    z_SUV      no  $19,217         2     Yes        3     17.0   \n",
       "\n",
       "            URBANICITY  \n",
       "0  Highly Urban/ Urban  \n",
       "1  Highly Urban/ Urban  \n",
       "2  Highly Urban/ Urban  \n",
       "3  Highly Urban/ Urban  \n",
       "4  Highly Urban/ Urban  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A FIRST VIEW AT THE DATA\n",
    "pd.set_option('display.max_columns', None)\n",
    "train_set.drop(\"TARGET_AMT\", axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f928588",
   "metadata": {},
   "source": [
    "**ELEMENTARY DATA TRANSFORMATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c99286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer as KB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def moneytoflt(x):\n",
    "    \"\"\"\n",
    "        transform money str --> money float or nan\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(str(x)[1:].replace(\",\", \"\"))\n",
    "    except:\n",
    "        # BCSE NANs\n",
    "        return np.nan\n",
    "\n",
    "def inputation(df, colname):\n",
    "    \"\"\"\n",
    "           Inputs data where a nan is present with the median of the variable\n",
    "    \"\"\"\n",
    "    med = np.median(df[colname].loc[1-np.isnan(df[colname])])\n",
    "    train_set[colname].loc[np.isnan(train_set[colname])] = med \n",
    "\n",
    "\n",
    "def normalize(df, colname):\n",
    "    \"\"\"\n",
    "        normalize column as x-mu/sigma to have an Normal range of value\n",
    "    \"\"\"\n",
    "    #df[colname] = (df[colname] - df[colname].mean())/df[colname].std()\n",
    "\n",
    "    #est = KB(n_bins=3, encode='ordinal', strategy='quantile')\n",
    "    #est.fit(df[colname].values.reshape(-1, 1))\n",
    "    est = StandardScaler().fit(df[colname].values.reshape(-1, 1))\n",
    "    df[colname] = est.transform(df[colname].values.reshape(-1, 1))\n",
    "\n",
    "def yestobool(x):\n",
    "    if x.lower()==\"yes\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def modeleval(Y_test, prediction):\n",
    "    tn, fp, fn, tp = confusion_matrix(Y_test, prediction, labels=[0,1]).ravel()\n",
    "    c = tn, fp, fn, tp\n",
    "\n",
    "    recall = recall_score(Y_test, prediction)\n",
    "    precision = precision_score(Y_test, prediction)\n",
    "    accuracy = accuracy_score(Y_test, prediction)\n",
    "    print(f\" tn:{tn}, fp:{fp}, fn:{fn}, tp:{tp} \\n\")\n",
    "    print(f\"precision: {precision}\")\n",
    "    print(f\"recall: {recall}\")\n",
    "    print(f\"accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d7861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE TRANSFORMATION\n",
    "train_set[\"INCOME\"] = train_set[\"INCOME\"].apply(moneytoflt)\n",
    "train_set[\"OLDCLAIM\"] = train_set[\"OLDCLAIM\"].apply(moneytoflt)\n",
    "train_set[\"HOME_VAL\"] = train_set[\"HOME_VAL\"].apply(moneytoflt)\n",
    "train_set[\"BLUEBOOK\"] = train_set[\"BLUEBOOK\"].apply(moneytoflt)\n",
    "\n",
    "train_set[\"PARENT1\"] = train_set[\"PARENT1\"].apply(yestobool)\n",
    "train_set[\"RED_CAR\"] = train_set[\"RED_CAR\"].apply(yestobool)\n",
    "train_set[\"REVOKED\"] = train_set[\"REVOKED\"].apply(yestobool)\n",
    "train_set[\"MSTATUS\"] = train_set[\"MSTATUS\"].apply(yestobool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca76b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of data without na 0.7407180492586692\n"
     ]
    }
   ],
   "source": [
    "# DROP THE NA if not to costly\n",
    "df = train_set.dropna()\n",
    "print(f\"percentage of data without na {df.shape[0]/train_set.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da83672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORM DUMMIES\n",
    "df = pd.concat([df, pd.get_dummies(df[\"CAR_TYPE\"])], axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df[\"SEX\"])],  axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df[\"URBANICITY\"])], axis= 1)\n",
    "df = pd.concat([df, pd.get_dummies(df[\"JOB\"])],  axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df[\"EDUCATION\"])],  axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df[\"CAR_USE\"])],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8420797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP OLD COL\n",
    "df.drop(columns=\"CAR_TYPE\", axis=1, inplace=True)\n",
    "df.drop(columns=\"URBANICITY\", axis=1, inplace=True)\n",
    "df.drop(columns=\"SEX\", axis=1, inplace=True)\n",
    "df.drop(columns=\"JOB\",axis= 1, inplace=True)\n",
    "df.drop(columns=\"EDUCATION\", axis=1, inplace=True)\n",
    "df.drop(columns=\"CAR_USE\", axis=1, inplace=True)\n",
    "df.drop(columns=\"INDEX\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f25971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TARGET_FLAG' 'TARGET_AMT' 'KIDSDRIV' 'AGE' 'HOMEKIDS' 'YOJ' 'INCOME'\n",
      " 'PARENT1' 'HOME_VAL' 'MSTATUS' 'TRAVTIME' 'BLUEBOOK' 'TIF' 'RED_CAR'\n",
      " 'OLDCLAIM' 'CLM_FREQ' 'REVOKED' 'MVR_PTS' 'CAR_AGE' 'Minivan'\n",
      " 'Panel Truck' 'Pickup' 'Sports Car' 'Van' 'z_SUV' 'M' 'z_F'\n",
      " 'Highly Urban/ Urban' 'z_Highly Rural/ Rural' 'Clerical' 'Doctor'\n",
      " 'Home Maker' 'Lawyer' 'Manager' 'Professional' 'Student' 'z_Blue Collar'\n",
      " '<High School' 'Bachelors' 'Masters' 'PhD' 'z_High School' 'Commercial'\n",
      " 'Private']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_FLAG</th>\n",
       "      <th>TARGET_AMT</th>\n",
       "      <th>KIDSDRIV</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HOMEKIDS</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>PARENT1</th>\n",
       "      <th>HOME_VAL</th>\n",
       "      <th>MSTATUS</th>\n",
       "      <th>TRAVTIME</th>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <th>TIF</th>\n",
       "      <th>RED_CAR</th>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <th>CLM_FREQ</th>\n",
       "      <th>REVOKED</th>\n",
       "      <th>MVR_PTS</th>\n",
       "      <th>CAR_AGE</th>\n",
       "      <th>Minivan</th>\n",
       "      <th>Panel Truck</th>\n",
       "      <th>Pickup</th>\n",
       "      <th>Sports Car</th>\n",
       "      <th>Van</th>\n",
       "      <th>z_SUV</th>\n",
       "      <th>M</th>\n",
       "      <th>z_F</th>\n",
       "      <th>Highly Urban/ Urban</th>\n",
       "      <th>z_Highly Rural/ Rural</th>\n",
       "      <th>Clerical</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Home Maker</th>\n",
       "      <th>Lawyer</th>\n",
       "      <th>Manager</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Student</th>\n",
       "      <th>z_Blue Collar</th>\n",
       "      <th>&lt;High School</th>\n",
       "      <th>Bachelors</th>\n",
       "      <th>Masters</th>\n",
       "      <th>PhD</th>\n",
       "      <th>z_High School</th>\n",
       "      <th>Commercial</th>\n",
       "      <th>Private</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>67349.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14230.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4461.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>91449.0</td>\n",
       "      <td>0</td>\n",
       "      <td>257252.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>14940.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16039.0</td>\n",
       "      <td>0</td>\n",
       "      <td>124191.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38690.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2946.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>125301.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>17430.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>62978.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET_FLAG  TARGET_AMT  KIDSDRIV   AGE  HOMEKIDS   YOJ    INCOME  PARENT1  \\\n",
       "0            0         0.0         0  60.0         0  11.0   67349.0        0   \n",
       "1            0         0.0         0  43.0         0  11.0   91449.0        0   \n",
       "2            0         0.0         0  35.0         1  10.0   16039.0        0   \n",
       "5            1      2946.0         0  34.0         1  12.0  125301.0        1   \n",
       "8            1      2501.0         0  34.0         0  10.0   62978.0        0   \n",
       "\n",
       "   HOME_VAL  MSTATUS  TRAVTIME  BLUEBOOK  TIF  RED_CAR  OLDCLAIM  CLM_FREQ  \\\n",
       "0       0.0        0        14   14230.0   11        1    4461.0         2   \n",
       "1  257252.0        0        22   14940.0    1        1       0.0         0   \n",
       "2  124191.0        1         5    4010.0    4        0   38690.0         2   \n",
       "5       0.0        0        46   17430.0    1        0       0.0         0   \n",
       "8       0.0        0        34   11200.0    1        0       0.0         0   \n",
       "\n",
       "   REVOKED  MVR_PTS  CAR_AGE  Minivan  Panel Truck  Pickup  Sports Car  Van  \\\n",
       "0        0        3     18.0        1            0       0           0    0   \n",
       "1        0        0      1.0        1            0       0           0    0   \n",
       "2        0        3     10.0        0            0       0           0    0   \n",
       "5        0        0      7.0        0            0       0           1    0   \n",
       "8        0        0      1.0        0            0       0           0    0   \n",
       "\n",
       "   z_SUV  M  z_F  Highly Urban/ Urban  z_Highly Rural/ Rural  Clerical  \\\n",
       "0      0  1    0                    1                      0         0   \n",
       "1      0  1    0                    1                      0         0   \n",
       "2      1  0    1                    1                      0         1   \n",
       "5      0  0    1                    1                      0         0   \n",
       "8      1  0    1                    1                      0         1   \n",
       "\n",
       "   Doctor  Home Maker  Lawyer  Manager  Professional  Student  z_Blue Collar  \\\n",
       "0       0           0       0        0             1        0              0   \n",
       "1       0           0       0        0             0        0              1   \n",
       "2       0           0       0        0             0        0              0   \n",
       "5       0           0       0        0             0        0              1   \n",
       "8       0           0       0        0             0        0              0   \n",
       "\n",
       "   <High School  Bachelors  Masters  PhD  z_High School  Commercial  Private  \n",
       "0             0          0        0    1              0           0        1  \n",
       "1             0          0        0    0              1           1        0  \n",
       "2             0          0        0    0              1           0        1  \n",
       "5             0          1        0    0              0           1        0  \n",
       "8             0          1        0    0              0           0        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns.values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec31a3a",
   "metadata": {},
   "source": [
    "We begin an elementary data analysis in order to know more about our explanatory variable and their link to the variable to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2a1e644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 49 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h=df.hist(figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6717a8",
   "metadata": {},
   "source": [
    "We first try to identify what could be driver for the variable to be explained: if the ratio is above 1 the amount,we have P(y|x)/ p(y) > 1, i.e P(y|x) > P(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98fa4c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "KIDSDRIV 1.3796363004634384\n",
      "CLM_FREQ 1.5417162274191383\n",
      "REVOKED 1.6337947204064627\n",
      "MVR_PTS 1.6337947204064627\n",
      "\n",
      "\n",
      "MSTATUS 0.8193027064792863\n",
      "RED_CAR 0.8193027064792863\n",
      "\n",
      "\n",
      "Commercial 1.374334471616362\n",
      "<High School 1.2367296115457773\n",
      "z_High School 1.279975551394091\n",
      "Bachelors 0.8717874208962935\n",
      "PhD 0.6515237248403525\n",
      "\n",
      "\n",
      "Highly Urban/ Urban 1.1976296752347237\n",
      "Highly Rural/ Rural 0.27865168539325846\n",
      "\n",
      "\n",
      "z_Blue Collar 1.3140459588116482\n",
      "Student 1.4053661972813314\n",
      "Manager 0.47954738861403995\n",
      "Lawyer 0.7152579797641009\n",
      "Home Maker 1.0369076361160119\n",
      "Doctor 0.5094101123595506\n",
      "Clerical 1.1419043363593762\n",
      "\n",
      "\n",
      "Minivan 0.6100454238198725\n",
      "Sports Car 1.2947969449952266\n",
      "z_SUV 1.122912053363952\n",
      "Panel Truck 0.7152579797641009\n",
      "Pickup 1.2131470277537693\n",
      "\n",
      "\n",
      "M 0.9552932252406012\n",
      "z_F 1.0357494483488376\n"
     ]
    }
   ],
   "source": [
    "## SOME ELEMENTARY VERIFICATIONS\n",
    "prop = df[\"TARGET_FLAG\"].mean()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"KIDSDRIV\",df[df[\"KIDSDRIV\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"CLM_FREQ\", df[df[\"CLM_FREQ\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"REVOKED\", df[df[\"REVOKED\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"MVR_PTS\", df[df[\"REVOKED\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"MSTATUS\", df[df[\"MSTATUS\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"RED_CAR\", df[df[\"MSTATUS\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Commercial\", df[df[\"Commercial\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"<High School\", df[df[\"<High School\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"z_High School\", df[df[\"z_High School\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"Bachelors\", df[df[\"Bachelors\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"PhD\", df[df[\"PhD\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Highly Urban/ Urban\", df[df['Highly Urban/ Urban']>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"Highly Rural/ Rural\", df[df['z_Highly Rural/ Rural']>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"z_Blue Collar\", df[df[\"z_Blue Collar\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"Student\", df[df[\"Student\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"Manager\", df[df[\"Manager\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"Lawyer\", df[df[\"Lawyer\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"Home Maker\", df[df[\"Home Maker\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"Doctor\", df[df[\"Doctor\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"Clerical\", df[df[\"Clerical\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Minivan\", df[df[\"Minivan\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"Sports Car\", df[df[\"Sports Car\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"z_SUV\", df[df[\"z_SUV\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"Panel Truck\", df[df[\"Lawyer\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"Pickup\", df[df[\"Pickup\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"M\", df[df[\"M\"]>=1][\"TARGET_FLAG\"].mean() / prop)\n",
    "print(\"z_F\", df[df[\"z_F\"]>=1][\"TARGET_FLAG\"].mean() / prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0082e",
   "metadata": {},
   "source": [
    "Some variable seem like good predictors (**[highly urban, sportscar, pickup, commerical, kidsdrive, claimfreq, student]**, or on the other hand **[PhD,  manager, lawyer, MINivan, REDCAR,MSTATUS]**) seem like grood predictor of the target_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "095803cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f92fa2335e0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df.groupby(\"YOJ\").mean()[\"TARGET_FLAG\"]/ prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6401087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHITEN MONETARY VARIABELS\n",
    "normalize(df, \"INCOME\")\n",
    "normalize(df, \"HOME_VAL\")\n",
    "normalize(df, \"BLUEBOOK\")\n",
    "normalize(df, \"OLDCLAIM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "035d5f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2650124069478908"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if we are not undersampled\n",
    "df[\"TARGET_FLAG\"].mean()\n",
    "# we are undersampled "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d192c1",
   "metadata": {},
   "source": [
    "The dataset shows an unbalance towards the label 0, i.e. positive values are under-represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d65f1b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_FLAG</th>\n",
       "      <th>TARGET_AMT</th>\n",
       "      <th>KIDSDRIV</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HOMEKIDS</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>PARENT1</th>\n",
       "      <th>HOME_VAL</th>\n",
       "      <th>MSTATUS</th>\n",
       "      <th>TRAVTIME</th>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <th>TIF</th>\n",
       "      <th>RED_CAR</th>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <th>CLM_FREQ</th>\n",
       "      <th>REVOKED</th>\n",
       "      <th>MVR_PTS</th>\n",
       "      <th>CAR_AGE</th>\n",
       "      <th>Minivan</th>\n",
       "      <th>Panel Truck</th>\n",
       "      <th>Pickup</th>\n",
       "      <th>Sports Car</th>\n",
       "      <th>Van</th>\n",
       "      <th>z_SUV</th>\n",
       "      <th>M</th>\n",
       "      <th>z_F</th>\n",
       "      <th>Highly Urban/ Urban</th>\n",
       "      <th>z_Highly Rural/ Rural</th>\n",
       "      <th>Clerical</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Home Maker</th>\n",
       "      <th>Lawyer</th>\n",
       "      <th>Manager</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Student</th>\n",
       "      <th>z_Blue Collar</th>\n",
       "      <th>&lt;High School</th>\n",
       "      <th>Bachelors</th>\n",
       "      <th>Masters</th>\n",
       "      <th>PhD</th>\n",
       "      <th>z_High School</th>\n",
       "      <th>Commercial</th>\n",
       "      <th>Private</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TARGET_FLAG</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.541242</td>\n",
       "      <td>0.086933</td>\n",
       "      <td>-0.115274</td>\n",
       "      <td>0.111866</td>\n",
       "      <td>-0.066429</td>\n",
       "      <td>-0.148034</td>\n",
       "      <td>0.162017</td>\n",
       "      <td>-1.845159e-01</td>\n",
       "      <td>-0.131525</td>\n",
       "      <td>0.051459</td>\n",
       "      <td>-0.111521</td>\n",
       "      <td>-0.078885</td>\n",
       "      <td>-2.516496e-02</td>\n",
       "      <td>0.138721</td>\n",
       "      <td>0.228004</td>\n",
       "      <td>0.142795</td>\n",
       "      <td>0.230171</td>\n",
       "      <td>-0.110253</td>\n",
       "      <td>-0.146526</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>0.057460</td>\n",
       "      <td>0.064783</td>\n",
       "      <td>-0.010080</td>\n",
       "      <td>0.047699</td>\n",
       "      <td>-0.024006</td>\n",
       "      <td>0.024006</td>\n",
       "      <td>0.226721</td>\n",
       "      <td>-0.226721</td>\n",
       "      <td>0.038639</td>\n",
       "      <td>-0.054492</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>-0.060366</td>\n",
       "      <td>-0.120199</td>\n",
       "      <td>-0.042788</td>\n",
       "      <td>0.076003</td>\n",
       "      <td>0.107181</td>\n",
       "      <td>0.061573</td>\n",
       "      <td>-0.048945</td>\n",
       "      <td>-0.099694</td>\n",
       "      <td>-0.056958</td>\n",
       "      <td>0.112601</td>\n",
       "      <td>0.160423</td>\n",
       "      <td>-0.160423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TARGET_AMT</th>\n",
       "      <td>0.541242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039043</td>\n",
       "      <td>-0.056546</td>\n",
       "      <td>0.053780</td>\n",
       "      <td>-0.024286</td>\n",
       "      <td>-0.062690</td>\n",
       "      <td>0.095154</td>\n",
       "      <td>-9.749983e-02</td>\n",
       "      <td>-0.093214</td>\n",
       "      <td>0.024283</td>\n",
       "      <td>-0.015724</td>\n",
       "      <td>-0.043934</td>\n",
       "      <td>-3.449673e-03</td>\n",
       "      <td>0.074603</td>\n",
       "      <td>0.113483</td>\n",
       "      <td>0.061262</td>\n",
       "      <td>0.140949</td>\n",
       "      <td>-0.069613</td>\n",
       "      <td>-0.086467</td>\n",
       "      <td>0.037344</td>\n",
       "      <td>0.020211</td>\n",
       "      <td>0.036666</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>0.015135</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>-0.002727</td>\n",
       "      <td>0.123812</td>\n",
       "      <td>-0.123812</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>-0.035937</td>\n",
       "      <td>-0.003548</td>\n",
       "      <td>-0.031817</td>\n",
       "      <td>-0.074727</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>0.079566</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>-0.013718</td>\n",
       "      <td>-0.057331</td>\n",
       "      <td>-0.026361</td>\n",
       "      <td>0.043025</td>\n",
       "      <td>0.104196</td>\n",
       "      <td>-0.104196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIDSDRIV</th>\n",
       "      <td>0.086933</td>\n",
       "      <td>0.039043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.066429</td>\n",
       "      <td>0.454167</td>\n",
       "      <td>0.051048</td>\n",
       "      <td>-0.031816</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>-1.172042e-02</td>\n",
       "      <td>0.045769</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.011378</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>-3.352508e-02</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.040624</td>\n",
       "      <td>0.037857</td>\n",
       "      <td>0.062978</td>\n",
       "      <td>-0.047095</td>\n",
       "      <td>-0.010432</td>\n",
       "      <td>-0.005659</td>\n",
       "      <td>0.011489</td>\n",
       "      <td>-0.009613</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>0.029240</td>\n",
       "      <td>-0.040837</td>\n",
       "      <td>0.040837</td>\n",
       "      <td>-0.027217</td>\n",
       "      <td>0.027217</td>\n",
       "      <td>0.030236</td>\n",
       "      <td>-0.042424</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>-0.038899</td>\n",
       "      <td>-0.021961</td>\n",
       "      <td>-0.024108</td>\n",
       "      <td>0.022554</td>\n",
       "      <td>0.042854</td>\n",
       "      <td>0.035724</td>\n",
       "      <td>-0.017986</td>\n",
       "      <td>-0.037772</td>\n",
       "      <td>-0.035748</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.009958</td>\n",
       "      <td>-0.009958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>-0.115274</td>\n",
       "      <td>-0.056546</td>\n",
       "      <td>-0.066429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.445086</td>\n",
       "      <td>0.132253</td>\n",
       "      <td>0.183458</td>\n",
       "      <td>-0.316694</td>\n",
       "      <td>2.158415e-01</td>\n",
       "      <td>0.098247</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>0.156458</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>1.698497e-02</td>\n",
       "      <td>-0.026570</td>\n",
       "      <td>-0.030659</td>\n",
       "      <td>-0.035284</td>\n",
       "      <td>-0.078043</td>\n",
       "      <td>0.190253</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>0.020658</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>0.030922</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>-0.026517</td>\n",
       "      <td>0.062553</td>\n",
       "      <td>-0.062553</td>\n",
       "      <td>0.043143</td>\n",
       "      <td>-0.043143</td>\n",
       "      <td>-0.160579</td>\n",
       "      <td>0.119215</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.151418</td>\n",
       "      <td>0.099144</td>\n",
       "      <td>0.045862</td>\n",
       "      <td>-0.126245</td>\n",
       "      <td>-0.057652</td>\n",
       "      <td>-0.128571</td>\n",
       "      <td>-0.002078</td>\n",
       "      <td>0.175363</td>\n",
       "      <td>0.145360</td>\n",
       "      <td>-0.120499</td>\n",
       "      <td>-0.073692</td>\n",
       "      <td>0.073692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOMEKIDS</th>\n",
       "      <td>0.111866</td>\n",
       "      <td>0.053780</td>\n",
       "      <td>0.454167</td>\n",
       "      <td>-0.445086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095758</td>\n",
       "      <td>-0.145551</td>\n",
       "      <td>0.445659</td>\n",
       "      <td>-1.042645e-01</td>\n",
       "      <td>0.048468</td>\n",
       "      <td>-0.013962</td>\n",
       "      <td>-0.092876</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>-6.934824e-02</td>\n",
       "      <td>0.033514</td>\n",
       "      <td>0.034326</td>\n",
       "      <td>0.044586</td>\n",
       "      <td>0.071230</td>\n",
       "      <td>-0.154874</td>\n",
       "      <td>-0.047928</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>0.030861</td>\n",
       "      <td>-0.048140</td>\n",
       "      <td>0.073995</td>\n",
       "      <td>-0.109589</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>-0.053517</td>\n",
       "      <td>0.053517</td>\n",
       "      <td>0.129903</td>\n",
       "      <td>-0.086300</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>-0.107980</td>\n",
       "      <td>-0.088545</td>\n",
       "      <td>-0.070925</td>\n",
       "      <td>0.126687</td>\n",
       "      <td>0.039677</td>\n",
       "      <td>0.130558</td>\n",
       "      <td>-0.036632</td>\n",
       "      <td>-0.135442</td>\n",
       "      <td>-0.090486</td>\n",
       "      <td>0.093916</td>\n",
       "      <td>0.027309</td>\n",
       "      <td>-0.027309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YOJ</th>\n",
       "      <td>-0.066429</td>\n",
       "      <td>-0.024286</td>\n",
       "      <td>0.051048</td>\n",
       "      <td>0.132253</td>\n",
       "      <td>0.095758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298453</td>\n",
       "      <td>-0.046951</td>\n",
       "      <td>2.772885e-01</td>\n",
       "      <td>0.141523</td>\n",
       "      <td>-0.015694</td>\n",
       "      <td>0.135757</td>\n",
       "      <td>0.030362</td>\n",
       "      <td>4.030718e-02</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>-0.034353</td>\n",
       "      <td>-0.004496</td>\n",
       "      <td>-0.037392</td>\n",
       "      <td>0.053479</td>\n",
       "      <td>0.061931</td>\n",
       "      <td>0.024295</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>-0.052785</td>\n",
       "      <td>0.036631</td>\n",
       "      <td>-0.053221</td>\n",
       "      <td>0.066328</td>\n",
       "      <td>-0.066328</td>\n",
       "      <td>0.074142</td>\n",
       "      <td>-0.074142</td>\n",
       "      <td>0.112347</td>\n",
       "      <td>0.033989</td>\n",
       "      <td>-0.332360</td>\n",
       "      <td>0.077372</td>\n",
       "      <td>0.078828</td>\n",
       "      <td>0.083294</td>\n",
       "      <td>-0.333939</td>\n",
       "      <td>0.132597</td>\n",
       "      <td>-0.046294</td>\n",
       "      <td>0.022193</td>\n",
       "      <td>0.065280</td>\n",
       "      <td>0.010370</td>\n",
       "      <td>-0.044608</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>-0.006761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCOME</th>\n",
       "      <td>-0.148034</td>\n",
       "      <td>-0.062690</td>\n",
       "      <td>-0.031816</td>\n",
       "      <td>0.183458</td>\n",
       "      <td>-0.145551</td>\n",
       "      <td>0.298453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.064973</td>\n",
       "      <td>5.817192e-01</td>\n",
       "      <td>-0.024963</td>\n",
       "      <td>-0.045834</td>\n",
       "      <td>0.383451</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>3.111072e-02</td>\n",
       "      <td>-0.040746</td>\n",
       "      <td>-0.061672</td>\n",
       "      <td>-0.016505</td>\n",
       "      <td>-0.077280</td>\n",
       "      <td>0.389749</td>\n",
       "      <td>0.090892</td>\n",
       "      <td>0.103658</td>\n",
       "      <td>-0.076578</td>\n",
       "      <td>-0.076428</td>\n",
       "      <td>0.128565</td>\n",
       "      <td>-0.102503</td>\n",
       "      <td>0.057403</td>\n",
       "      <td>-0.057403</td>\n",
       "      <td>0.201310</td>\n",
       "      <td>-0.201310</td>\n",
       "      <td>-0.248185</td>\n",
       "      <td>0.300671</td>\n",
       "      <td>-0.309750</td>\n",
       "      <td>0.240779</td>\n",
       "      <td>0.260044</td>\n",
       "      <td>0.177764</td>\n",
       "      <td>-0.372543</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>-0.321036</td>\n",
       "      <td>0.116930</td>\n",
       "      <td>0.264049</td>\n",
       "      <td>0.377145</td>\n",
       "      <td>-0.285222</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>0.016378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARENT1</th>\n",
       "      <td>0.162017</td>\n",
       "      <td>0.095154</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>-0.316694</td>\n",
       "      <td>0.445659</td>\n",
       "      <td>-0.046951</td>\n",
       "      <td>-0.064973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.600270e-01</td>\n",
       "      <td>-0.480884</td>\n",
       "      <td>-0.011957</td>\n",
       "      <td>-0.049007</td>\n",
       "      <td>-0.011548</td>\n",
       "      <td>-4.402081e-02</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>0.058332</td>\n",
       "      <td>0.046308</td>\n",
       "      <td>0.078017</td>\n",
       "      <td>-0.058432</td>\n",
       "      <td>-0.014277</td>\n",
       "      <td>-0.016982</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>0.017810</td>\n",
       "      <td>-0.032524</td>\n",
       "      <td>0.033686</td>\n",
       "      <td>-0.069196</td>\n",
       "      <td>0.069196</td>\n",
       "      <td>-0.007313</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.044660</td>\n",
       "      <td>-0.043702</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>-0.049359</td>\n",
       "      <td>-0.033027</td>\n",
       "      <td>-0.012429</td>\n",
       "      <td>0.052551</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>0.034588</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>-0.070126</td>\n",
       "      <td>-0.035619</td>\n",
       "      <td>0.041173</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>-0.017964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOME_VAL</th>\n",
       "      <td>-0.184516</td>\n",
       "      <td>-0.097500</td>\n",
       "      <td>-0.011720</td>\n",
       "      <td>0.215841</td>\n",
       "      <td>-0.104264</td>\n",
       "      <td>0.277288</td>\n",
       "      <td>0.581719</td>\n",
       "      <td>-0.260027</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.462668</td>\n",
       "      <td>-0.029127</td>\n",
       "      <td>0.241906</td>\n",
       "      <td>-0.000740</td>\n",
       "      <td>-4.890107e-07</td>\n",
       "      <td>-0.060764</td>\n",
       "      <td>-0.103029</td>\n",
       "      <td>-0.045871</td>\n",
       "      <td>-0.099512</td>\n",
       "      <td>0.204695</td>\n",
       "      <td>0.053916</td>\n",
       "      <td>0.066080</td>\n",
       "      <td>-0.044822</td>\n",
       "      <td>-0.044854</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>-0.058461</td>\n",
       "      <td>0.038569</td>\n",
       "      <td>-0.038569</td>\n",
       "      <td>0.106081</td>\n",
       "      <td>-0.106081</td>\n",
       "      <td>-0.119596</td>\n",
       "      <td>0.134961</td>\n",
       "      <td>-0.154167</td>\n",
       "      <td>0.146389</td>\n",
       "      <td>0.154237</td>\n",
       "      <td>0.133256</td>\n",
       "      <td>-0.341092</td>\n",
       "      <td>0.035762</td>\n",
       "      <td>-0.197523</td>\n",
       "      <td>0.088453</td>\n",
       "      <td>0.165096</td>\n",
       "      <td>0.180754</td>\n",
       "      <td>-0.165710</td>\n",
       "      <td>-0.024932</td>\n",
       "      <td>0.024932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSTATUS</th>\n",
       "      <td>-0.131525</td>\n",
       "      <td>-0.093214</td>\n",
       "      <td>0.045769</td>\n",
       "      <td>0.098247</td>\n",
       "      <td>0.048468</td>\n",
       "      <td>0.141523</td>\n",
       "      <td>-0.024963</td>\n",
       "      <td>-0.480884</td>\n",
       "      <td>4.626684e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>0.014182</td>\n",
       "      <td>-0.003984</td>\n",
       "      <td>-1.817449e-02</td>\n",
       "      <td>-0.043221</td>\n",
       "      <td>-0.076955</td>\n",
       "      <td>-0.037805</td>\n",
       "      <td>-0.059975</td>\n",
       "      <td>-0.029307</td>\n",
       "      <td>-0.005365</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>-0.010364</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>-0.006287</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>-0.006112</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.028238</td>\n",
       "      <td>-0.039581</td>\n",
       "      <td>-0.008690</td>\n",
       "      <td>-0.001798</td>\n",
       "      <td>-0.001543</td>\n",
       "      <td>-0.011044</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.014543</td>\n",
       "      <td>-0.025578</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>-0.041396</td>\n",
       "      <td>0.029220</td>\n",
       "      <td>-0.007751</td>\n",
       "      <td>0.007751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAVTIME</th>\n",
       "      <td>0.051459</td>\n",
       "      <td>0.024283</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>0.009195</td>\n",
       "      <td>-0.013962</td>\n",
       "      <td>-0.015694</td>\n",
       "      <td>-0.045834</td>\n",
       "      <td>-0.011957</td>\n",
       "      <td>-2.912683e-02</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013343</td>\n",
       "      <td>-0.012107</td>\n",
       "      <td>-2.691268e-03</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>-0.019178</td>\n",
       "      <td>-0.003039</td>\n",
       "      <td>-0.029993</td>\n",
       "      <td>-0.007292</td>\n",
       "      <td>-0.005053</td>\n",
       "      <td>-0.006269</td>\n",
       "      <td>0.014071</td>\n",
       "      <td>-0.007979</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>-0.006324</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>-0.163024</td>\n",
       "      <td>0.163024</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>-0.023214</td>\n",
       "      <td>0.043111</td>\n",
       "      <td>-0.030612</td>\n",
       "      <td>-0.069589</td>\n",
       "      <td>-0.002127</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>0.039381</td>\n",
       "      <td>0.023374</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>-0.034250</td>\n",
       "      <td>-0.026351</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>0.022029</td>\n",
       "      <td>-0.022029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <td>-0.111521</td>\n",
       "      <td>-0.015724</td>\n",
       "      <td>-0.011378</td>\n",
       "      <td>0.156458</td>\n",
       "      <td>-0.092876</td>\n",
       "      <td>0.135757</td>\n",
       "      <td>0.383451</td>\n",
       "      <td>-0.049007</td>\n",
       "      <td>2.419056e-01</td>\n",
       "      <td>0.014182</td>\n",
       "      <td>-0.013343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>-8.335184e-03</td>\n",
       "      <td>-0.037475</td>\n",
       "      <td>-0.058051</td>\n",
       "      <td>-0.021650</td>\n",
       "      <td>-0.065272</td>\n",
       "      <td>0.143979</td>\n",
       "      <td>0.086369</td>\n",
       "      <td>0.416651</td>\n",
       "      <td>-0.132565</td>\n",
       "      <td>-0.139798</td>\n",
       "      <td>0.207122</td>\n",
       "      <td>-0.213939</td>\n",
       "      <td>0.018364</td>\n",
       "      <td>-0.018364</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>-0.082600</td>\n",
       "      <td>-0.107773</td>\n",
       "      <td>0.093231</td>\n",
       "      <td>-0.116117</td>\n",
       "      <td>0.050319</td>\n",
       "      <td>0.127210</td>\n",
       "      <td>0.115670</td>\n",
       "      <td>-0.176101</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>-0.133144</td>\n",
       "      <td>0.073225</td>\n",
       "      <td>0.085644</td>\n",
       "      <td>0.133566</td>\n",
       "      <td>-0.110349</td>\n",
       "      <td>0.144139</td>\n",
       "      <td>-0.144139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIF</th>\n",
       "      <td>-0.078885</td>\n",
       "      <td>-0.043934</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.030362</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>-0.011548</td>\n",
       "      <td>-7.396246e-04</td>\n",
       "      <td>-0.003984</td>\n",
       "      <td>-0.012107</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.823897e-03</td>\n",
       "      <td>-0.018050</td>\n",
       "      <td>-0.024453</td>\n",
       "      <td>-0.031770</td>\n",
       "      <td>-0.039664</td>\n",
       "      <td>0.008438</td>\n",
       "      <td>-0.008954</td>\n",
       "      <td>-0.007040</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>-0.011039</td>\n",
       "      <td>0.024935</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>0.013445</td>\n",
       "      <td>-0.013445</td>\n",
       "      <td>0.029454</td>\n",
       "      <td>-0.014519</td>\n",
       "      <td>-0.030649</td>\n",
       "      <td>-0.009969</td>\n",
       "      <td>0.011357</td>\n",
       "      <td>0.014144</td>\n",
       "      <td>-0.024620</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>-0.008104</td>\n",
       "      <td>0.009939</td>\n",
       "      <td>-0.013269</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>-0.003040</td>\n",
       "      <td>0.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RED_CAR</th>\n",
       "      <td>-0.025165</td>\n",
       "      <td>-0.003450</td>\n",
       "      <td>-0.033525</td>\n",
       "      <td>0.016985</td>\n",
       "      <td>-0.069348</td>\n",
       "      <td>0.040307</td>\n",
       "      <td>0.031111</td>\n",
       "      <td>-0.044021</td>\n",
       "      <td>-4.890107e-07</td>\n",
       "      <td>-0.018174</td>\n",
       "      <td>-0.002691</td>\n",
       "      <td>-0.008335</td>\n",
       "      <td>0.006824</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>0.025571</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>-0.011372</td>\n",
       "      <td>0.190279</td>\n",
       "      <td>0.161497</td>\n",
       "      <td>0.180847</td>\n",
       "      <td>-0.201809</td>\n",
       "      <td>0.163004</td>\n",
       "      <td>-0.372853</td>\n",
       "      <td>0.674664</td>\n",
       "      <td>-0.674664</td>\n",
       "      <td>0.045438</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-0.002359</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>-0.166201</td>\n",
       "      <td>-0.018106</td>\n",
       "      <td>0.036393</td>\n",
       "      <td>0.050645</td>\n",
       "      <td>0.025625</td>\n",
       "      <td>0.032694</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.035214</td>\n",
       "      <td>-0.018213</td>\n",
       "      <td>-0.027121</td>\n",
       "      <td>-0.010892</td>\n",
       "      <td>0.170955</td>\n",
       "      <td>-0.170955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <td>0.138721</td>\n",
       "      <td>0.074603</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>-0.026570</td>\n",
       "      <td>0.033514</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>-0.040746</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>-6.076370e-02</td>\n",
       "      <td>-0.043221</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>-0.037475</td>\n",
       "      <td>-0.018050</td>\n",
       "      <td>9.249951e-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.495052</td>\n",
       "      <td>0.431533</td>\n",
       "      <td>0.274089</td>\n",
       "      <td>-0.017146</td>\n",
       "      <td>-0.032460</td>\n",
       "      <td>-0.007859</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.046909</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>-0.012624</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.152848</td>\n",
       "      <td>-0.152848</td>\n",
       "      <td>0.012909</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>-0.007157</td>\n",
       "      <td>-0.015029</td>\n",
       "      <td>-0.006741</td>\n",
       "      <td>-0.007313</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>-0.007142</td>\n",
       "      <td>-0.012257</td>\n",
       "      <td>-0.024036</td>\n",
       "      <td>0.023063</td>\n",
       "      <td>0.028387</td>\n",
       "      <td>-0.028387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLM_FREQ</th>\n",
       "      <td>0.228004</td>\n",
       "      <td>0.113483</td>\n",
       "      <td>0.040624</td>\n",
       "      <td>-0.030659</td>\n",
       "      <td>0.034326</td>\n",
       "      <td>-0.034353</td>\n",
       "      <td>-0.061672</td>\n",
       "      <td>0.058332</td>\n",
       "      <td>-1.030290e-01</td>\n",
       "      <td>-0.076955</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>-0.058051</td>\n",
       "      <td>-0.024453</td>\n",
       "      <td>2.557078e-02</td>\n",
       "      <td>0.495052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065845</td>\n",
       "      <td>0.399165</td>\n",
       "      <td>-0.019161</td>\n",
       "      <td>-0.072947</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.022603</td>\n",
       "      <td>0.050705</td>\n",
       "      <td>-0.006132</td>\n",
       "      <td>0.012104</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>-0.005441</td>\n",
       "      <td>0.245447</td>\n",
       "      <td>-0.245447</td>\n",
       "      <td>-0.010074</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>-0.028937</td>\n",
       "      <td>-0.019183</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.029584</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.008117</td>\n",
       "      <td>-0.033525</td>\n",
       "      <td>-0.010171</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.071680</td>\n",
       "      <td>-0.071680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REVOKED</th>\n",
       "      <td>0.142795</td>\n",
       "      <td>0.061262</td>\n",
       "      <td>0.037857</td>\n",
       "      <td>-0.035284</td>\n",
       "      <td>0.044586</td>\n",
       "      <td>-0.004496</td>\n",
       "      <td>-0.016505</td>\n",
       "      <td>0.046308</td>\n",
       "      <td>-4.587113e-02</td>\n",
       "      <td>-0.037805</td>\n",
       "      <td>-0.019178</td>\n",
       "      <td>-0.021650</td>\n",
       "      <td>-0.031770</td>\n",
       "      <td>9.319750e-03</td>\n",
       "      <td>0.431533</td>\n",
       "      <td>0.065845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056173</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>-0.016684</td>\n",
       "      <td>-0.012590</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>-0.002258</td>\n",
       "      <td>0.016782</td>\n",
       "      <td>-0.001491</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.088666</td>\n",
       "      <td>-0.088666</td>\n",
       "      <td>-0.001649</td>\n",
       "      <td>-0.032849</td>\n",
       "      <td>-0.031003</td>\n",
       "      <td>0.021336</td>\n",
       "      <td>-0.006207</td>\n",
       "      <td>-0.003038</td>\n",
       "      <td>0.033112</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>-0.013589</td>\n",
       "      <td>-0.011919</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>-0.020762</td>\n",
       "      <td>0.030438</td>\n",
       "      <td>0.016219</td>\n",
       "      <td>-0.016219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MVR_PTS</th>\n",
       "      <td>0.230171</td>\n",
       "      <td>0.140949</td>\n",
       "      <td>0.062978</td>\n",
       "      <td>-0.078043</td>\n",
       "      <td>0.071230</td>\n",
       "      <td>-0.037392</td>\n",
       "      <td>-0.077280</td>\n",
       "      <td>0.078017</td>\n",
       "      <td>-9.951207e-02</td>\n",
       "      <td>-0.059975</td>\n",
       "      <td>-0.003039</td>\n",
       "      <td>-0.065272</td>\n",
       "      <td>-0.039664</td>\n",
       "      <td>1.489312e-03</td>\n",
       "      <td>0.274089</td>\n",
       "      <td>0.399165</td>\n",
       "      <td>0.056173</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029007</td>\n",
       "      <td>-0.056140</td>\n",
       "      <td>-0.011474</td>\n",
       "      <td>0.026152</td>\n",
       "      <td>0.037147</td>\n",
       "      <td>-0.004075</td>\n",
       "      <td>0.015933</td>\n",
       "      <td>-0.019986</td>\n",
       "      <td>0.019986</td>\n",
       "      <td>0.160044</td>\n",
       "      <td>-0.160044</td>\n",
       "      <td>0.017847</td>\n",
       "      <td>-0.021411</td>\n",
       "      <td>-0.017989</td>\n",
       "      <td>-0.003867</td>\n",
       "      <td>-0.057230</td>\n",
       "      <td>0.009098</td>\n",
       "      <td>0.037251</td>\n",
       "      <td>0.020018</td>\n",
       "      <td>0.028533</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>-0.036970</td>\n",
       "      <td>-0.030796</td>\n",
       "      <td>0.023059</td>\n",
       "      <td>0.056993</td>\n",
       "      <td>-0.056993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAR_AGE</th>\n",
       "      <td>-0.110253</td>\n",
       "      <td>-0.069613</td>\n",
       "      <td>-0.047095</td>\n",
       "      <td>0.190253</td>\n",
       "      <td>-0.154874</td>\n",
       "      <td>0.053479</td>\n",
       "      <td>0.389749</td>\n",
       "      <td>-0.058432</td>\n",
       "      <td>2.046951e-01</td>\n",
       "      <td>-0.029307</td>\n",
       "      <td>-0.029993</td>\n",
       "      <td>0.143979</td>\n",
       "      <td>0.008438</td>\n",
       "      <td>-1.137195e-02</td>\n",
       "      <td>-0.017146</td>\n",
       "      <td>-0.019161</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>-0.029007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064603</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>-0.078013</td>\n",
       "      <td>-0.008954</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>-0.005925</td>\n",
       "      <td>-0.026332</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>-0.159600</td>\n",
       "      <td>-0.241556</td>\n",
       "      <td>0.198584</td>\n",
       "      <td>-0.018529</td>\n",
       "      <td>0.389687</td>\n",
       "      <td>0.167005</td>\n",
       "      <td>0.072714</td>\n",
       "      <td>-0.154807</td>\n",
       "      <td>-0.231338</td>\n",
       "      <td>-0.344391</td>\n",
       "      <td>0.107948</td>\n",
       "      <td>0.505387</td>\n",
       "      <td>0.286545</td>\n",
       "      <td>-0.406907</td>\n",
       "      <td>-0.163646</td>\n",
       "      <td>0.163646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minivan</th>\n",
       "      <td>-0.146526</td>\n",
       "      <td>-0.086467</td>\n",
       "      <td>-0.010432</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>-0.047928</td>\n",
       "      <td>0.061931</td>\n",
       "      <td>0.090892</td>\n",
       "      <td>-0.014277</td>\n",
       "      <td>5.391614e-02</td>\n",
       "      <td>-0.005365</td>\n",
       "      <td>-0.007292</td>\n",
       "      <td>0.086369</td>\n",
       "      <td>-0.008954</td>\n",
       "      <td>1.902785e-01</td>\n",
       "      <td>-0.032460</td>\n",
       "      <td>-0.072947</td>\n",
       "      <td>-0.016684</td>\n",
       "      <td>-0.056140</td>\n",
       "      <td>0.064603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.154423</td>\n",
       "      <td>-0.280931</td>\n",
       "      <td>-0.229009</td>\n",
       "      <td>-0.185437</td>\n",
       "      <td>-0.404418</td>\n",
       "      <td>0.264446</td>\n",
       "      <td>-0.264446</td>\n",
       "      <td>0.041014</td>\n",
       "      <td>-0.041014</td>\n",
       "      <td>-0.028475</td>\n",
       "      <td>0.030280</td>\n",
       "      <td>-0.095146</td>\n",
       "      <td>0.100157</td>\n",
       "      <td>0.015149</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>-0.001996</td>\n",
       "      <td>-0.042088</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.072960</td>\n",
       "      <td>0.015475</td>\n",
       "      <td>-0.040388</td>\n",
       "      <td>-0.169632</td>\n",
       "      <td>0.169632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Panel Truck</th>\n",
       "      <td>0.019402</td>\n",
       "      <td>0.037344</td>\n",
       "      <td>-0.005659</td>\n",
       "      <td>0.020658</td>\n",
       "      <td>-0.035769</td>\n",
       "      <td>0.024295</td>\n",
       "      <td>0.103658</td>\n",
       "      <td>-0.016982</td>\n",
       "      <td>6.608049e-02</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>-0.005053</td>\n",
       "      <td>0.416651</td>\n",
       "      <td>-0.007040</td>\n",
       "      <td>1.614969e-01</td>\n",
       "      <td>-0.007859</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>-0.012590</td>\n",
       "      <td>-0.011474</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>-0.154423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.110789</td>\n",
       "      <td>-0.090313</td>\n",
       "      <td>-0.073130</td>\n",
       "      <td>-0.159488</td>\n",
       "      <td>0.248772</td>\n",
       "      <td>-0.248772</td>\n",
       "      <td>0.028774</td>\n",
       "      <td>-0.028774</td>\n",
       "      <td>-0.024925</td>\n",
       "      <td>-0.045648</td>\n",
       "      <td>-0.064942</td>\n",
       "      <td>-0.087127</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.089586</td>\n",
       "      <td>-0.029560</td>\n",
       "      <td>0.018663</td>\n",
       "      <td>-0.024997</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>-0.029733</td>\n",
       "      <td>0.011402</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>0.345772</td>\n",
       "      <td>-0.345772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pickup</th>\n",
       "      <td>0.057460</td>\n",
       "      <td>0.020211</td>\n",
       "      <td>0.011489</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>-0.001889</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>-0.076578</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>-4.482213e-02</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>-0.006269</td>\n",
       "      <td>-0.132565</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>1.808470e-01</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.022603</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>0.026152</td>\n",
       "      <td>-0.078013</td>\n",
       "      <td>-0.280931</td>\n",
       "      <td>-0.110789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.164300</td>\n",
       "      <td>-0.133040</td>\n",
       "      <td>-0.290145</td>\n",
       "      <td>0.243648</td>\n",
       "      <td>-0.243648</td>\n",
       "      <td>-0.011784</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>0.043623</td>\n",
       "      <td>-0.033537</td>\n",
       "      <td>-0.057403</td>\n",
       "      <td>-0.086577</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>-0.008333</td>\n",
       "      <td>0.066796</td>\n",
       "      <td>0.041650</td>\n",
       "      <td>0.066531</td>\n",
       "      <td>-0.011608</td>\n",
       "      <td>-0.079113</td>\n",
       "      <td>-0.038345</td>\n",
       "      <td>0.044994</td>\n",
       "      <td>0.237649</td>\n",
       "      <td>-0.237649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports Car</th>\n",
       "      <td>0.064783</td>\n",
       "      <td>0.036666</td>\n",
       "      <td>-0.009613</td>\n",
       "      <td>0.030922</td>\n",
       "      <td>0.030861</td>\n",
       "      <td>-0.052785</td>\n",
       "      <td>-0.076428</td>\n",
       "      <td>0.017810</td>\n",
       "      <td>-4.485426e-02</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>0.014071</td>\n",
       "      <td>-0.139798</td>\n",
       "      <td>-0.011039</td>\n",
       "      <td>-2.018086e-01</td>\n",
       "      <td>0.046909</td>\n",
       "      <td>0.050705</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.037147</td>\n",
       "      <td>-0.008954</td>\n",
       "      <td>-0.229009</td>\n",
       "      <td>-0.090313</td>\n",
       "      <td>-0.164300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.108451</td>\n",
       "      <td>-0.236520</td>\n",
       "      <td>-0.307661</td>\n",
       "      <td>0.307661</td>\n",
       "      <td>-0.026762</td>\n",
       "      <td>0.026762</td>\n",
       "      <td>-0.003783</td>\n",
       "      <td>-0.010382</td>\n",
       "      <td>0.114890</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>-0.016844</td>\n",
       "      <td>-0.031459</td>\n",
       "      <td>0.022651</td>\n",
       "      <td>-0.043354</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>-0.024361</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>-0.006581</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>-0.114852</td>\n",
       "      <td>0.114852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Van</th>\n",
       "      <td>-0.010080</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>-0.048140</td>\n",
       "      <td>0.036631</td>\n",
       "      <td>0.128565</td>\n",
       "      <td>-0.032524</td>\n",
       "      <td>6.702444e-02</td>\n",
       "      <td>-0.010364</td>\n",
       "      <td>-0.007979</td>\n",
       "      <td>0.207122</td>\n",
       "      <td>0.024935</td>\n",
       "      <td>1.630040e-01</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.006132</td>\n",
       "      <td>-0.002258</td>\n",
       "      <td>-0.004075</td>\n",
       "      <td>0.020620</td>\n",
       "      <td>-0.185437</td>\n",
       "      <td>-0.073130</td>\n",
       "      <td>-0.133040</td>\n",
       "      <td>-0.108451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.191520</td>\n",
       "      <td>0.254399</td>\n",
       "      <td>-0.254399</td>\n",
       "      <td>0.028003</td>\n",
       "      <td>-0.028003</td>\n",
       "      <td>-0.021361</td>\n",
       "      <td>0.036852</td>\n",
       "      <td>-0.069525</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>0.055289</td>\n",
       "      <td>-0.051975</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>-0.016808</td>\n",
       "      <td>0.028881</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.029561</td>\n",
       "      <td>-0.031682</td>\n",
       "      <td>0.114703</td>\n",
       "      <td>-0.114703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_SUV</th>\n",
       "      <td>0.047699</td>\n",
       "      <td>0.015135</td>\n",
       "      <td>0.029240</td>\n",
       "      <td>-0.026517</td>\n",
       "      <td>0.073995</td>\n",
       "      <td>-0.053221</td>\n",
       "      <td>-0.102503</td>\n",
       "      <td>0.033686</td>\n",
       "      <td>-5.846107e-02</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.009715</td>\n",
       "      <td>-0.213939</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>-3.728526e-01</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.012104</td>\n",
       "      <td>0.016782</td>\n",
       "      <td>0.015933</td>\n",
       "      <td>-0.005925</td>\n",
       "      <td>-0.404418</td>\n",
       "      <td>-0.159488</td>\n",
       "      <td>-0.290145</td>\n",
       "      <td>-0.236520</td>\n",
       "      <td>-0.191520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.521692</td>\n",
       "      <td>0.521692</td>\n",
       "      <td>-0.043268</td>\n",
       "      <td>0.043268</td>\n",
       "      <td>0.020495</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.134245</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>-0.053624</td>\n",
       "      <td>-0.066986</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>-0.026071</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>-0.020554</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.002661</td>\n",
       "      <td>0.016846</td>\n",
       "      <td>-0.191115</td>\n",
       "      <td>0.191115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>-0.024006</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>-0.040837</td>\n",
       "      <td>0.062553</td>\n",
       "      <td>-0.109589</td>\n",
       "      <td>0.066328</td>\n",
       "      <td>0.057403</td>\n",
       "      <td>-0.069196</td>\n",
       "      <td>3.856908e-02</td>\n",
       "      <td>-0.006287</td>\n",
       "      <td>-0.006324</td>\n",
       "      <td>0.018364</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>6.746639e-01</td>\n",
       "      <td>-0.012624</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>-0.001491</td>\n",
       "      <td>-0.019986</td>\n",
       "      <td>-0.026332</td>\n",
       "      <td>0.264446</td>\n",
       "      <td>0.248772</td>\n",
       "      <td>0.243648</td>\n",
       "      <td>-0.307661</td>\n",
       "      <td>0.254399</td>\n",
       "      <td>-0.521692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.043460</td>\n",
       "      <td>-0.043460</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>-0.012782</td>\n",
       "      <td>-0.231918</td>\n",
       "      <td>-0.018775</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>0.062124</td>\n",
       "      <td>0.016121</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>-0.021388</td>\n",
       "      <td>-0.034533</td>\n",
       "      <td>-0.007052</td>\n",
       "      <td>0.239076</td>\n",
       "      <td>-0.239076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_F</th>\n",
       "      <td>0.024006</td>\n",
       "      <td>-0.002727</td>\n",
       "      <td>0.040837</td>\n",
       "      <td>-0.062553</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>-0.066328</td>\n",
       "      <td>-0.057403</td>\n",
       "      <td>0.069196</td>\n",
       "      <td>-3.856908e-02</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>-0.018364</td>\n",
       "      <td>-0.008695</td>\n",
       "      <td>-6.746639e-01</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>-0.005441</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.019986</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>-0.264446</td>\n",
       "      <td>-0.248772</td>\n",
       "      <td>-0.243648</td>\n",
       "      <td>0.307661</td>\n",
       "      <td>-0.254399</td>\n",
       "      <td>0.521692</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043460</td>\n",
       "      <td>0.043460</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>0.231918</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>-0.050540</td>\n",
       "      <td>-0.065809</td>\n",
       "      <td>-0.014502</td>\n",
       "      <td>-0.062124</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>-0.031515</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>0.034533</td>\n",
       "      <td>0.007052</td>\n",
       "      <td>-0.239076</td>\n",
       "      <td>0.239076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Highly Urban/ Urban</th>\n",
       "      <td>0.226721</td>\n",
       "      <td>0.123812</td>\n",
       "      <td>-0.027217</td>\n",
       "      <td>0.043143</td>\n",
       "      <td>-0.053517</td>\n",
       "      <td>0.074142</td>\n",
       "      <td>0.201310</td>\n",
       "      <td>-0.007313</td>\n",
       "      <td>1.060812e-01</td>\n",
       "      <td>-0.006112</td>\n",
       "      <td>-0.163024</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.013445</td>\n",
       "      <td>4.543815e-02</td>\n",
       "      <td>0.152848</td>\n",
       "      <td>0.245447</td>\n",
       "      <td>0.088666</td>\n",
       "      <td>0.160044</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.041014</td>\n",
       "      <td>0.028774</td>\n",
       "      <td>-0.011784</td>\n",
       "      <td>-0.026762</td>\n",
       "      <td>0.028003</td>\n",
       "      <td>-0.043268</td>\n",
       "      <td>0.043460</td>\n",
       "      <td>-0.043460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.151239</td>\n",
       "      <td>0.096823</td>\n",
       "      <td>-0.108173</td>\n",
       "      <td>0.114259</td>\n",
       "      <td>0.201318</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>-0.099795</td>\n",
       "      <td>-0.048344</td>\n",
       "      <td>-0.097835</td>\n",
       "      <td>0.036633</td>\n",
       "      <td>0.143069</td>\n",
       "      <td>0.104346</td>\n",
       "      <td>-0.133601</td>\n",
       "      <td>-0.049635</td>\n",
       "      <td>0.049635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_Highly Rural/ Rural</th>\n",
       "      <td>-0.226721</td>\n",
       "      <td>-0.123812</td>\n",
       "      <td>0.027217</td>\n",
       "      <td>-0.043143</td>\n",
       "      <td>0.053517</td>\n",
       "      <td>-0.074142</td>\n",
       "      <td>-0.201310</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>-1.060812e-01</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.163024</td>\n",
       "      <td>-0.082600</td>\n",
       "      <td>-0.013445</td>\n",
       "      <td>-4.543815e-02</td>\n",
       "      <td>-0.152848</td>\n",
       "      <td>-0.245447</td>\n",
       "      <td>-0.088666</td>\n",
       "      <td>-0.160044</td>\n",
       "      <td>-0.159600</td>\n",
       "      <td>-0.041014</td>\n",
       "      <td>-0.028774</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>0.026762</td>\n",
       "      <td>-0.028003</td>\n",
       "      <td>0.043268</td>\n",
       "      <td>-0.043460</td>\n",
       "      <td>0.043460</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151239</td>\n",
       "      <td>-0.096823</td>\n",
       "      <td>0.108173</td>\n",
       "      <td>-0.114259</td>\n",
       "      <td>-0.201318</td>\n",
       "      <td>-0.042100</td>\n",
       "      <td>0.099795</td>\n",
       "      <td>0.048344</td>\n",
       "      <td>0.097835</td>\n",
       "      <td>-0.036633</td>\n",
       "      <td>-0.143069</td>\n",
       "      <td>-0.104346</td>\n",
       "      <td>0.133601</td>\n",
       "      <td>0.049635</td>\n",
       "      <td>-0.049635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clerical</th>\n",
       "      <td>0.038639</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.030236</td>\n",
       "      <td>-0.160579</td>\n",
       "      <td>0.129903</td>\n",
       "      <td>0.112347</td>\n",
       "      <td>-0.248185</td>\n",
       "      <td>0.044660</td>\n",
       "      <td>-1.195959e-01</td>\n",
       "      <td>0.028238</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>-0.107773</td>\n",
       "      <td>0.029454</td>\n",
       "      <td>-2.358606e-03</td>\n",
       "      <td>0.012909</td>\n",
       "      <td>-0.010074</td>\n",
       "      <td>-0.001649</td>\n",
       "      <td>0.017847</td>\n",
       "      <td>-0.241556</td>\n",
       "      <td>-0.028475</td>\n",
       "      <td>-0.024925</td>\n",
       "      <td>0.043623</td>\n",
       "      <td>-0.003783</td>\n",
       "      <td>-0.021361</td>\n",
       "      <td>0.020495</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>-0.151239</td>\n",
       "      <td>0.151239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083880</td>\n",
       "      <td>-0.133778</td>\n",
       "      <td>-0.160098</td>\n",
       "      <td>-0.174408</td>\n",
       "      <td>-0.185677</td>\n",
       "      <td>-0.141588</td>\n",
       "      <td>-0.257733</td>\n",
       "      <td>0.237710</td>\n",
       "      <td>-0.122172</td>\n",
       "      <td>-0.209221</td>\n",
       "      <td>-0.123432</td>\n",
       "      <td>0.171914</td>\n",
       "      <td>-0.148761</td>\n",
       "      <td>0.148761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctor</th>\n",
       "      <td>-0.054492</td>\n",
       "      <td>-0.035937</td>\n",
       "      <td>-0.042424</td>\n",
       "      <td>0.119215</td>\n",
       "      <td>-0.086300</td>\n",
       "      <td>0.033989</td>\n",
       "      <td>0.300671</td>\n",
       "      <td>-0.043702</td>\n",
       "      <td>1.349615e-01</td>\n",
       "      <td>-0.039581</td>\n",
       "      <td>-0.023214</td>\n",
       "      <td>0.093231</td>\n",
       "      <td>-0.014519</td>\n",
       "      <td>2.169577e-03</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>-0.032849</td>\n",
       "      <td>-0.021411</td>\n",
       "      <td>0.198584</td>\n",
       "      <td>0.030280</td>\n",
       "      <td>-0.045648</td>\n",
       "      <td>-0.033537</td>\n",
       "      <td>-0.010382</td>\n",
       "      <td>0.036852</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>-0.012782</td>\n",
       "      <td>0.012782</td>\n",
       "      <td>0.096823</td>\n",
       "      <td>-0.096823</td>\n",
       "      <td>-0.083880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054572</td>\n",
       "      <td>-0.065309</td>\n",
       "      <td>-0.071146</td>\n",
       "      <td>-0.075743</td>\n",
       "      <td>-0.057758</td>\n",
       "      <td>-0.105137</td>\n",
       "      <td>-0.080125</td>\n",
       "      <td>-0.117601</td>\n",
       "      <td>-0.085348</td>\n",
       "      <td>0.679566</td>\n",
       "      <td>-0.123894</td>\n",
       "      <td>-0.132019</td>\n",
       "      <td>0.132019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home Maker</th>\n",
       "      <td>0.006538</td>\n",
       "      <td>-0.003548</td>\n",
       "      <td>-0.002163</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.007094</td>\n",
       "      <td>-0.332360</td>\n",
       "      <td>-0.309750</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>-1.541670e-01</td>\n",
       "      <td>-0.008690</td>\n",
       "      <td>0.043111</td>\n",
       "      <td>-0.116117</td>\n",
       "      <td>-0.030649</td>\n",
       "      <td>-1.662011e-01</td>\n",
       "      <td>-0.007157</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>-0.031003</td>\n",
       "      <td>-0.017989</td>\n",
       "      <td>-0.018529</td>\n",
       "      <td>-0.095146</td>\n",
       "      <td>-0.064942</td>\n",
       "      <td>-0.057403</td>\n",
       "      <td>0.114890</td>\n",
       "      <td>-0.069525</td>\n",
       "      <td>0.134245</td>\n",
       "      <td>-0.231918</td>\n",
       "      <td>0.231918</td>\n",
       "      <td>-0.108173</td>\n",
       "      <td>0.108173</td>\n",
       "      <td>-0.133778</td>\n",
       "      <td>-0.054572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.104158</td>\n",
       "      <td>-0.113468</td>\n",
       "      <td>-0.120800</td>\n",
       "      <td>-0.092116</td>\n",
       "      <td>-0.167679</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>-0.007156</td>\n",
       "      <td>-0.035171</td>\n",
       "      <td>0.032741</td>\n",
       "      <td>0.017291</td>\n",
       "      <td>-0.164145</td>\n",
       "      <td>0.164145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lawyer</th>\n",
       "      <td>-0.060366</td>\n",
       "      <td>-0.031817</td>\n",
       "      <td>-0.038899</td>\n",
       "      <td>0.151418</td>\n",
       "      <td>-0.107980</td>\n",
       "      <td>0.077372</td>\n",
       "      <td>0.240779</td>\n",
       "      <td>-0.049359</td>\n",
       "      <td>1.463892e-01</td>\n",
       "      <td>-0.001798</td>\n",
       "      <td>-0.030612</td>\n",
       "      <td>0.050319</td>\n",
       "      <td>-0.009969</td>\n",
       "      <td>-1.810560e-02</td>\n",
       "      <td>-0.015029</td>\n",
       "      <td>-0.028937</td>\n",
       "      <td>0.021336</td>\n",
       "      <td>-0.003867</td>\n",
       "      <td>0.389687</td>\n",
       "      <td>0.100157</td>\n",
       "      <td>-0.087127</td>\n",
       "      <td>-0.086577</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>-0.018775</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>0.114259</td>\n",
       "      <td>-0.114259</td>\n",
       "      <td>-0.160098</td>\n",
       "      <td>-0.065309</td>\n",
       "      <td>-0.104158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.135793</td>\n",
       "      <td>-0.144567</td>\n",
       "      <td>-0.110240</td>\n",
       "      <td>-0.200669</td>\n",
       "      <td>-0.152929</td>\n",
       "      <td>-0.224459</td>\n",
       "      <td>0.690405</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>-0.236470</td>\n",
       "      <td>-0.251978</td>\n",
       "      <td>0.251978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manager</th>\n",
       "      <td>-0.120199</td>\n",
       "      <td>-0.074727</td>\n",
       "      <td>-0.021961</td>\n",
       "      <td>0.099144</td>\n",
       "      <td>-0.088545</td>\n",
       "      <td>0.078828</td>\n",
       "      <td>0.260044</td>\n",
       "      <td>-0.033027</td>\n",
       "      <td>1.542365e-01</td>\n",
       "      <td>-0.001543</td>\n",
       "      <td>-0.069589</td>\n",
       "      <td>0.127210</td>\n",
       "      <td>0.011357</td>\n",
       "      <td>3.639300e-02</td>\n",
       "      <td>-0.006741</td>\n",
       "      <td>-0.019183</td>\n",
       "      <td>-0.006207</td>\n",
       "      <td>-0.057230</td>\n",
       "      <td>0.167005</td>\n",
       "      <td>0.015149</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>-0.004851</td>\n",
       "      <td>-0.016844</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>-0.053624</td>\n",
       "      <td>0.050540</td>\n",
       "      <td>-0.050540</td>\n",
       "      <td>0.201318</td>\n",
       "      <td>-0.201318</td>\n",
       "      <td>-0.174408</td>\n",
       "      <td>-0.071146</td>\n",
       "      <td>-0.113468</td>\n",
       "      <td>-0.135793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.157489</td>\n",
       "      <td>-0.120093</td>\n",
       "      <td>-0.218605</td>\n",
       "      <td>-0.163891</td>\n",
       "      <td>0.128430</td>\n",
       "      <td>0.118462</td>\n",
       "      <td>0.094027</td>\n",
       "      <td>-0.145482</td>\n",
       "      <td>-0.083417</td>\n",
       "      <td>0.083417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Professional</th>\n",
       "      <td>-0.042788</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>-0.024108</td>\n",
       "      <td>0.045862</td>\n",
       "      <td>-0.070925</td>\n",
       "      <td>0.083294</td>\n",
       "      <td>0.177764</td>\n",
       "      <td>-0.012429</td>\n",
       "      <td>1.332558e-01</td>\n",
       "      <td>-0.011044</td>\n",
       "      <td>-0.002127</td>\n",
       "      <td>0.115670</td>\n",
       "      <td>0.014144</td>\n",
       "      <td>5.064493e-02</td>\n",
       "      <td>-0.007313</td>\n",
       "      <td>-0.005158</td>\n",
       "      <td>-0.003038</td>\n",
       "      <td>0.009098</td>\n",
       "      <td>0.072714</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.089586</td>\n",
       "      <td>-0.008333</td>\n",
       "      <td>-0.031459</td>\n",
       "      <td>0.055289</td>\n",
       "      <td>-0.066986</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>-0.065809</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>-0.042100</td>\n",
       "      <td>-0.185677</td>\n",
       "      <td>-0.075743</td>\n",
       "      <td>-0.120800</td>\n",
       "      <td>-0.144567</td>\n",
       "      <td>-0.157489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.127853</td>\n",
       "      <td>-0.232731</td>\n",
       "      <td>-0.172190</td>\n",
       "      <td>0.302318</td>\n",
       "      <td>-0.001673</td>\n",
       "      <td>-0.085398</td>\n",
       "      <td>-0.112027</td>\n",
       "      <td>-0.062776</td>\n",
       "      <td>0.062776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student</th>\n",
       "      <td>0.076003</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>0.022554</td>\n",
       "      <td>-0.126245</td>\n",
       "      <td>0.126687</td>\n",
       "      <td>-0.333939</td>\n",
       "      <td>-0.372543</td>\n",
       "      <td>0.052551</td>\n",
       "      <td>-3.410919e-01</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>-0.176101</td>\n",
       "      <td>-0.024620</td>\n",
       "      <td>2.562532e-02</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.033112</td>\n",
       "      <td>0.037251</td>\n",
       "      <td>-0.154807</td>\n",
       "      <td>-0.037636</td>\n",
       "      <td>-0.029560</td>\n",
       "      <td>0.066796</td>\n",
       "      <td>0.022651</td>\n",
       "      <td>-0.051975</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>-0.014502</td>\n",
       "      <td>-0.099795</td>\n",
       "      <td>0.099795</td>\n",
       "      <td>-0.141588</td>\n",
       "      <td>-0.057758</td>\n",
       "      <td>-0.092116</td>\n",
       "      <td>-0.110240</td>\n",
       "      <td>-0.120093</td>\n",
       "      <td>-0.127853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177469</td>\n",
       "      <td>0.142148</td>\n",
       "      <td>-0.077788</td>\n",
       "      <td>-0.144065</td>\n",
       "      <td>-0.084993</td>\n",
       "      <td>0.129157</td>\n",
       "      <td>0.106712</td>\n",
       "      <td>-0.106712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_Blue Collar</th>\n",
       "      <td>0.107181</td>\n",
       "      <td>0.079566</td>\n",
       "      <td>0.042854</td>\n",
       "      <td>-0.057652</td>\n",
       "      <td>0.039677</td>\n",
       "      <td>0.132597</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>3.576189e-02</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.039381</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>3.269438e-02</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.029584</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.020018</td>\n",
       "      <td>-0.231338</td>\n",
       "      <td>-0.001996</td>\n",
       "      <td>0.018663</td>\n",
       "      <td>0.041650</td>\n",
       "      <td>-0.043354</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>-0.026071</td>\n",
       "      <td>0.062124</td>\n",
       "      <td>-0.062124</td>\n",
       "      <td>-0.048344</td>\n",
       "      <td>0.048344</td>\n",
       "      <td>-0.257733</td>\n",
       "      <td>-0.105137</td>\n",
       "      <td>-0.167679</td>\n",
       "      <td>-0.200669</td>\n",
       "      <td>-0.218605</td>\n",
       "      <td>-0.232731</td>\n",
       "      <td>-0.177469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110668</td>\n",
       "      <td>0.029042</td>\n",
       "      <td>-0.259205</td>\n",
       "      <td>-0.154712</td>\n",
       "      <td>0.182324</td>\n",
       "      <td>0.518674</td>\n",
       "      <td>-0.518674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;High School</th>\n",
       "      <td>0.061573</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.035724</td>\n",
       "      <td>-0.128571</td>\n",
       "      <td>0.130558</td>\n",
       "      <td>-0.046294</td>\n",
       "      <td>-0.321036</td>\n",
       "      <td>0.034588</td>\n",
       "      <td>-1.975227e-01</td>\n",
       "      <td>0.014543</td>\n",
       "      <td>0.023374</td>\n",
       "      <td>-0.133144</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>7.934922e-03</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>-0.013589</td>\n",
       "      <td>0.028533</td>\n",
       "      <td>-0.344391</td>\n",
       "      <td>-0.042088</td>\n",
       "      <td>-0.024997</td>\n",
       "      <td>0.066531</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>-0.016808</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.016121</td>\n",
       "      <td>-0.016121</td>\n",
       "      <td>-0.097835</td>\n",
       "      <td>0.097835</td>\n",
       "      <td>0.237710</td>\n",
       "      <td>-0.080125</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>-0.152929</td>\n",
       "      <td>-0.163891</td>\n",
       "      <td>-0.172190</td>\n",
       "      <td>0.142148</td>\n",
       "      <td>0.110668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.275379</td>\n",
       "      <td>-0.199853</td>\n",
       "      <td>-0.117905</td>\n",
       "      <td>-0.290116</td>\n",
       "      <td>-0.102908</td>\n",
       "      <td>0.102908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bachelors</th>\n",
       "      <td>-0.048945</td>\n",
       "      <td>-0.013718</td>\n",
       "      <td>-0.017986</td>\n",
       "      <td>-0.002078</td>\n",
       "      <td>-0.036632</td>\n",
       "      <td>0.022193</td>\n",
       "      <td>0.116930</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>8.845280e-02</td>\n",
       "      <td>-0.025578</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.073225</td>\n",
       "      <td>-0.008104</td>\n",
       "      <td>3.521365e-02</td>\n",
       "      <td>-0.007142</td>\n",
       "      <td>0.008117</td>\n",
       "      <td>-0.011919</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.107948</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>-0.011608</td>\n",
       "      <td>-0.024361</td>\n",
       "      <td>0.028881</td>\n",
       "      <td>-0.020554</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>-0.031515</td>\n",
       "      <td>0.036633</td>\n",
       "      <td>-0.036633</td>\n",
       "      <td>-0.122172</td>\n",
       "      <td>-0.117601</td>\n",
       "      <td>-0.007156</td>\n",
       "      <td>-0.224459</td>\n",
       "      <td>0.128430</td>\n",
       "      <td>0.302318</td>\n",
       "      <td>-0.077788</td>\n",
       "      <td>0.029042</td>\n",
       "      <td>-0.275379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.293330</td>\n",
       "      <td>-0.173053</td>\n",
       "      <td>-0.425811</td>\n",
       "      <td>0.113437</td>\n",
       "      <td>-0.113437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Masters</th>\n",
       "      <td>-0.099694</td>\n",
       "      <td>-0.057331</td>\n",
       "      <td>-0.037772</td>\n",
       "      <td>0.175363</td>\n",
       "      <td>-0.135442</td>\n",
       "      <td>0.065280</td>\n",
       "      <td>0.264049</td>\n",
       "      <td>-0.070126</td>\n",
       "      <td>1.650958e-01</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>-0.034250</td>\n",
       "      <td>0.085644</td>\n",
       "      <td>0.009939</td>\n",
       "      <td>-1.821262e-02</td>\n",
       "      <td>-0.012257</td>\n",
       "      <td>-0.033525</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>-0.036970</td>\n",
       "      <td>0.505387</td>\n",
       "      <td>0.072960</td>\n",
       "      <td>-0.029733</td>\n",
       "      <td>-0.079113</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>-0.021388</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>0.143069</td>\n",
       "      <td>-0.143069</td>\n",
       "      <td>-0.209221</td>\n",
       "      <td>-0.085348</td>\n",
       "      <td>-0.035171</td>\n",
       "      <td>0.690405</td>\n",
       "      <td>0.118462</td>\n",
       "      <td>-0.001673</td>\n",
       "      <td>-0.144065</td>\n",
       "      <td>-0.259205</td>\n",
       "      <td>-0.199853</td>\n",
       "      <td>-0.293330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.125591</td>\n",
       "      <td>-0.309028</td>\n",
       "      <td>-0.236406</td>\n",
       "      <td>0.236406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhD</th>\n",
       "      <td>-0.056958</td>\n",
       "      <td>-0.026361</td>\n",
       "      <td>-0.035748</td>\n",
       "      <td>0.145360</td>\n",
       "      <td>-0.090486</td>\n",
       "      <td>0.010370</td>\n",
       "      <td>0.377145</td>\n",
       "      <td>-0.035619</td>\n",
       "      <td>1.807543e-01</td>\n",
       "      <td>-0.041396</td>\n",
       "      <td>-0.026351</td>\n",
       "      <td>0.133566</td>\n",
       "      <td>-0.013269</td>\n",
       "      <td>-2.712098e-02</td>\n",
       "      <td>-0.024036</td>\n",
       "      <td>-0.010171</td>\n",
       "      <td>-0.020762</td>\n",
       "      <td>-0.030796</td>\n",
       "      <td>0.286545</td>\n",
       "      <td>0.015475</td>\n",
       "      <td>0.011402</td>\n",
       "      <td>-0.038345</td>\n",
       "      <td>-0.006581</td>\n",
       "      <td>0.029561</td>\n",
       "      <td>-0.002661</td>\n",
       "      <td>-0.034533</td>\n",
       "      <td>0.034533</td>\n",
       "      <td>0.104346</td>\n",
       "      <td>-0.104346</td>\n",
       "      <td>-0.123432</td>\n",
       "      <td>0.679566</td>\n",
       "      <td>0.032741</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.094027</td>\n",
       "      <td>-0.085398</td>\n",
       "      <td>-0.084993</td>\n",
       "      <td>-0.154712</td>\n",
       "      <td>-0.117905</td>\n",
       "      <td>-0.173053</td>\n",
       "      <td>-0.125591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.182314</td>\n",
       "      <td>-0.132147</td>\n",
       "      <td>0.132147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_High School</th>\n",
       "      <td>0.112601</td>\n",
       "      <td>0.043025</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>-0.120499</td>\n",
       "      <td>0.093916</td>\n",
       "      <td>-0.044608</td>\n",
       "      <td>-0.285222</td>\n",
       "      <td>0.041173</td>\n",
       "      <td>-1.657100e-01</td>\n",
       "      <td>0.029220</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>-0.110349</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>-1.089174e-02</td>\n",
       "      <td>0.023063</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.030438</td>\n",
       "      <td>0.023059</td>\n",
       "      <td>-0.406907</td>\n",
       "      <td>-0.040388</td>\n",
       "      <td>-0.009933</td>\n",
       "      <td>0.044994</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>-0.031682</td>\n",
       "      <td>0.016846</td>\n",
       "      <td>-0.007052</td>\n",
       "      <td>0.007052</td>\n",
       "      <td>-0.133601</td>\n",
       "      <td>0.133601</td>\n",
       "      <td>0.171914</td>\n",
       "      <td>-0.123894</td>\n",
       "      <td>0.017291</td>\n",
       "      <td>-0.236470</td>\n",
       "      <td>-0.145482</td>\n",
       "      <td>-0.112027</td>\n",
       "      <td>0.129157</td>\n",
       "      <td>0.182324</td>\n",
       "      <td>-0.290116</td>\n",
       "      <td>-0.425811</td>\n",
       "      <td>-0.309028</td>\n",
       "      <td>-0.182314</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237031</td>\n",
       "      <td>-0.237031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Commercial</th>\n",
       "      <td>0.160423</td>\n",
       "      <td>0.104196</td>\n",
       "      <td>0.009958</td>\n",
       "      <td>-0.073692</td>\n",
       "      <td>0.027309</td>\n",
       "      <td>0.006761</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>-2.493236e-02</td>\n",
       "      <td>-0.007751</td>\n",
       "      <td>0.022029</td>\n",
       "      <td>0.144139</td>\n",
       "      <td>-0.003040</td>\n",
       "      <td>1.709550e-01</td>\n",
       "      <td>0.028387</td>\n",
       "      <td>0.071680</td>\n",
       "      <td>0.016219</td>\n",
       "      <td>0.056993</td>\n",
       "      <td>-0.163646</td>\n",
       "      <td>-0.169632</td>\n",
       "      <td>0.345772</td>\n",
       "      <td>0.237649</td>\n",
       "      <td>-0.114852</td>\n",
       "      <td>0.114703</td>\n",
       "      <td>-0.191115</td>\n",
       "      <td>0.239076</td>\n",
       "      <td>-0.239076</td>\n",
       "      <td>-0.049635</td>\n",
       "      <td>0.049635</td>\n",
       "      <td>-0.148761</td>\n",
       "      <td>-0.132019</td>\n",
       "      <td>-0.164145</td>\n",
       "      <td>-0.251978</td>\n",
       "      <td>-0.083417</td>\n",
       "      <td>-0.062776</td>\n",
       "      <td>0.106712</td>\n",
       "      <td>0.518674</td>\n",
       "      <td>-0.102908</td>\n",
       "      <td>0.113437</td>\n",
       "      <td>-0.236406</td>\n",
       "      <td>-0.132147</td>\n",
       "      <td>0.237031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private</th>\n",
       "      <td>-0.160423</td>\n",
       "      <td>-0.104196</td>\n",
       "      <td>-0.009958</td>\n",
       "      <td>0.073692</td>\n",
       "      <td>-0.027309</td>\n",
       "      <td>-0.006761</td>\n",
       "      <td>0.016378</td>\n",
       "      <td>-0.017964</td>\n",
       "      <td>2.493236e-02</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>-0.022029</td>\n",
       "      <td>-0.144139</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>-1.709550e-01</td>\n",
       "      <td>-0.028387</td>\n",
       "      <td>-0.071680</td>\n",
       "      <td>-0.016219</td>\n",
       "      <td>-0.056993</td>\n",
       "      <td>0.163646</td>\n",
       "      <td>0.169632</td>\n",
       "      <td>-0.345772</td>\n",
       "      <td>-0.237649</td>\n",
       "      <td>0.114852</td>\n",
       "      <td>-0.114703</td>\n",
       "      <td>0.191115</td>\n",
       "      <td>-0.239076</td>\n",
       "      <td>0.239076</td>\n",
       "      <td>0.049635</td>\n",
       "      <td>-0.049635</td>\n",
       "      <td>0.148761</td>\n",
       "      <td>0.132019</td>\n",
       "      <td>0.164145</td>\n",
       "      <td>0.251978</td>\n",
       "      <td>0.083417</td>\n",
       "      <td>0.062776</td>\n",
       "      <td>-0.106712</td>\n",
       "      <td>-0.518674</td>\n",
       "      <td>0.102908</td>\n",
       "      <td>-0.113437</td>\n",
       "      <td>0.236406</td>\n",
       "      <td>0.132147</td>\n",
       "      <td>-0.237031</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       TARGET_FLAG  TARGET_AMT  KIDSDRIV       AGE  HOMEKIDS  \\\n",
       "TARGET_FLAG               1.000000    0.541242  0.086933 -0.115274  0.111866   \n",
       "TARGET_AMT                0.541242    1.000000  0.039043 -0.056546  0.053780   \n",
       "KIDSDRIV                  0.086933    0.039043  1.000000 -0.066429  0.454167   \n",
       "AGE                      -0.115274   -0.056546 -0.066429  1.000000 -0.445086   \n",
       "HOMEKIDS                  0.111866    0.053780  0.454167 -0.445086  1.000000   \n",
       "YOJ                      -0.066429   -0.024286  0.051048  0.132253  0.095758   \n",
       "INCOME                   -0.148034   -0.062690 -0.031816  0.183458 -0.145551   \n",
       "PARENT1                   0.162017    0.095154  0.188811 -0.316694  0.445659   \n",
       "HOME_VAL                 -0.184516   -0.097500 -0.011720  0.215841 -0.104264   \n",
       "MSTATUS                  -0.131525   -0.093214  0.045769  0.098247  0.048468   \n",
       "TRAVTIME                  0.051459    0.024283 -0.000443  0.009195 -0.013962   \n",
       "BLUEBOOK                 -0.111521   -0.015724 -0.011378  0.156458 -0.092876   \n",
       "TIF                      -0.078885   -0.043934  0.000524  0.002110  0.001333   \n",
       "RED_CAR                  -0.025165   -0.003450 -0.033525  0.016985 -0.069348   \n",
       "OLDCLAIM                  0.138721    0.074603  0.022166 -0.026570  0.033514   \n",
       "CLM_FREQ                  0.228004    0.113483  0.040624 -0.030659  0.034326   \n",
       "REVOKED                   0.142795    0.061262  0.037857 -0.035284  0.044586   \n",
       "MVR_PTS                   0.230171    0.140949  0.062978 -0.078043  0.071230   \n",
       "CAR_AGE                  -0.110253   -0.069613 -0.047095  0.190253 -0.154874   \n",
       "Minivan                  -0.146526   -0.086467 -0.010432  0.019562 -0.047928   \n",
       "Panel Truck               0.019402    0.037344 -0.005659  0.020658 -0.035769   \n",
       "Pickup                    0.057460    0.020211  0.011489 -0.046641 -0.001889   \n",
       "Sports Car                0.064783    0.036666 -0.009613  0.030922  0.030861   \n",
       "Van                      -0.010080    0.014354 -0.031250  0.021782 -0.048140   \n",
       "z_SUV                     0.047699    0.015135  0.029240 -0.026517  0.073995   \n",
       "M                        -0.024006    0.002727 -0.040837  0.062553 -0.109589   \n",
       "z_F                       0.024006   -0.002727  0.040837 -0.062553  0.109589   \n",
       "Highly Urban/ Urban       0.226721    0.123812 -0.027217  0.043143 -0.053517   \n",
       "z_Highly Rural/ Rural    -0.226721   -0.123812  0.027217 -0.043143  0.053517   \n",
       "Clerical                  0.038639    0.003161  0.030236 -0.160579  0.129903   \n",
       "Doctor                   -0.054492   -0.035937 -0.042424  0.119215 -0.086300   \n",
       "Home Maker                0.006538   -0.003548 -0.002163  0.010769  0.007094   \n",
       "Lawyer                   -0.060366   -0.031817 -0.038899  0.151418 -0.107980   \n",
       "Manager                  -0.120199   -0.074727 -0.021961  0.099144 -0.088545   \n",
       "Professional             -0.042788    0.002987 -0.024108  0.045862 -0.070925   \n",
       "Student                   0.076003    0.021087  0.022554 -0.126245  0.126687   \n",
       "z_Blue Collar             0.107181    0.079566  0.042854 -0.057652  0.039677   \n",
       "<High School              0.061573    0.040600  0.035724 -0.128571  0.130558   \n",
       "Bachelors                -0.048945   -0.013718 -0.017986 -0.002078 -0.036632   \n",
       "Masters                  -0.099694   -0.057331 -0.037772  0.175363 -0.135442   \n",
       "PhD                      -0.056958   -0.026361 -0.035748  0.145360 -0.090486   \n",
       "z_High School             0.112601    0.043025  0.040103 -0.120499  0.093916   \n",
       "Commercial                0.160423    0.104196  0.009958 -0.073692  0.027309   \n",
       "Private                  -0.160423   -0.104196 -0.009958  0.073692 -0.027309   \n",
       "\n",
       "                            YOJ    INCOME   PARENT1      HOME_VAL   MSTATUS  \\\n",
       "TARGET_FLAG           -0.066429 -0.148034  0.162017 -1.845159e-01 -0.131525   \n",
       "TARGET_AMT            -0.024286 -0.062690  0.095154 -9.749983e-02 -0.093214   \n",
       "KIDSDRIV               0.051048 -0.031816  0.188811 -1.172042e-02  0.045769   \n",
       "AGE                    0.132253  0.183458 -0.316694  2.158415e-01  0.098247   \n",
       "HOMEKIDS               0.095758 -0.145551  0.445659 -1.042645e-01  0.048468   \n",
       "YOJ                    1.000000  0.298453 -0.046951  2.772885e-01  0.141523   \n",
       "INCOME                 0.298453  1.000000 -0.064973  5.817192e-01 -0.024963   \n",
       "PARENT1               -0.046951 -0.064973  1.000000 -2.600270e-01 -0.480884   \n",
       "HOME_VAL               0.277288  0.581719 -0.260027  1.000000e+00  0.462668   \n",
       "MSTATUS                0.141523 -0.024963 -0.480884  4.626684e-01  1.000000   \n",
       "TRAVTIME              -0.015694 -0.045834 -0.011957 -2.912683e-02  0.006651   \n",
       "BLUEBOOK               0.135757  0.383451 -0.049007  2.419056e-01  0.014182   \n",
       "TIF                    0.030362  0.008170 -0.011548 -7.396246e-04 -0.003984   \n",
       "RED_CAR                0.040307  0.031111 -0.044021 -4.890107e-07 -0.018174   \n",
       "OLDCLAIM               0.000764 -0.040746  0.034943 -6.076370e-02 -0.043221   \n",
       "CLM_FREQ              -0.034353 -0.061672  0.058332 -1.030290e-01 -0.076955   \n",
       "REVOKED               -0.004496 -0.016505  0.046308 -4.587113e-02 -0.037805   \n",
       "MVR_PTS               -0.037392 -0.077280  0.078017 -9.951207e-02 -0.059975   \n",
       "CAR_AGE                0.053479  0.389749 -0.058432  2.046951e-01 -0.029307   \n",
       "Minivan                0.061931  0.090892 -0.014277  5.391614e-02 -0.005365   \n",
       "Panel Truck            0.024295  0.103658 -0.016982  6.608049e-02 -0.000692   \n",
       "Pickup                -0.005836 -0.076578 -0.005017 -4.482213e-02  0.002374   \n",
       "Sports Car            -0.052785 -0.076428  0.017810 -4.485426e-02  0.010591   \n",
       "Van                    0.036631  0.128565 -0.032524  6.702444e-02 -0.010364   \n",
       "z_SUV                 -0.053221 -0.102503  0.033686 -5.846107e-02  0.002394   \n",
       "M                      0.066328  0.057403 -0.069196  3.856908e-02 -0.006287   \n",
       "z_F                   -0.066328 -0.057403  0.069196 -3.856908e-02  0.006287   \n",
       "Highly Urban/ Urban    0.074142  0.201310 -0.007313  1.060812e-01 -0.006112   \n",
       "z_Highly Rural/ Rural -0.074142 -0.201310  0.007313 -1.060812e-01  0.006112   \n",
       "Clerical               0.112347 -0.248185  0.044660 -1.195959e-01  0.028238   \n",
       "Doctor                 0.033989  0.300671 -0.043702  1.349615e-01 -0.039581   \n",
       "Home Maker            -0.332360 -0.309750  0.005665 -1.541670e-01 -0.008690   \n",
       "Lawyer                 0.077372  0.240779 -0.049359  1.463892e-01 -0.001798   \n",
       "Manager                0.078828  0.260044 -0.033027  1.542365e-01 -0.001543   \n",
       "Professional           0.083294  0.177764 -0.012429  1.332558e-01 -0.011044   \n",
       "Student               -0.333939 -0.372543  0.052551 -3.410919e-01  0.010027   \n",
       "z_Blue Collar          0.132597  0.010641  0.012687  3.576189e-02  0.002138   \n",
       "<High School          -0.046294 -0.321036  0.034588 -1.975227e-01  0.014543   \n",
       "Bachelors              0.022193  0.116930  0.008948  8.845280e-02 -0.025578   \n",
       "Masters                0.065280  0.264049 -0.070126  1.650958e-01  0.008562   \n",
       "PhD                    0.010370  0.377145 -0.035619  1.807543e-01 -0.041396   \n",
       "z_High School         -0.044608 -0.285222  0.041173 -1.657100e-01  0.029220   \n",
       "Commercial             0.006761 -0.016378  0.017964 -2.493236e-02 -0.007751   \n",
       "Private               -0.006761  0.016378 -0.017964  2.493236e-02  0.007751   \n",
       "\n",
       "                       TRAVTIME  BLUEBOOK       TIF       RED_CAR  OLDCLAIM  \\\n",
       "TARGET_FLAG            0.051459 -0.111521 -0.078885 -2.516496e-02  0.138721   \n",
       "TARGET_AMT             0.024283 -0.015724 -0.043934 -3.449673e-03  0.074603   \n",
       "KIDSDRIV              -0.000443 -0.011378  0.000524 -3.352508e-02  0.022166   \n",
       "AGE                    0.009195  0.156458  0.002110  1.698497e-02 -0.026570   \n",
       "HOMEKIDS              -0.013962 -0.092876  0.001333 -6.934824e-02  0.033514   \n",
       "YOJ                   -0.015694  0.135757  0.030362  4.030718e-02  0.000764   \n",
       "INCOME                -0.045834  0.383451  0.008170  3.111072e-02 -0.040746   \n",
       "PARENT1               -0.011957 -0.049007 -0.011548 -4.402081e-02  0.034943   \n",
       "HOME_VAL              -0.029127  0.241906 -0.000740 -4.890107e-07 -0.060764   \n",
       "MSTATUS                0.006651  0.014182 -0.003984 -1.817449e-02 -0.043221   \n",
       "TRAVTIME               1.000000 -0.013343 -0.012107 -2.691268e-03 -0.025930   \n",
       "BLUEBOOK              -0.013343  1.000000  0.009534 -8.335184e-03 -0.037475   \n",
       "TIF                   -0.012107  0.009534  1.000000  6.823897e-03 -0.018050   \n",
       "RED_CAR               -0.002691 -0.008335  0.006824  1.000000e+00  0.009250   \n",
       "OLDCLAIM              -0.025930 -0.037475 -0.018050  9.249951e-03  1.000000   \n",
       "CLM_FREQ               0.008725 -0.058051 -0.024453  2.557078e-02  0.495052   \n",
       "REVOKED               -0.019178 -0.021650 -0.031770  9.319750e-03  0.431533   \n",
       "MVR_PTS               -0.003039 -0.065272 -0.039664  1.489312e-03  0.274089   \n",
       "CAR_AGE               -0.029993  0.143979  0.008438 -1.137195e-02 -0.017146   \n",
       "Minivan               -0.007292  0.086369 -0.008954  1.902785e-01 -0.032460   \n",
       "Panel Truck           -0.005053  0.416651 -0.007040  1.614969e-01 -0.007859   \n",
       "Pickup                -0.006269 -0.132565  0.002848  1.808470e-01  0.000693   \n",
       "Sports Car             0.014071 -0.139798 -0.011039 -2.018086e-01  0.046909   \n",
       "Van                   -0.007979  0.207122  0.024935  1.630040e-01 -0.000797   \n",
       "z_SUV                  0.009715 -0.213939  0.003004 -3.728526e-01  0.002726   \n",
       "M                     -0.006324  0.018364  0.008695  6.746639e-01 -0.012624   \n",
       "z_F                    0.006324 -0.018364 -0.008695 -6.746639e-01  0.012624   \n",
       "Highly Urban/ Urban   -0.163024  0.082600  0.013445  4.543815e-02  0.152848   \n",
       "z_Highly Rural/ Rural  0.163024 -0.082600 -0.013445 -4.543815e-02 -0.152848   \n",
       "Clerical               0.009470 -0.107773  0.029454 -2.358606e-03  0.012909   \n",
       "Doctor                -0.023214  0.093231 -0.014519  2.169577e-03 -0.022002   \n",
       "Home Maker             0.043111 -0.116117 -0.030649 -1.662011e-01 -0.007157   \n",
       "Lawyer                -0.030612  0.050319 -0.009969 -1.810560e-02 -0.015029   \n",
       "Manager               -0.069589  0.127210  0.011357  3.639300e-02 -0.006741   \n",
       "Professional          -0.002127  0.115670  0.014144  5.064493e-02 -0.007313   \n",
       "Student                0.019837 -0.176101 -0.024620  2.562532e-02  0.019358   \n",
       "z_Blue Collar          0.039381  0.015118  0.002806  3.269438e-02  0.011769   \n",
       "<High School           0.023374 -0.133144  0.000976  7.934922e-03  0.009115   \n",
       "Bachelors              0.009310  0.073225 -0.008104  3.521365e-02 -0.007142   \n",
       "Masters               -0.034250  0.085644  0.009939 -1.821262e-02 -0.012257   \n",
       "PhD                   -0.026351  0.133566 -0.013269 -2.712098e-02 -0.024036   \n",
       "z_High School          0.015068 -0.110349  0.006261 -1.089174e-02  0.023063   \n",
       "Commercial             0.022029  0.144139 -0.003040  1.709550e-01  0.028387   \n",
       "Private               -0.022029 -0.144139  0.003040 -1.709550e-01 -0.028387   \n",
       "\n",
       "                       CLM_FREQ   REVOKED   MVR_PTS   CAR_AGE   Minivan  \\\n",
       "TARGET_FLAG            0.228004  0.142795  0.230171 -0.110253 -0.146526   \n",
       "TARGET_AMT             0.113483  0.061262  0.140949 -0.069613 -0.086467   \n",
       "KIDSDRIV               0.040624  0.037857  0.062978 -0.047095 -0.010432   \n",
       "AGE                   -0.030659 -0.035284 -0.078043  0.190253  0.019562   \n",
       "HOMEKIDS               0.034326  0.044586  0.071230 -0.154874 -0.047928   \n",
       "YOJ                   -0.034353 -0.004496 -0.037392  0.053479  0.061931   \n",
       "INCOME                -0.061672 -0.016505 -0.077280  0.389749  0.090892   \n",
       "PARENT1                0.058332  0.046308  0.078017 -0.058432 -0.014277   \n",
       "HOME_VAL              -0.103029 -0.045871 -0.099512  0.204695  0.053916   \n",
       "MSTATUS               -0.076955 -0.037805 -0.059975 -0.029307 -0.005365   \n",
       "TRAVTIME               0.008725 -0.019178 -0.003039 -0.029993 -0.007292   \n",
       "BLUEBOOK              -0.058051 -0.021650 -0.065272  0.143979  0.086369   \n",
       "TIF                   -0.024453 -0.031770 -0.039664  0.008438 -0.008954   \n",
       "RED_CAR                0.025571  0.009320  0.001489 -0.011372  0.190279   \n",
       "OLDCLAIM               0.495052  0.431533  0.274089 -0.017146 -0.032460   \n",
       "CLM_FREQ               1.000000  0.065845  0.399165 -0.019161 -0.072947   \n",
       "REVOKED                0.065845  1.000000  0.056173  0.000630 -0.016684   \n",
       "MVR_PTS                0.399165  0.056173  1.000000 -0.029007 -0.056140   \n",
       "CAR_AGE               -0.019161  0.000630 -0.029007  1.000000  0.064603   \n",
       "Minivan               -0.072947 -0.016684 -0.056140  0.064603  1.000000   \n",
       "Panel Truck            0.017820 -0.012590 -0.011474  0.000311 -0.154423   \n",
       "Pickup                 0.022603  0.006548  0.026152 -0.078013 -0.280931   \n",
       "Sports Car             0.050705  0.002940  0.037147 -0.008954 -0.229009   \n",
       "Van                   -0.006132 -0.002258 -0.004075  0.020620 -0.185437   \n",
       "z_SUV                  0.012104  0.016782  0.015933 -0.005925 -0.404418   \n",
       "M                      0.005441 -0.001491 -0.019986 -0.026332  0.264446   \n",
       "z_F                   -0.005441  0.001491  0.019986  0.026332 -0.264446   \n",
       "Highly Urban/ Urban    0.245447  0.088666  0.160044  0.159600  0.041014   \n",
       "z_Highly Rural/ Rural -0.245447 -0.088666 -0.160044 -0.159600 -0.041014   \n",
       "Clerical              -0.010074 -0.001649  0.017847 -0.241556 -0.028475   \n",
       "Doctor                 0.002546 -0.032849 -0.021411  0.198584  0.030280   \n",
       "Home Maker             0.000257 -0.031003 -0.017989 -0.018529 -0.095146   \n",
       "Lawyer                -0.028937  0.021336 -0.003867  0.389687  0.100157   \n",
       "Manager               -0.019183 -0.006207 -0.057230  0.167005  0.015149   \n",
       "Professional          -0.005158 -0.003038  0.009098  0.072714  0.017576   \n",
       "Student                0.027681  0.033112  0.037251 -0.154807 -0.037636   \n",
       "z_Blue Collar          0.029584  0.004508  0.020018 -0.231338 -0.001996   \n",
       "<High School           0.010679 -0.013589  0.028533 -0.344391 -0.042088   \n",
       "Bachelors              0.008117 -0.011919  0.001766  0.107948  0.005186   \n",
       "Masters               -0.033525  0.004052 -0.036970  0.505387  0.072960   \n",
       "PhD                   -0.010171 -0.020762 -0.030796  0.286545  0.015475   \n",
       "z_High School          0.016785  0.030438  0.023059 -0.406907 -0.040388   \n",
       "Commercial             0.071680  0.016219  0.056993 -0.163646 -0.169632   \n",
       "Private               -0.071680 -0.016219 -0.056993  0.163646  0.169632   \n",
       "\n",
       "                       Panel Truck    Pickup  Sports Car       Van     z_SUV  \\\n",
       "TARGET_FLAG               0.019402  0.057460    0.064783 -0.010080  0.047699   \n",
       "TARGET_AMT                0.037344  0.020211    0.036666  0.014354  0.015135   \n",
       "KIDSDRIV                 -0.005659  0.011489   -0.009613 -0.031250  0.029240   \n",
       "AGE                       0.020658 -0.046641    0.030922  0.021782 -0.026517   \n",
       "HOMEKIDS                 -0.035769 -0.001889    0.030861 -0.048140  0.073995   \n",
       "YOJ                       0.024295 -0.005836   -0.052785  0.036631 -0.053221   \n",
       "INCOME                    0.103658 -0.076578   -0.076428  0.128565 -0.102503   \n",
       "PARENT1                  -0.016982 -0.005017    0.017810 -0.032524  0.033686   \n",
       "HOME_VAL                  0.066080 -0.044822   -0.044854  0.067024 -0.058461   \n",
       "MSTATUS                  -0.000692  0.002374    0.010591 -0.010364  0.002394   \n",
       "TRAVTIME                 -0.005053 -0.006269    0.014071 -0.007979  0.009715   \n",
       "BLUEBOOK                  0.416651 -0.132565   -0.139798  0.207122 -0.213939   \n",
       "TIF                      -0.007040  0.002848   -0.011039  0.024935  0.003004   \n",
       "RED_CAR                   0.161497  0.180847   -0.201809  0.163004 -0.372853   \n",
       "OLDCLAIM                 -0.007859  0.000693    0.046909 -0.000797  0.002726   \n",
       "CLM_FREQ                  0.017820  0.022603    0.050705 -0.006132  0.012104   \n",
       "REVOKED                  -0.012590  0.006548    0.002940 -0.002258  0.016782   \n",
       "MVR_PTS                  -0.011474  0.026152    0.037147 -0.004075  0.015933   \n",
       "CAR_AGE                   0.000311 -0.078013   -0.008954  0.020620 -0.005925   \n",
       "Minivan                  -0.154423 -0.280931   -0.229009 -0.185437 -0.404418   \n",
       "Panel Truck               1.000000 -0.110789   -0.090313 -0.073130 -0.159488   \n",
       "Pickup                   -0.110789  1.000000   -0.164300 -0.133040 -0.290145   \n",
       "Sports Car               -0.090313 -0.164300    1.000000 -0.108451 -0.236520   \n",
       "Van                      -0.073130 -0.133040   -0.108451  1.000000 -0.191520   \n",
       "z_SUV                    -0.159488 -0.290145   -0.236520 -0.191520  1.000000   \n",
       "M                         0.248772  0.243648   -0.307661  0.254399 -0.521692   \n",
       "z_F                      -0.248772 -0.243648    0.307661 -0.254399  0.521692   \n",
       "Highly Urban/ Urban       0.028774 -0.011784   -0.026762  0.028003 -0.043268   \n",
       "z_Highly Rural/ Rural    -0.028774  0.011784    0.026762 -0.028003  0.043268   \n",
       "Clerical                 -0.024925  0.043623   -0.003783 -0.021361  0.020495   \n",
       "Doctor                   -0.045648 -0.033537   -0.010382  0.036852  0.006239   \n",
       "Home Maker               -0.064942 -0.057403    0.114890 -0.069525  0.134245   \n",
       "Lawyer                   -0.087127 -0.086577    0.003043  0.003699  0.012255   \n",
       "Manager                   0.093994 -0.004851   -0.016844  0.011079 -0.053624   \n",
       "Professional              0.089586 -0.008333   -0.031459  0.055289 -0.066986   \n",
       "Student                  -0.029560  0.066796    0.022651 -0.051975  0.012483   \n",
       "z_Blue Collar             0.018663  0.041650   -0.043354  0.025226 -0.026071   \n",
       "<High School             -0.024997  0.066531    0.007309 -0.016808  0.004611   \n",
       "Bachelors                 0.048881 -0.011608   -0.024361  0.028881 -0.020554   \n",
       "Masters                  -0.029733 -0.079113    0.009002  0.000555  0.001340   \n",
       "PhD                       0.011402 -0.038345   -0.006581  0.029561 -0.002661   \n",
       "z_High School            -0.009933  0.044994    0.014290 -0.031682  0.016846   \n",
       "Commercial                0.345772  0.237649   -0.114852  0.114703 -0.191115   \n",
       "Private                  -0.345772 -0.237649    0.114852 -0.114703  0.191115   \n",
       "\n",
       "                              M       z_F  Highly Urban/ Urban  \\\n",
       "TARGET_FLAG           -0.024006  0.024006             0.226721   \n",
       "TARGET_AMT             0.002727 -0.002727             0.123812   \n",
       "KIDSDRIV              -0.040837  0.040837            -0.027217   \n",
       "AGE                    0.062553 -0.062553             0.043143   \n",
       "HOMEKIDS              -0.109589  0.109589            -0.053517   \n",
       "YOJ                    0.066328 -0.066328             0.074142   \n",
       "INCOME                 0.057403 -0.057403             0.201310   \n",
       "PARENT1               -0.069196  0.069196            -0.007313   \n",
       "HOME_VAL               0.038569 -0.038569             0.106081   \n",
       "MSTATUS               -0.006287  0.006287            -0.006112   \n",
       "TRAVTIME              -0.006324  0.006324            -0.163024   \n",
       "BLUEBOOK               0.018364 -0.018364             0.082600   \n",
       "TIF                    0.008695 -0.008695             0.013445   \n",
       "RED_CAR                0.674664 -0.674664             0.045438   \n",
       "OLDCLAIM              -0.012624  0.012624             0.152848   \n",
       "CLM_FREQ               0.005441 -0.005441             0.245447   \n",
       "REVOKED               -0.001491  0.001491             0.088666   \n",
       "MVR_PTS               -0.019986  0.019986             0.160044   \n",
       "CAR_AGE               -0.026332  0.026332             0.159600   \n",
       "Minivan                0.264446 -0.264446             0.041014   \n",
       "Panel Truck            0.248772 -0.248772             0.028774   \n",
       "Pickup                 0.243648 -0.243648            -0.011784   \n",
       "Sports Car            -0.307661  0.307661            -0.026762   \n",
       "Van                    0.254399 -0.254399             0.028003   \n",
       "z_SUV                 -0.521692  0.521692            -0.043268   \n",
       "M                      1.000000 -1.000000             0.043460   \n",
       "z_F                   -1.000000  1.000000            -0.043460   \n",
       "Highly Urban/ Urban    0.043460 -0.043460             1.000000   \n",
       "z_Highly Rural/ Rural -0.043460  0.043460            -1.000000   \n",
       "Clerical               0.000789 -0.000789            -0.151239   \n",
       "Doctor                -0.012782  0.012782             0.096823   \n",
       "Home Maker            -0.231918  0.231918            -0.108173   \n",
       "Lawyer                -0.018775  0.018775             0.114259   \n",
       "Manager                0.050540 -0.050540             0.201318   \n",
       "Professional           0.065809 -0.065809             0.042100   \n",
       "Student                0.014502 -0.014502            -0.099795   \n",
       "z_Blue Collar          0.062124 -0.062124            -0.048344   \n",
       "<High School           0.016121 -0.016121            -0.097835   \n",
       "Bachelors              0.031515 -0.031515             0.036633   \n",
       "Masters               -0.021388  0.021388             0.143069   \n",
       "PhD                   -0.034533  0.034533             0.104346   \n",
       "z_High School         -0.007052  0.007052            -0.133601   \n",
       "Commercial             0.239076 -0.239076            -0.049635   \n",
       "Private               -0.239076  0.239076             0.049635   \n",
       "\n",
       "                       z_Highly Rural/ Rural  Clerical    Doctor  Home Maker  \\\n",
       "TARGET_FLAG                        -0.226721  0.038639 -0.054492    0.006538   \n",
       "TARGET_AMT                         -0.123812  0.003161 -0.035937   -0.003548   \n",
       "KIDSDRIV                            0.027217  0.030236 -0.042424   -0.002163   \n",
       "AGE                                -0.043143 -0.160579  0.119215    0.010769   \n",
       "HOMEKIDS                            0.053517  0.129903 -0.086300    0.007094   \n",
       "YOJ                                -0.074142  0.112347  0.033989   -0.332360   \n",
       "INCOME                             -0.201310 -0.248185  0.300671   -0.309750   \n",
       "PARENT1                             0.007313  0.044660 -0.043702    0.005665   \n",
       "HOME_VAL                           -0.106081 -0.119596  0.134961   -0.154167   \n",
       "MSTATUS                             0.006112  0.028238 -0.039581   -0.008690   \n",
       "TRAVTIME                            0.163024  0.009470 -0.023214    0.043111   \n",
       "BLUEBOOK                           -0.082600 -0.107773  0.093231   -0.116117   \n",
       "TIF                                -0.013445  0.029454 -0.014519   -0.030649   \n",
       "RED_CAR                            -0.045438 -0.002359  0.002170   -0.166201   \n",
       "OLDCLAIM                           -0.152848  0.012909 -0.022002   -0.007157   \n",
       "CLM_FREQ                           -0.245447 -0.010074  0.002546    0.000257   \n",
       "REVOKED                            -0.088666 -0.001649 -0.032849   -0.031003   \n",
       "MVR_PTS                            -0.160044  0.017847 -0.021411   -0.017989   \n",
       "CAR_AGE                            -0.159600 -0.241556  0.198584   -0.018529   \n",
       "Minivan                            -0.041014 -0.028475  0.030280   -0.095146   \n",
       "Panel Truck                        -0.028774 -0.024925 -0.045648   -0.064942   \n",
       "Pickup                              0.011784  0.043623 -0.033537   -0.057403   \n",
       "Sports Car                          0.026762 -0.003783 -0.010382    0.114890   \n",
       "Van                                -0.028003 -0.021361  0.036852   -0.069525   \n",
       "z_SUV                               0.043268  0.020495  0.006239    0.134245   \n",
       "M                                  -0.043460  0.000789 -0.012782   -0.231918   \n",
       "z_F                                 0.043460 -0.000789  0.012782    0.231918   \n",
       "Highly Urban/ Urban                -1.000000 -0.151239  0.096823   -0.108173   \n",
       "z_Highly Rural/ Rural               1.000000  0.151239 -0.096823    0.108173   \n",
       "Clerical                            0.151239  1.000000 -0.083880   -0.133778   \n",
       "Doctor                             -0.096823 -0.083880  1.000000   -0.054572   \n",
       "Home Maker                          0.108173 -0.133778 -0.054572    1.000000   \n",
       "Lawyer                             -0.114259 -0.160098 -0.065309   -0.104158   \n",
       "Manager                            -0.201318 -0.174408 -0.071146   -0.113468   \n",
       "Professional                       -0.042100 -0.185677 -0.075743   -0.120800   \n",
       "Student                             0.099795 -0.141588 -0.057758   -0.092116   \n",
       "z_Blue Collar                       0.048344 -0.257733 -0.105137   -0.167679   \n",
       "<High School                        0.097835  0.237710 -0.080125    0.000897   \n",
       "Bachelors                          -0.036633 -0.122172 -0.117601   -0.007156   \n",
       "Masters                            -0.143069 -0.209221 -0.085348   -0.035171   \n",
       "PhD                                -0.104346 -0.123432  0.679566    0.032741   \n",
       "z_High School                       0.133601  0.171914 -0.123894    0.017291   \n",
       "Commercial                          0.049635 -0.148761 -0.132019   -0.164145   \n",
       "Private                            -0.049635  0.148761  0.132019    0.164145   \n",
       "\n",
       "                         Lawyer   Manager  Professional   Student  \\\n",
       "TARGET_FLAG           -0.060366 -0.120199     -0.042788  0.076003   \n",
       "TARGET_AMT            -0.031817 -0.074727      0.002987  0.021087   \n",
       "KIDSDRIV              -0.038899 -0.021961     -0.024108  0.022554   \n",
       "AGE                    0.151418  0.099144      0.045862 -0.126245   \n",
       "HOMEKIDS              -0.107980 -0.088545     -0.070925  0.126687   \n",
       "YOJ                    0.077372  0.078828      0.083294 -0.333939   \n",
       "INCOME                 0.240779  0.260044      0.177764 -0.372543   \n",
       "PARENT1               -0.049359 -0.033027     -0.012429  0.052551   \n",
       "HOME_VAL               0.146389  0.154237      0.133256 -0.341092   \n",
       "MSTATUS               -0.001798 -0.001543     -0.011044  0.010027   \n",
       "TRAVTIME              -0.030612 -0.069589     -0.002127  0.019837   \n",
       "BLUEBOOK               0.050319  0.127210      0.115670 -0.176101   \n",
       "TIF                   -0.009969  0.011357      0.014144 -0.024620   \n",
       "RED_CAR               -0.018106  0.036393      0.050645  0.025625   \n",
       "OLDCLAIM              -0.015029 -0.006741     -0.007313  0.019358   \n",
       "CLM_FREQ              -0.028937 -0.019183     -0.005158  0.027681   \n",
       "REVOKED                0.021336 -0.006207     -0.003038  0.033112   \n",
       "MVR_PTS               -0.003867 -0.057230      0.009098  0.037251   \n",
       "CAR_AGE                0.389687  0.167005      0.072714 -0.154807   \n",
       "Minivan                0.100157  0.015149      0.017576 -0.037636   \n",
       "Panel Truck           -0.087127  0.093994      0.089586 -0.029560   \n",
       "Pickup                -0.086577 -0.004851     -0.008333  0.066796   \n",
       "Sports Car             0.003043 -0.016844     -0.031459  0.022651   \n",
       "Van                    0.003699  0.011079      0.055289 -0.051975   \n",
       "z_SUV                  0.012255 -0.053624     -0.066986  0.012483   \n",
       "M                     -0.018775  0.050540      0.065809  0.014502   \n",
       "z_F                    0.018775 -0.050540     -0.065809 -0.014502   \n",
       "Highly Urban/ Urban    0.114259  0.201318      0.042100 -0.099795   \n",
       "z_Highly Rural/ Rural -0.114259 -0.201318     -0.042100  0.099795   \n",
       "Clerical              -0.160098 -0.174408     -0.185677 -0.141588   \n",
       "Doctor                -0.065309 -0.071146     -0.075743 -0.057758   \n",
       "Home Maker            -0.104158 -0.113468     -0.120800 -0.092116   \n",
       "Lawyer                 1.000000 -0.135793     -0.144567 -0.110240   \n",
       "Manager               -0.135793  1.000000     -0.157489 -0.120093   \n",
       "Professional          -0.144567 -0.157489      1.000000 -0.127853   \n",
       "Student               -0.110240 -0.120093     -0.127853  1.000000   \n",
       "z_Blue Collar         -0.200669 -0.218605     -0.232731 -0.177469   \n",
       "<High School          -0.152929 -0.163891     -0.172190  0.142148   \n",
       "Bachelors             -0.224459  0.128430      0.302318 -0.077788   \n",
       "Masters                0.690405  0.118462     -0.001673 -0.144065   \n",
       "PhD                    0.016181  0.094027     -0.085398 -0.084993   \n",
       "z_High School         -0.236470 -0.145482     -0.112027  0.129157   \n",
       "Commercial            -0.251978 -0.083417     -0.062776  0.106712   \n",
       "Private                0.251978  0.083417      0.062776 -0.106712   \n",
       "\n",
       "                       z_Blue Collar  <High School  Bachelors   Masters  \\\n",
       "TARGET_FLAG                 0.107181      0.061573  -0.048945 -0.099694   \n",
       "TARGET_AMT                  0.079566      0.040600  -0.013718 -0.057331   \n",
       "KIDSDRIV                    0.042854      0.035724  -0.017986 -0.037772   \n",
       "AGE                        -0.057652     -0.128571  -0.002078  0.175363   \n",
       "HOMEKIDS                    0.039677      0.130558  -0.036632 -0.135442   \n",
       "YOJ                         0.132597     -0.046294   0.022193  0.065280   \n",
       "INCOME                      0.010641     -0.321036   0.116930  0.264049   \n",
       "PARENT1                     0.012687      0.034588   0.008948 -0.070126   \n",
       "HOME_VAL                    0.035762     -0.197523   0.088453  0.165096   \n",
       "MSTATUS                     0.002138      0.014543  -0.025578  0.008562   \n",
       "TRAVTIME                    0.039381      0.023374   0.009310 -0.034250   \n",
       "BLUEBOOK                    0.015118     -0.133144   0.073225  0.085644   \n",
       "TIF                         0.002806      0.000976  -0.008104  0.009939   \n",
       "RED_CAR                     0.032694      0.007935   0.035214 -0.018213   \n",
       "OLDCLAIM                    0.011769      0.009115  -0.007142 -0.012257   \n",
       "CLM_FREQ                    0.029584      0.010679   0.008117 -0.033525   \n",
       "REVOKED                     0.004508     -0.013589  -0.011919  0.004052   \n",
       "MVR_PTS                     0.020018      0.028533   0.001766 -0.036970   \n",
       "CAR_AGE                    -0.231338     -0.344391   0.107948  0.505387   \n",
       "Minivan                    -0.001996     -0.042088   0.005186  0.072960   \n",
       "Panel Truck                 0.018663     -0.024997   0.048881 -0.029733   \n",
       "Pickup                      0.041650      0.066531  -0.011608 -0.079113   \n",
       "Sports Car                 -0.043354      0.007309  -0.024361  0.009002   \n",
       "Van                         0.025226     -0.016808   0.028881  0.000555   \n",
       "z_SUV                      -0.026071      0.004611  -0.020554  0.001340   \n",
       "M                           0.062124      0.016121   0.031515 -0.021388   \n",
       "z_F                        -0.062124     -0.016121  -0.031515  0.021388   \n",
       "Highly Urban/ Urban        -0.048344     -0.097835   0.036633  0.143069   \n",
       "z_Highly Rural/ Rural       0.048344      0.097835  -0.036633 -0.143069   \n",
       "Clerical                   -0.257733      0.237710  -0.122172 -0.209221   \n",
       "Doctor                     -0.105137     -0.080125  -0.117601 -0.085348   \n",
       "Home Maker                 -0.167679      0.000897  -0.007156 -0.035171   \n",
       "Lawyer                     -0.200669     -0.152929  -0.224459  0.690405   \n",
       "Manager                    -0.218605     -0.163891   0.128430  0.118462   \n",
       "Professional               -0.232731     -0.172190   0.302318 -0.001673   \n",
       "Student                    -0.177469      0.142148  -0.077788 -0.144065   \n",
       "z_Blue Collar               1.000000      0.110668   0.029042 -0.259205   \n",
       "<High School                0.110668      1.000000  -0.275379 -0.199853   \n",
       "Bachelors                   0.029042     -0.275379   1.000000 -0.293330   \n",
       "Masters                    -0.259205     -0.199853  -0.293330  1.000000   \n",
       "PhD                        -0.154712     -0.117905  -0.173053 -0.125591   \n",
       "z_High School               0.182324     -0.290116  -0.425811 -0.309028   \n",
       "Commercial                  0.518674     -0.102908   0.113437 -0.236406   \n",
       "Private                    -0.518674      0.102908  -0.113437  0.236406   \n",
       "\n",
       "                            PhD  z_High School  Commercial   Private  \n",
       "TARGET_FLAG           -0.056958       0.112601    0.160423 -0.160423  \n",
       "TARGET_AMT            -0.026361       0.043025    0.104196 -0.104196  \n",
       "KIDSDRIV              -0.035748       0.040103    0.009958 -0.009958  \n",
       "AGE                    0.145360      -0.120499   -0.073692  0.073692  \n",
       "HOMEKIDS              -0.090486       0.093916    0.027309 -0.027309  \n",
       "YOJ                    0.010370      -0.044608    0.006761 -0.006761  \n",
       "INCOME                 0.377145      -0.285222   -0.016378  0.016378  \n",
       "PARENT1               -0.035619       0.041173    0.017964 -0.017964  \n",
       "HOME_VAL               0.180754      -0.165710   -0.024932  0.024932  \n",
       "MSTATUS               -0.041396       0.029220   -0.007751  0.007751  \n",
       "TRAVTIME              -0.026351       0.015068    0.022029 -0.022029  \n",
       "BLUEBOOK               0.133566      -0.110349    0.144139 -0.144139  \n",
       "TIF                   -0.013269       0.006261   -0.003040  0.003040  \n",
       "RED_CAR               -0.027121      -0.010892    0.170955 -0.170955  \n",
       "OLDCLAIM              -0.024036       0.023063    0.028387 -0.028387  \n",
       "CLM_FREQ              -0.010171       0.016785    0.071680 -0.071680  \n",
       "REVOKED               -0.020762       0.030438    0.016219 -0.016219  \n",
       "MVR_PTS               -0.030796       0.023059    0.056993 -0.056993  \n",
       "CAR_AGE                0.286545      -0.406907   -0.163646  0.163646  \n",
       "Minivan                0.015475      -0.040388   -0.169632  0.169632  \n",
       "Panel Truck            0.011402      -0.009933    0.345772 -0.345772  \n",
       "Pickup                -0.038345       0.044994    0.237649 -0.237649  \n",
       "Sports Car            -0.006581       0.014290   -0.114852  0.114852  \n",
       "Van                    0.029561      -0.031682    0.114703 -0.114703  \n",
       "z_SUV                 -0.002661       0.016846   -0.191115  0.191115  \n",
       "M                     -0.034533      -0.007052    0.239076 -0.239076  \n",
       "z_F                    0.034533       0.007052   -0.239076  0.239076  \n",
       "Highly Urban/ Urban    0.104346      -0.133601   -0.049635  0.049635  \n",
       "z_Highly Rural/ Rural -0.104346       0.133601    0.049635 -0.049635  \n",
       "Clerical              -0.123432       0.171914   -0.148761  0.148761  \n",
       "Doctor                 0.679566      -0.123894   -0.132019  0.132019  \n",
       "Home Maker             0.032741       0.017291   -0.164145  0.164145  \n",
       "Lawyer                 0.016181      -0.236470   -0.251978  0.251978  \n",
       "Manager                0.094027      -0.145482   -0.083417  0.083417  \n",
       "Professional          -0.085398      -0.112027   -0.062776  0.062776  \n",
       "Student               -0.084993       0.129157    0.106712 -0.106712  \n",
       "z_Blue Collar         -0.154712       0.182324    0.518674 -0.518674  \n",
       "<High School          -0.117905      -0.290116   -0.102908  0.102908  \n",
       "Bachelors             -0.173053      -0.425811    0.113437 -0.113437  \n",
       "Masters               -0.125591      -0.309028   -0.236406  0.236406  \n",
       "PhD                    1.000000      -0.182314   -0.132147  0.132147  \n",
       "z_High School         -0.182314       1.000000    0.237031 -0.237031  \n",
       "Commercial            -0.132147       0.237031    1.000000 -1.000000  \n",
       "Private                0.132147      -0.237031   -1.000000  1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We begin by a very simple data analysis of correlation\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c7a18",
   "metadata": {},
   "source": [
    "**ABOUT REMOVING TARGET_AMT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a568bc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct FLAG ==1 when amt>0 : 1.0\n",
      "pct FLAG ==1 when amt==0 : 0.0\n",
      "correlation matrix between the TARGET_AMT, and TARGET_FLAG\n"
     ]
    }
   ],
   "source": [
    "val = df.loc[df[\"TARGET_AMT\"]>0][\"TARGET_FLAG\"].mean()\n",
    "val2 = df.loc[df[\"TARGET_AMT\"]<=-0][\"TARGET_FLAG\"].mean()\n",
    "print(f\"pct FLAG ==1 when amt>0 : {val}\")\n",
    "print(f\"pct FLAG ==1 when amt==0 : {val2}\")\n",
    "\n",
    "print(\"correlation matrix between the TARGET_AMT, and TARGET_FLAG\")\n",
    "np.corrcoef((df[\"TARGET_AMT\"]>0).values.astype(np.uint16), df[\"TARGET_FLAG\"].values)\n",
    "\n",
    "df.drop(\"HOMEKIDS\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9a2912",
   "metadata": {},
   "source": [
    "**REMARK** \n",
    "we exclude \"TARGET_AMT\" because of the exhibited correlation and the simple rule that would lead to a almost 100 % accuracy\n",
    "\n",
    "Similarly HOMEKIDS AND KIDSDRIV, we only keep \"KIDSDRIV\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74da34d",
   "metadata": {},
   "source": [
    "## Learning Task and Data Preparation\n",
    "The task we aim at solving is a binary classification task (predicting variable \"Target_Flag\").\n",
    "\n",
    "To do so we access several co-variates that can be divided into two subsets:\n",
    "\n",
    "- Continuous (such as monetary variables)\n",
    "\n",
    "- Binary and leveled variables e.g. SEX, Marital status\n",
    "\n",
    "\n",
    "We begin by converting monetary and continuous variables and normalizing the one that needs to (to avoid numerical problems in LS regression).\n",
    "\n",
    "\n",
    "## Metrics\n",
    "Several options are available here, but we begin by defining our target metrics of interest.\n",
    "\n",
    "First, we consider the confusion matrix that enables to check \"where\" the algorithm fails (false positive or false negatives).\n",
    "\n",
    "Then, we also consider two other metrics:\n",
    "\n",
    "- **recall**:  Tp / (Tp + Fn). It states the amount of detected \"positive\". High recall, we can trust the model when it says negative\n",
    "\n",
    "- **precision**: TP / (Tp + Fp). It accounts for the adequacy of the model when stating Positive. High precision, we can trust the model when it says positive.\n",
    "\n",
    "- **accuracy**: Tp+Tn / total (to detect overfitting)\n",
    "\n",
    "\n",
    "## Method\n",
    "We begin by proposing a first model that serves both simplicity and interpretability purpose:\n",
    "\n",
    "- a logistic regression method\n",
    "\n",
    "Since Ensemble methods are really good for such classification they can be taken a (very) good of the shelf method with minimal tuning.\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87bcda9",
   "metadata": {},
   "source": [
    "## LINEAR MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16cc6b0",
   "metadata": {},
   "source": [
    "We first investigate a linear regression model. The main reason for such investigation is the fact that such models are interpretable, which is great help in risk (and insurance) modeling.\n",
    "We can notice that the dataset is imbalanced (the average number of positive example to predict consitutes only 25% of the data base).\n",
    "\n",
    "### We first investigate a very simple regression model where all variables are considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31245a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one should exclude one reference level for level-variables to avoid colinariy\n",
    "REFERENCE_LEVELS = [\"INDEX\", \"TARGET_FLAG\", \"TARGET_AMT\", \"z_F\", \"Minivan\", \"z_Highly Rural/ Rural\",'z_Blue Collar', '<High School', \"Private\"]\n",
    "EXO_VAR = [x for x in df.columns.values if x not in REFERENCE_LEVELS] \n",
    "\n",
    "Y = df[\"TARGET_FLAG\"].values\n",
    "X = df[EXO_VAR].copy()\n",
    "\n",
    "## CREATE TRAIN TEST VALIDATION SPLIT\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a2d3cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.444706\n",
      "         Iterations 7\n",
      " tn:1279, fp:136, fn:344, tp:236 \n",
      "\n",
      "precision: 0.6344086021505376\n",
      "recall: 0.4068965517241379\n",
      "accuracy: 0.7593984962406015\n"
     ]
    }
   ],
   "source": [
    "clf = sm.Logit(Y_train, X_train).fit(method=\"newton\", maxiter=100)\n",
    "p = clf.predict(X_test) > 0.5\n",
    "modeleval(Y_test, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83efea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tn:2784, fp:244, fn:587, tp:435 \n",
      "\n",
      "precision: 0.6406480117820325\n",
      "recall: 0.42563600782778865\n",
      "accuracy: 0.7948148148148149\n"
     ]
    }
   ],
   "source": [
    "# TO VERIFY OVER-fitting\n",
    "p = clf.predict(X_train) > 0.5\n",
    "modeleval(Y_train, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e31883",
   "metadata": {},
   "source": [
    "**Performance interpretation**\n",
    "\n",
    "The overall accuracy is not too bad. However, this may be due to the imbalance in the dataset.\n",
    "\n",
    "Indeed,\n",
    "\n",
    "- Regarding positive values: the number of true positive value is high, hence a bias in the omdel to predict 0.\n",
    "Consequently, to model tends to predict 0 (even when positive) which leads to a high false negative rate leading to law recall.\n",
    "\n",
    "- Finally, the amount of FP is not too high hence the gap between recall and precision.\n",
    "\n",
    "- We can notice a small overfitting in the model. (higher accuracy in train than test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efadef2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 4050\n",
      "Model:                          Logit   Df Residuals:                     4015\n",
      "Method:                           MLE   Df Model:                           34\n",
      "Date:                Tue, 01 Feb 2022   Pseudo R-squ.:                  0.2128\n",
      "Time:                        11:59:15   Log-Likelihood:                -1801.1\n",
      "converged:                       True   LL-Null:                       -2287.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.941e-182\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "KIDSDRIV                0.3385      0.081      4.159      0.000       0.179       0.498\n",
      "AGE                    -0.0398      0.004     -9.192      0.000      -0.048      -0.031\n",
      "YOJ                    -0.0491      0.011     -4.331      0.000      -0.071      -0.027\n",
      "INCOME                 -0.0940      0.075     -1.256      0.209      -0.241       0.053\n",
      "PARENT1                -0.1342      0.132     -1.016      0.310      -0.393       0.125\n",
      "HOME_VAL               -0.0793      0.063     -1.265      0.206      -0.202       0.044\n",
      "MSTATUS                -0.7834      0.114     -6.843      0.000      -1.008      -0.559\n",
      "TRAVTIME                0.0088      0.003      3.468      0.001       0.004       0.014\n",
      "BLUEBOOK               -0.1294      0.059     -2.184      0.029      -0.246      -0.013\n",
      "TIF                    -0.0644      0.010     -6.172      0.000      -0.085      -0.044\n",
      "RED_CAR                -0.2552      0.127     -2.009      0.045      -0.504      -0.006\n",
      "OLDCLAIM               -0.0778      0.050     -1.565      0.118      -0.175       0.020\n",
      "CLM_FREQ                0.1613      0.041      3.930      0.000       0.081       0.242\n",
      "REVOKED                 0.7038      0.132      5.317      0.000       0.444       0.963\n",
      "MVR_PTS                 0.1100      0.019      5.646      0.000       0.072       0.148\n",
      "CAR_AGE                -0.0183      0.011     -1.702      0.089      -0.039       0.003\n",
      "Panel Truck             0.5703      0.238      2.399      0.016       0.104       1.036\n",
      "Pickup                  0.2749      0.140      1.970      0.049       0.001       0.548\n",
      "Sports Car              0.8424      0.173      4.881      0.000       0.504       1.181\n",
      "Van                     0.3216      0.182      1.771      0.077      -0.034       0.678\n",
      "z_SUV                   0.4242      0.146      2.910      0.004       0.139       0.710\n",
      "M                      -0.0994      0.154     -0.647      0.518      -0.400       0.202\n",
      "Highly Urban/ Urban     1.8611      0.131     14.219      0.000       1.605       2.118\n",
      "Clerical               -0.1101      0.142     -0.775      0.439      -0.389       0.168\n",
      "Doctor                 -0.8659      0.402     -2.156      0.031      -1.653      -0.079\n",
      "Home Maker             -0.6256      0.213     -2.932      0.003      -1.044      -0.207\n",
      "Lawyer                  0.0149      0.263      0.057      0.955      -0.500       0.530\n",
      "Manager                -1.2020      0.204     -5.896      0.000      -1.602      -0.802\n",
      "Professional           -0.3062      0.168     -1.823      0.068      -0.635       0.023\n",
      "Student                -0.5313      0.181     -2.939      0.003      -0.886      -0.177\n",
      "Bachelors              -0.7500      0.162     -4.637      0.000      -1.067      -0.433\n",
      "Masters                -0.6347      0.265     -2.398      0.017      -1.154      -0.116\n",
      "PhD                    -0.2719      0.324     -0.838      0.402      -0.907       0.364\n",
      "z_High School          -0.3888      0.128     -3.042      0.002      -0.639      -0.138\n",
      "Commercial              0.7017      0.130      5.403      0.000       0.447       0.956\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(clf.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca95f388",
   "metadata": {},
   "source": [
    "### **Coefficient Interpretation**\n",
    "\n",
    "For a significant amount of variable, we can reject the null hypothesis with high confidence. \n",
    "\n",
    "For example, \"KIDSDRIV\" has a positive impact on the prediction, increasing the log odds by 0.364.\n",
    "\n",
    "On the other hand, \"MSTATUS\" has a negative impact on prediction decreasing logiodds.\n",
    "\n",
    "Note that a key driver in the prediction is \"Highly Urban/ Urban\" which increase significantly the probability of our model to output 1 along with \"Commercial\" as indicated by our preliminary analysis.\n",
    "\n",
    "However, some variables are highly correlated. And multi-collinearity is known to arm both performances and coefficient interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f8689",
   "metadata": {},
   "source": [
    "### Simplification \n",
    "\n",
    "We can refine the amove method by taking a closer look to the correlation table. First selecting the most correlated variables with our variable of interest, then eliminate redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3c96413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET_FLAG              1.000000\n",
      "TARGET_AMT               0.541242\n",
      "MVR_PTS                  0.230171\n",
      "CLM_FREQ                 0.228004\n",
      "Highly Urban/ Urban      0.226721\n",
      "z_Highly Rural/ Rural    0.226721\n",
      "HOME_VAL                 0.184516\n",
      "PARENT1                  0.162017\n",
      "Commercial               0.160423\n",
      "Private                  0.160423\n",
      "INCOME                   0.148034\n",
      "Minivan                  0.146526\n",
      "REVOKED                  0.142795\n",
      "OLDCLAIM                 0.138721\n",
      "MSTATUS                  0.131525\n",
      "Manager                  0.120199\n",
      "AGE                      0.115274\n",
      "z_High School            0.112601\n",
      "BLUEBOOK                 0.111521\n",
      "CAR_AGE                  0.110253\n",
      "z_Blue Collar            0.107181\n",
      "Masters                  0.099694\n",
      "KIDSDRIV                 0.086933\n",
      "TIF                      0.078885\n",
      "Student                  0.076003\n",
      "YOJ                      0.066429\n",
      "Sports Car               0.064783\n",
      "<High School             0.061573\n",
      "Lawyer                   0.060366\n",
      "Pickup                   0.057460\n",
      "PhD                      0.056958\n",
      "Doctor                   0.054492\n",
      "TRAVTIME                 0.051459\n",
      "Bachelors                0.048945\n",
      "z_SUV                    0.047699\n",
      "Professional             0.042788\n",
      "Clerical                 0.038639\n",
      "RED_CAR                  0.025165\n",
      "M                        0.024006\n",
      "z_F                      0.024006\n",
      "Panel Truck              0.019402\n",
      "Van                      0.010080\n",
      "Home Maker               0.006538\n",
      "Name: TARGET_FLAG, dtype: float64 43\n",
      "['MVR_PTS', 'CLM_FREQ', 'Highly Urban/ Urban', 'HOME_VAL', 'PARENT1', 'Commercial', 'INCOME', 'REVOKED', 'OLDCLAIM', 'MSTATUS', 'Manager', 'AGE', 'z_High School', 'BLUEBOOK', 'CAR_AGE', 'Masters']\n"
     ]
    }
   ],
   "source": [
    "# WE NOW TAKE SIMPLE LOOK AT THE CORRELATION TABLE\n",
    "print(df.corr()[\"TARGET_FLAG\"].abs().sort_values()[::-1], len(df.corr()[\"TARGET_FLAG\"].abs().sort_values()[::-1]))\n",
    "\n",
    "# we take the 20 HIGHEST CORR\n",
    "simple_regression_VAR = df.corr()[\"TARGET_FLAG\"].abs().sort_values()[::-1][2:22].index.values\n",
    "simple_regression_VAR = [x for x in simple_regression_VAR if x not in REFERENCE_LEVELS]\n",
    "print(simple_regression_VAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e4939dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MVR_PTS</th>\n",
       "      <th>CLM_FREQ</th>\n",
       "      <th>Highly Urban/ Urban</th>\n",
       "      <th>HOME_VAL</th>\n",
       "      <th>PARENT1</th>\n",
       "      <th>Commercial</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>REVOKED</th>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <th>MSTATUS</th>\n",
       "      <th>Manager</th>\n",
       "      <th>AGE</th>\n",
       "      <th>z_High School</th>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <th>CAR_AGE</th>\n",
       "      <th>Masters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MVR_PTS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.399165</td>\n",
       "      <td>0.160044</td>\n",
       "      <td>-0.099512</td>\n",
       "      <td>0.078017</td>\n",
       "      <td>0.056993</td>\n",
       "      <td>-0.077280</td>\n",
       "      <td>0.056173</td>\n",
       "      <td>0.274089</td>\n",
       "      <td>-0.059975</td>\n",
       "      <td>-0.057230</td>\n",
       "      <td>-0.078043</td>\n",
       "      <td>0.023059</td>\n",
       "      <td>-0.065272</td>\n",
       "      <td>-0.029007</td>\n",
       "      <td>-0.036970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLM_FREQ</th>\n",
       "      <td>0.399165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.245447</td>\n",
       "      <td>-0.103029</td>\n",
       "      <td>0.058332</td>\n",
       "      <td>0.071680</td>\n",
       "      <td>-0.061672</td>\n",
       "      <td>0.065845</td>\n",
       "      <td>0.495052</td>\n",
       "      <td>-0.076955</td>\n",
       "      <td>-0.019183</td>\n",
       "      <td>-0.030659</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>-0.058051</td>\n",
       "      <td>-0.019161</td>\n",
       "      <td>-0.033525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Highly Urban/ Urban</th>\n",
       "      <td>0.160044</td>\n",
       "      <td>0.245447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106081</td>\n",
       "      <td>-0.007313</td>\n",
       "      <td>-0.049635</td>\n",
       "      <td>0.201310</td>\n",
       "      <td>0.088666</td>\n",
       "      <td>0.152848</td>\n",
       "      <td>-0.006112</td>\n",
       "      <td>0.201318</td>\n",
       "      <td>0.043143</td>\n",
       "      <td>-0.133601</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.143069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOME_VAL</th>\n",
       "      <td>-0.099512</td>\n",
       "      <td>-0.103029</td>\n",
       "      <td>0.106081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.260027</td>\n",
       "      <td>-0.024932</td>\n",
       "      <td>0.581719</td>\n",
       "      <td>-0.045871</td>\n",
       "      <td>-0.060764</td>\n",
       "      <td>0.462668</td>\n",
       "      <td>0.154237</td>\n",
       "      <td>0.215841</td>\n",
       "      <td>-0.165710</td>\n",
       "      <td>0.241906</td>\n",
       "      <td>0.204695</td>\n",
       "      <td>0.165096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARENT1</th>\n",
       "      <td>0.078017</td>\n",
       "      <td>0.058332</td>\n",
       "      <td>-0.007313</td>\n",
       "      <td>-0.260027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>-0.064973</td>\n",
       "      <td>0.046308</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>-0.480884</td>\n",
       "      <td>-0.033027</td>\n",
       "      <td>-0.316694</td>\n",
       "      <td>0.041173</td>\n",
       "      <td>-0.049007</td>\n",
       "      <td>-0.058432</td>\n",
       "      <td>-0.070126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Commercial</th>\n",
       "      <td>0.056993</td>\n",
       "      <td>0.071680</td>\n",
       "      <td>-0.049635</td>\n",
       "      <td>-0.024932</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>0.016219</td>\n",
       "      <td>0.028387</td>\n",
       "      <td>-0.007751</td>\n",
       "      <td>-0.083417</td>\n",
       "      <td>-0.073692</td>\n",
       "      <td>0.237031</td>\n",
       "      <td>0.144139</td>\n",
       "      <td>-0.163646</td>\n",
       "      <td>-0.236406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCOME</th>\n",
       "      <td>-0.077280</td>\n",
       "      <td>-0.061672</td>\n",
       "      <td>0.201310</td>\n",
       "      <td>0.581719</td>\n",
       "      <td>-0.064973</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016505</td>\n",
       "      <td>-0.040746</td>\n",
       "      <td>-0.024963</td>\n",
       "      <td>0.260044</td>\n",
       "      <td>0.183458</td>\n",
       "      <td>-0.285222</td>\n",
       "      <td>0.383451</td>\n",
       "      <td>0.389749</td>\n",
       "      <td>0.264049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REVOKED</th>\n",
       "      <td>0.056173</td>\n",
       "      <td>0.065845</td>\n",
       "      <td>0.088666</td>\n",
       "      <td>-0.045871</td>\n",
       "      <td>0.046308</td>\n",
       "      <td>0.016219</td>\n",
       "      <td>-0.016505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431533</td>\n",
       "      <td>-0.037805</td>\n",
       "      <td>-0.006207</td>\n",
       "      <td>-0.035284</td>\n",
       "      <td>0.030438</td>\n",
       "      <td>-0.021650</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.004052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <td>0.274089</td>\n",
       "      <td>0.495052</td>\n",
       "      <td>0.152848</td>\n",
       "      <td>-0.060764</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>0.028387</td>\n",
       "      <td>-0.040746</td>\n",
       "      <td>0.431533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043221</td>\n",
       "      <td>-0.006741</td>\n",
       "      <td>-0.026570</td>\n",
       "      <td>0.023063</td>\n",
       "      <td>-0.037475</td>\n",
       "      <td>-0.017146</td>\n",
       "      <td>-0.012257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSTATUS</th>\n",
       "      <td>-0.059975</td>\n",
       "      <td>-0.076955</td>\n",
       "      <td>-0.006112</td>\n",
       "      <td>0.462668</td>\n",
       "      <td>-0.480884</td>\n",
       "      <td>-0.007751</td>\n",
       "      <td>-0.024963</td>\n",
       "      <td>-0.037805</td>\n",
       "      <td>-0.043221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001543</td>\n",
       "      <td>0.098247</td>\n",
       "      <td>0.029220</td>\n",
       "      <td>0.014182</td>\n",
       "      <td>-0.029307</td>\n",
       "      <td>0.008562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manager</th>\n",
       "      <td>-0.057230</td>\n",
       "      <td>-0.019183</td>\n",
       "      <td>0.201318</td>\n",
       "      <td>0.154237</td>\n",
       "      <td>-0.033027</td>\n",
       "      <td>-0.083417</td>\n",
       "      <td>0.260044</td>\n",
       "      <td>-0.006207</td>\n",
       "      <td>-0.006741</td>\n",
       "      <td>-0.001543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099144</td>\n",
       "      <td>-0.145482</td>\n",
       "      <td>0.127210</td>\n",
       "      <td>0.167005</td>\n",
       "      <td>0.118462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>-0.078043</td>\n",
       "      <td>-0.030659</td>\n",
       "      <td>0.043143</td>\n",
       "      <td>0.215841</td>\n",
       "      <td>-0.316694</td>\n",
       "      <td>-0.073692</td>\n",
       "      <td>0.183458</td>\n",
       "      <td>-0.035284</td>\n",
       "      <td>-0.026570</td>\n",
       "      <td>0.098247</td>\n",
       "      <td>0.099144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.120499</td>\n",
       "      <td>0.156458</td>\n",
       "      <td>0.190253</td>\n",
       "      <td>0.175363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_High School</th>\n",
       "      <td>0.023059</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>-0.133601</td>\n",
       "      <td>-0.165710</td>\n",
       "      <td>0.041173</td>\n",
       "      <td>0.237031</td>\n",
       "      <td>-0.285222</td>\n",
       "      <td>0.030438</td>\n",
       "      <td>0.023063</td>\n",
       "      <td>0.029220</td>\n",
       "      <td>-0.145482</td>\n",
       "      <td>-0.120499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.110349</td>\n",
       "      <td>-0.406907</td>\n",
       "      <td>-0.309028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLUEBOOK</th>\n",
       "      <td>-0.065272</td>\n",
       "      <td>-0.058051</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.241906</td>\n",
       "      <td>-0.049007</td>\n",
       "      <td>0.144139</td>\n",
       "      <td>0.383451</td>\n",
       "      <td>-0.021650</td>\n",
       "      <td>-0.037475</td>\n",
       "      <td>0.014182</td>\n",
       "      <td>0.127210</td>\n",
       "      <td>0.156458</td>\n",
       "      <td>-0.110349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143979</td>\n",
       "      <td>0.085644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAR_AGE</th>\n",
       "      <td>-0.029007</td>\n",
       "      <td>-0.019161</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.204695</td>\n",
       "      <td>-0.058432</td>\n",
       "      <td>-0.163646</td>\n",
       "      <td>0.389749</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>-0.017146</td>\n",
       "      <td>-0.029307</td>\n",
       "      <td>0.167005</td>\n",
       "      <td>0.190253</td>\n",
       "      <td>-0.406907</td>\n",
       "      <td>0.143979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Masters</th>\n",
       "      <td>-0.036970</td>\n",
       "      <td>-0.033525</td>\n",
       "      <td>0.143069</td>\n",
       "      <td>0.165096</td>\n",
       "      <td>-0.070126</td>\n",
       "      <td>-0.236406</td>\n",
       "      <td>0.264049</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>-0.012257</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>0.118462</td>\n",
       "      <td>0.175363</td>\n",
       "      <td>-0.309028</td>\n",
       "      <td>0.085644</td>\n",
       "      <td>0.505387</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MVR_PTS  CLM_FREQ  Highly Urban/ Urban  HOME_VAL  \\\n",
       "MVR_PTS              1.000000  0.399165             0.160044 -0.099512   \n",
       "CLM_FREQ             0.399165  1.000000             0.245447 -0.103029   \n",
       "Highly Urban/ Urban  0.160044  0.245447             1.000000  0.106081   \n",
       "HOME_VAL            -0.099512 -0.103029             0.106081  1.000000   \n",
       "PARENT1              0.078017  0.058332            -0.007313 -0.260027   \n",
       "Commercial           0.056993  0.071680            -0.049635 -0.024932   \n",
       "INCOME              -0.077280 -0.061672             0.201310  0.581719   \n",
       "REVOKED              0.056173  0.065845             0.088666 -0.045871   \n",
       "OLDCLAIM             0.274089  0.495052             0.152848 -0.060764   \n",
       "MSTATUS             -0.059975 -0.076955            -0.006112  0.462668   \n",
       "Manager             -0.057230 -0.019183             0.201318  0.154237   \n",
       "AGE                 -0.078043 -0.030659             0.043143  0.215841   \n",
       "z_High School        0.023059  0.016785            -0.133601 -0.165710   \n",
       "BLUEBOOK            -0.065272 -0.058051             0.082600  0.241906   \n",
       "CAR_AGE             -0.029007 -0.019161             0.159600  0.204695   \n",
       "Masters             -0.036970 -0.033525             0.143069  0.165096   \n",
       "\n",
       "                      PARENT1  Commercial    INCOME   REVOKED  OLDCLAIM  \\\n",
       "MVR_PTS              0.078017    0.056993 -0.077280  0.056173  0.274089   \n",
       "CLM_FREQ             0.058332    0.071680 -0.061672  0.065845  0.495052   \n",
       "Highly Urban/ Urban -0.007313   -0.049635  0.201310  0.088666  0.152848   \n",
       "HOME_VAL            -0.260027   -0.024932  0.581719 -0.045871 -0.060764   \n",
       "PARENT1              1.000000    0.017964 -0.064973  0.046308  0.034943   \n",
       "Commercial           0.017964    1.000000 -0.016378  0.016219  0.028387   \n",
       "INCOME              -0.064973   -0.016378  1.000000 -0.016505 -0.040746   \n",
       "REVOKED              0.046308    0.016219 -0.016505  1.000000  0.431533   \n",
       "OLDCLAIM             0.034943    0.028387 -0.040746  0.431533  1.000000   \n",
       "MSTATUS             -0.480884   -0.007751 -0.024963 -0.037805 -0.043221   \n",
       "Manager             -0.033027   -0.083417  0.260044 -0.006207 -0.006741   \n",
       "AGE                 -0.316694   -0.073692  0.183458 -0.035284 -0.026570   \n",
       "z_High School        0.041173    0.237031 -0.285222  0.030438  0.023063   \n",
       "BLUEBOOK            -0.049007    0.144139  0.383451 -0.021650 -0.037475   \n",
       "CAR_AGE             -0.058432   -0.163646  0.389749  0.000630 -0.017146   \n",
       "Masters             -0.070126   -0.236406  0.264049  0.004052 -0.012257   \n",
       "\n",
       "                      MSTATUS   Manager       AGE  z_High School  BLUEBOOK  \\\n",
       "MVR_PTS             -0.059975 -0.057230 -0.078043       0.023059 -0.065272   \n",
       "CLM_FREQ            -0.076955 -0.019183 -0.030659       0.016785 -0.058051   \n",
       "Highly Urban/ Urban -0.006112  0.201318  0.043143      -0.133601  0.082600   \n",
       "HOME_VAL             0.462668  0.154237  0.215841      -0.165710  0.241906   \n",
       "PARENT1             -0.480884 -0.033027 -0.316694       0.041173 -0.049007   \n",
       "Commercial          -0.007751 -0.083417 -0.073692       0.237031  0.144139   \n",
       "INCOME              -0.024963  0.260044  0.183458      -0.285222  0.383451   \n",
       "REVOKED             -0.037805 -0.006207 -0.035284       0.030438 -0.021650   \n",
       "OLDCLAIM            -0.043221 -0.006741 -0.026570       0.023063 -0.037475   \n",
       "MSTATUS              1.000000 -0.001543  0.098247       0.029220  0.014182   \n",
       "Manager             -0.001543  1.000000  0.099144      -0.145482  0.127210   \n",
       "AGE                  0.098247  0.099144  1.000000      -0.120499  0.156458   \n",
       "z_High School        0.029220 -0.145482 -0.120499       1.000000 -0.110349   \n",
       "BLUEBOOK             0.014182  0.127210  0.156458      -0.110349  1.000000   \n",
       "CAR_AGE             -0.029307  0.167005  0.190253      -0.406907  0.143979   \n",
       "Masters              0.008562  0.118462  0.175363      -0.309028  0.085644   \n",
       "\n",
       "                      CAR_AGE   Masters  \n",
       "MVR_PTS             -0.029007 -0.036970  \n",
       "CLM_FREQ            -0.019161 -0.033525  \n",
       "Highly Urban/ Urban  0.159600  0.143069  \n",
       "HOME_VAL             0.204695  0.165096  \n",
       "PARENT1             -0.058432 -0.070126  \n",
       "Commercial          -0.163646 -0.236406  \n",
       "INCOME               0.389749  0.264049  \n",
       "REVOKED              0.000630  0.004052  \n",
       "OLDCLAIM            -0.017146 -0.012257  \n",
       "MSTATUS             -0.029307  0.008562  \n",
       "Manager              0.167005  0.118462  \n",
       "AGE                  0.190253  0.175363  \n",
       "z_High School       -0.406907 -0.309028  \n",
       "BLUEBOOK             0.143979  0.085644  \n",
       "CAR_AGE              1.000000  0.505387  \n",
       "Masters              0.505387  1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[simple_regression_VAR].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76715a7f",
   "metadata": {},
   "source": [
    "HOME_VAL is highly correlated with other variable (urban/urban), INCOME, MSTATUS, PARENT1, MANAGER that could lead to instability during training hence we remove it our first simple model.\n",
    "\n",
    "We can have similar observation with MVR_PTS and CLM_FREQ, OLDCLAIM, and to solve this one we sum both variables and create a \"insurance\" variable.\n",
    "\n",
    "Similar with income and home_val.\n",
    "\n",
    "High school is highly correlated with car_age, we remove it and keep car age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23e12497",
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_REMOVE = [\"HOME_VAL\",\"BLUEBOOOK\",\"z_High School\" ,\"CLM_FREQ\", \"MVR_PTS\", \"MSTATUS\", \"REVOKED\", \"HIGH_SCHOOL\", \"INCOME\", \"HOME_VAL\", \"PARENT1\", \"Manager\", \"Masters\"]\n",
    "\n",
    "df[\"insur\"] = df[\"CLM_FREQ\"] + df[\"MVR_PTS\"] + df[\"OLDCLAIM\"] + df[\"REVOKED\"] \n",
    "\n",
    "# - to get all in the same \"direction\"\n",
    "df[\"SOC\"] = df[\"INCOME\"] + df[\"HOME_VAL\"] + df[\"Manager\"] + df[\"MSTATUS\"] - df[\"PARENT1\"]\n",
    "\n",
    "# one should exclude one reference level for level-variables to avoid colinariy\n",
    "SIMPLE_VAR = [x for x in simple_regression_VAR if x not in REFERENCE_LEVELS and x not in TO_REMOVE] + [\"SOC\", \"insur\"]\n",
    "\n",
    "Y = df[\"TARGET_FLAG\"].values\n",
    "X = df[SIMPLE_VAR]\n",
    "\n",
    "## CREATE TRAIN TEST VALIDATION SPLIT: those models do not require cross validation\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "716761ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.480067\n",
      "         Iterations 6\n",
      "\n",
      " \n",
      "\n",
      "---------------\n",
      "\n",
      " in train \n",
      "\n",
      "---------------\n",
      " tn:2824, fp:204, fn:669, tp:353 \n",
      "\n",
      "precision: 0.6337522441651705\n",
      "recall: 0.34540117416829746\n",
      "accuracy: 0.7844444444444445\n",
      "\n",
      " \n",
      "\n",
      "---------------\n",
      "\n",
      " in test \n",
      "\n",
      "---------------\n",
      " tn:1317, fp:98, fn:395, tp:185 \n",
      "\n",
      "precision: 0.6537102473498233\n",
      "recall: 0.31896551724137934\n",
      "accuracy: 0.7528822055137845\n"
     ]
    }
   ],
   "source": [
    "clf = sm.Logit(Y_train, X_train).fit(method=\"newton\", maxiter=100)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n \\n\")\n",
    "print(\"---------------\")\n",
    "print(\"\\n in train \\n\")\n",
    "print(\"---------------\")\n",
    "\n",
    "p = clf.predict(X_train) > 0.5\n",
    "modeleval(Y_train, p)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n \\n\")\n",
    "print(\"---------------\")\n",
    "print(\"\\n in test \\n\")\n",
    "print(\"---------------\")\n",
    "\n",
    "p = clf.predict(X_test) > 0.5\n",
    "modeleval(Y_test, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a091e45",
   "metadata": {},
   "source": [
    "***Performance interpretation***\n",
    "The amount of true neg remained constant while the the number of false negative has increastd. The metric to fight against is the number of false negative values.\n",
    "\n",
    "In order to fight such drawbacks one can try to re-weight the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09d38640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 4050\n",
      "Model:                          Logit   Df Residuals:                     4042\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Tue, 01 Feb 2022   Pseudo R-squ.:                  0.1502\n",
      "Time:                        11:59:15   Log-Likelihood:                -1944.3\n",
      "converged:                       True   LL-Null:                       -2287.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                4.116e-144\n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Highly Urban/ Urban     1.3897      0.113     12.250      0.000       1.167       1.612\n",
      "Commercial              0.6128      0.083      7.417      0.000       0.451       0.775\n",
      "OLDCLAIM               -0.0982      0.048     -2.027      0.043      -0.193      -0.003\n",
      "AGE                    -0.0551      0.003    -20.676      0.000      -0.060      -0.050\n",
      "BLUEBOOK               -0.0882      0.043     -2.031      0.042      -0.173      -0.003\n",
      "CAR_AGE                -0.0373      0.008     -4.892      0.000      -0.052      -0.022\n",
      "SOC                    -0.2114      0.022     -9.621      0.000      -0.254      -0.168\n",
      "insur                   0.1211      0.015      8.172      0.000       0.092       0.150\n",
      "=======================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(clf.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1294c2",
   "metadata": {},
   "source": [
    "The coefficient finds similar interpretation than in the previous case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a56c9b2",
   "metadata": {},
   "source": [
    "A further investigation can consist in the creation of themed variabled for example constructed using a PCA that would limit linear correlation.\n",
    "\n",
    "However, it leads to a reduced interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7517576",
   "metadata": {},
   "source": [
    "## Ensemble Method: \n",
    "\n",
    "Random Forest Classifiers are classical estimator estimating (classif)-trees on portion of the datasets (and portion of the variables) aggregating with a simple voting system with objective to decrease variance in the overall estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eda4031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"TARGET_FLAG\"].values\n",
    "X = df[EXO_VAR]\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.4, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5af03f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation to prevent overfitting which occurs often in RF estimator\n",
    "\n",
    "best = - np.inf\n",
    "params = None, None\n",
    "b_rf = None\n",
    "for depth in np.arange(1, 10, 2):\n",
    "\n",
    "    for n_sample in np.arange(1, 20, 2):\n",
    "\n",
    "        for sample_type in [\"balanced\", \"balanced_subsample\"]:\n",
    "\n",
    "            rf = RFC(min_samples_leaf=n_sample, class_weight=sample_type, max_depth=depth).fit(X_train, Y_train)\n",
    "            sc = rf.score(X_val,Y_val)\n",
    "            if sc > best:\n",
    "                best = sc\n",
    "                params = depth, n_sample, sample_type\n",
    "                b_rf = rf\n",
    "        #print(f\"\\n depth: {depth}, nsample:{n_sample}\")\n",
    "        #print(f\"train error {rf.score(X_train, Y_train)}\")\n",
    "        #print(f\"test error {rf.score(X_test,Y_test)}\")\n",
    "        # easy overfitting with RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e035fd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7456140350877193\n",
      "9 3 balanced\n"
     ]
    }
   ],
   "source": [
    "print(best)\n",
    "depth, n_sample, sample_type = params\n",
    "print(depth, n_sample, sample_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a30b95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "\n",
      "---------------\n",
      "\n",
      " in train \n",
      "\n",
      "---------------\n",
      " tn:2626, fp:402, fn:130, tp:892 \n",
      "\n",
      "precision: 0.6893353941267388\n",
      "recall: 0.87279843444227\n",
      "accuracy: 0.868641975308642\n",
      "\n",
      " \n",
      "\n",
      "---------------\n",
      "\n",
      " in test \n",
      "\n",
      "---------------\n",
      " tn:681, fp:182, fn:126, tp:208 \n",
      "\n",
      "precision: 0.5333333333333333\n",
      "recall: 0.6227544910179641\n",
      "accuracy: 0.7426900584795322\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n \\n\")\n",
    "print(\"---------------\")\n",
    "print(\"\\n in train \\n\")\n",
    "print(\"---------------\")\n",
    "\n",
    "p = b_rf.predict(X_train)\n",
    "modeleval(Y_train,p)\n",
    "\n",
    "\n",
    "print(\"\\n \\n\")\n",
    "print(\"---------------\")\n",
    "print(\"\\n in test \\n\")\n",
    "print(\"---------------\")\n",
    "\n",
    "p = b_rf.predict(X_test)\n",
    "modeleval(Y_test,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22113c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Urban/ Urban\n",
      "OLDCLAIM\n",
      "HOME_VAL\n",
      "INCOME\n",
      "BLUEBOOK\n",
      "TRAVTIME\n",
      "MVR_PTS\n",
      "AGE\n",
      "CLM_FREQ\n",
      "CAR_AGE\n"
     ]
    }
   ],
   "source": [
    "### 10 HIGHEST IMPORTANT VARIABLE IN CLASSIFICATION \n",
    "for i in b_rf.feature_importances_.argsort()[-10:][::-1]:\n",
    "    print(EXO_VAR[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aac2bf",
   "metadata": {},
   "source": [
    "**PERFORMANCE INTERPRETATION**\n",
    "\n",
    "The performance of this classifier is interesting. Yet it has a lower precision that the \"large\" logistic regression by has a much better recall. \n",
    "\n",
    "Moreover, we find that the importance variable match (for most) what was understood in the preliminary analysis\n",
    "\n",
    "\n",
    "Yet this model is prone to overfitting as illustrated by the gap in performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d86f3",
   "metadata": {},
   "source": [
    "## A Gradient Boosting ( Ensemble ) Approach:\n",
    "\n",
    "Gradient boosting algorithm are known to perform very well on such task, since a weak estimator is added each time to correct the in-accurary in the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "383ea006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating: 100-model\n",
      "evaluating: 200-model\n"
     ]
    }
   ],
   "source": [
    "# MODEL ALSO PRONE TO OVERFITTING, CROSS-VALIDATION TO PALLIATE THIS DRAWBACK\n",
    "\n",
    "best = -np.inf\n",
    "params = None, None\n",
    "best_alg = None\n",
    "\n",
    "i=0\n",
    "for nfeat in [\"sqrt\", None]:\n",
    "\n",
    "    for nestim in [50, 100, 150, 200, 300]:\n",
    "        \n",
    "        for sample in [1, 2, 5, 10, 20]:\n",
    "            \n",
    "            for lr in [0.01, 0.1, 0.15, 0.2]:\n",
    "                i+=1\n",
    "                gb = GradientBoostingClassifier(learning_rate=lr,\n",
    "                                                max_features=nfeat,\n",
    "                                                min_samples_leaf=sample,\n",
    "                                                n_estimators=nestim).fit(X_train, Y_train)\n",
    "                if i % 100==0:\n",
    "                    print(f\"evaluating: {i}-model\")\n",
    "\n",
    "                score = gb.score(X_val, Y_val)\n",
    "                if score > best:\n",
    "                    best = score\n",
    "                    params = nfeat, nestim, sample, lr\n",
    "                    b_gb = gb\n",
    "\n",
    "                    print(best, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f76b56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "\n",
      "---------------\n",
      "\n",
      " in train \n",
      "\n",
      "---------------\n",
      " tn:2890, fp:138, fn:461, tp:561 \n",
      "\n",
      "precision: 0.8025751072961373\n",
      "recall: 0.5489236790606654\n",
      "accuracy: 0.8520987654320987\n",
      "\n",
      " \n",
      "\n",
      "---------------\n",
      "\n",
      " in test \n",
      "\n",
      "---------------\n",
      " tn:792, fp:71, fn:192, tp:142 \n",
      "\n",
      "precision: 0.6666666666666666\n",
      "recall: 0.4251497005988024\n",
      "accuracy: 0.7802840434419381\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n \\n\")\n",
    "print(\"---------------\")\n",
    "print(\"\\n in train \\n\")\n",
    "print(\"---------------\")\n",
    "\n",
    "# Despite it good performances, it blatantly overfits \n",
    "p = b_gb.predict(X_train)\n",
    "modeleval(Y_train, p)\n",
    "\n",
    "\n",
    "print(\"\\n \\n\")\n",
    "print(\"---------------\")\n",
    "print(\"\\n in test \\n\")\n",
    "print(\"---------------\")\n",
    "\n",
    "p = b_gb.predict(X_test)\n",
    "modeleval(Y_test, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24968951",
   "metadata": {},
   "source": [
    "The recall precision and overall accuracy are very interesting in this model, yet unlike the logistic regression it is not interpretable. However, it finds the best precision and accuracy and recall comparable to the best in the above.\n",
    "\n",
    "Yet again, the model overfits despite its good performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d32b6568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Urban/ Urban\n",
      "CLM_FREQ\n",
      "MVR_PTS\n",
      "OLDCLAIM\n",
      "AGE\n",
      "INCOME\n",
      "HOME_VAL\n",
      "TRAVTIME\n",
      "Commercial\n",
      "BLUEBOOK\n"
     ]
    }
   ],
   "source": [
    "# 10 HIGHEST IMPORTANT VARIABLE IN CLASSIFICATION \n",
    "for i in b_gb.feature_importances_.argsort()[-10:][::-1]:\n",
    "    print(EXO_VAR[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7557b951",
   "metadata": {},
   "source": [
    "**REMARK**\n",
    "\n",
    "In all presented algorithm, it is perfectly doable to reduce the amount of overfitting. Yet this reduction of overfitting comes at the price of decreased performances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e0f54",
   "metadata": {},
   "source": [
    "### CONCLUSION\n",
    "\n",
    "This insurance data-science project was the opportunity to test the impact of social, insurance, and financial variables on an a Target Flag variable.\n",
    "\n",
    "In conclusion, Logistic-Regression is competitive with more involved traditional Machine Learning approaches as tested here e.g. Random Forest and Gradient Boosting Classifiers.\n",
    "\n",
    "Few main paths may open to obtain better performances:\n",
    "\n",
    "- Features Engineering\n",
    "\n",
    "- the use of another class of classifier involving more flexible features extraction and learning e.g. deep nets (see below but competitive with Gradient boosting algorithms).\n",
    "\n",
    "- Reweighting the database in order to create a balance between recall and precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0c3d42",
   "metadata": {},
   "source": [
    "### Extension A Small DL approach:\n",
    "\n",
    "We can fit a NN to solve this problem. This model is only a POC since several hyperparameters need to be tuned to reach good performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "766ac546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class Ds(Dataset):\n",
    "\n",
    "    def __init__(self, X, Y):\n",
    "        super(Ds, self).__init__()\n",
    "        self.X=X\n",
    "        self.Y=Y\n",
    "        self.len = X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    '''Multilayer Perceptron.'''\n",
    "    \n",
    "    def __init__(self, indim, hidden):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(indim, hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden, hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden, hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden, 1),\n",
    "        nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        return self.layers(x)\n",
    "    \n",
    "def validation(mlp, xval, yval, split=\"valid\"):\n",
    "    print(split)\n",
    "    modeleval((mlp(xval.float()) > 0.5).float(), yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "af794cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "validation\n",
      " tn:539, fp:220, fn:13, tp:26 \n",
      "\n",
      "precision: 0.10569105691056911\n",
      "recall: 0.6666666666666666\n",
      "accuracy: 0.7080200501253133\n",
      "test\n",
      " tn:849, fp:297, fn:14, tp:37 \n",
      "\n",
      "precision: 0.11077844311377245\n",
      "recall: 0.7254901960784313\n",
      "accuracy: 0.7401837928153717\n",
      "Starting epoch 2\n",
      "validation\n",
      " tn:537, fp:217, fn:15, tp:29 \n",
      "\n",
      "precision: 0.11788617886178862\n",
      "recall: 0.6590909090909091\n",
      "accuracy: 0.7092731829573935\n",
      "test\n",
      " tn:847, fp:295, fn:16, tp:39 \n",
      "\n",
      "precision: 0.11676646706586827\n",
      "recall: 0.7090909090909091\n",
      "accuracy: 0.7401837928153717\n",
      "Starting epoch 3\n",
      "validation\n",
      " tn:527, fp:181, fn:25, tp:65 \n",
      "\n",
      "precision: 0.26422764227642276\n",
      "recall: 0.7222222222222222\n",
      "accuracy: 0.7418546365914787\n",
      "test\n",
      " tn:822, fp:249, fn:41, tp:85 \n",
      "\n",
      "precision: 0.25449101796407186\n",
      "recall: 0.6746031746031746\n",
      "accuracy: 0.7577276524644946\n",
      "Starting epoch 4\n",
      "validation\n",
      " tn:525, fp:176, fn:27, tp:70 \n",
      "\n",
      "precision: 0.2845528455284553\n",
      "recall: 0.7216494845360825\n",
      "accuracy: 0.7456140350877193\n",
      "test\n",
      " tn:815, fp:236, fn:48, tp:98 \n",
      "\n",
      "precision: 0.2934131736526946\n",
      "recall: 0.6712328767123288\n",
      "accuracy: 0.7627401837928154\n",
      "Starting epoch 5\n",
      "validation\n",
      " tn:499, fp:137, fn:53, tp:109 \n",
      "\n",
      "precision: 0.44308943089430897\n",
      "recall: 0.6728395061728395\n",
      "accuracy: 0.7619047619047619\n",
      "test\n",
      " tn:778, fp:189, fn:85, tp:145 \n",
      "\n",
      "precision: 0.4341317365269461\n",
      "recall: 0.6304347826086957\n",
      "accuracy: 0.77109440267335\n",
      "Starting epoch 6\n",
      "validation\n",
      " tn:531, fp:180, fn:21, tp:66 \n",
      "\n",
      "precision: 0.2682926829268293\n",
      "recall: 0.7586206896551724\n",
      "accuracy: 0.7481203007518797\n",
      "test\n",
      " tn:825, fp:241, fn:38, tp:93 \n",
      "\n",
      "precision: 0.27844311377245506\n",
      "recall: 0.7099236641221374\n",
      "accuracy: 0.7669172932330827\n",
      "Starting epoch 7\n",
      "validation\n",
      " tn:531, fp:189, fn:21, tp:57 \n",
      "\n",
      "precision: 0.23170731707317074\n",
      "recall: 0.7307692307692307\n",
      "accuracy: 0.7368421052631579\n",
      "test\n",
      " tn:828, fp:250, fn:35, tp:84 \n",
      "\n",
      "precision: 0.25149700598802394\n",
      "recall: 0.7058823529411765\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 8\n",
      "validation\n",
      " tn:536, fp:198, fn:16, tp:48 \n",
      "\n",
      "precision: 0.1951219512195122\n",
      "recall: 0.75\n",
      "accuracy: 0.731829573934837\n",
      "test\n",
      " tn:837, fp:268, fn:26, tp:66 \n",
      "\n",
      "precision: 0.19760479041916168\n",
      "recall: 0.717391304347826\n",
      "accuracy: 0.7543859649122807\n",
      "Starting epoch 9\n",
      "validation\n",
      " tn:478, fp:125, fn:74, tp:121 \n",
      "\n",
      "precision: 0.491869918699187\n",
      "recall: 0.6205128205128205\n",
      "accuracy: 0.7506265664160401\n",
      "test\n",
      " tn:729, fp:148, fn:134, tp:186 \n",
      "\n",
      "precision: 0.5568862275449101\n",
      "recall: 0.58125\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 10\n",
      "validation\n",
      " tn:450, fp:106, fn:102, tp:140 \n",
      "\n",
      "precision: 0.5691056910569106\n",
      "recall: 0.5785123966942148\n",
      "accuracy: 0.7393483709273183\n",
      "test\n",
      " tn:712, fp:135, fn:151, tp:199 \n",
      "\n",
      "precision: 0.5958083832335329\n",
      "recall: 0.5685714285714286\n",
      "accuracy: 0.7610693400167085\n",
      "Starting epoch 11\n",
      "validation\n",
      " tn:508, fp:153, fn:44, tp:93 \n",
      "\n",
      "precision: 0.3780487804878049\n",
      "recall: 0.6788321167883211\n",
      "accuracy: 0.7531328320802005\n",
      "test\n",
      " tn:806, fp:198, fn:57, tp:136 \n",
      "\n",
      "precision: 0.40718562874251496\n",
      "recall: 0.7046632124352331\n",
      "accuracy: 0.7869674185463659\n",
      "Starting epoch 12\n",
      "validation\n",
      " tn:529, fp:175, fn:23, tp:71 \n",
      "\n",
      "precision: 0.2886178861788618\n",
      "recall: 0.7553191489361702\n",
      "accuracy: 0.7518796992481203\n",
      "test\n",
      " tn:826, fp:245, fn:37, tp:89 \n",
      "\n",
      "precision: 0.26646706586826346\n",
      "recall: 0.7063492063492064\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 13\n",
      "validation\n",
      " tn:478, fp:123, fn:74, tp:123 \n",
      "\n",
      "precision: 0.5\n",
      "recall: 0.6243654822335025\n",
      "accuracy: 0.7531328320802005\n",
      "test\n",
      " tn:748, fp:153, fn:115, tp:181 \n",
      "\n",
      "precision: 0.5419161676646707\n",
      "recall: 0.6114864864864865\n",
      "accuracy: 0.7761069340016709\n",
      "Starting epoch 14\n",
      "validation\n",
      " tn:493, fp:128, fn:59, tp:118 \n",
      "\n",
      "precision: 0.4796747967479675\n",
      "recall: 0.6666666666666666\n",
      "accuracy: 0.7656641604010025\n",
      "test\n",
      " tn:772, fp:172, fn:91, tp:162 \n",
      "\n",
      "precision: 0.48502994011976047\n",
      "recall: 0.6403162055335968\n",
      "accuracy: 0.7802840434419381\n",
      "Starting epoch 15\n",
      "validation\n",
      " tn:478, fp:120, fn:74, tp:126 \n",
      "\n",
      "precision: 0.5121951219512195\n",
      "recall: 0.63\n",
      "accuracy: 0.7568922305764411\n",
      "test\n",
      " tn:752, fp:156, fn:111, tp:178 \n",
      "\n",
      "precision: 0.5329341317365269\n",
      "recall: 0.615916955017301\n",
      "accuracy: 0.7769423558897243\n",
      "Starting epoch 16\n",
      "validation\n",
      " tn:447, fp:96, fn:105, tp:150 \n",
      "\n",
      "precision: 0.6097560975609756\n",
      "recall: 0.5882352941176471\n",
      "accuracy: 0.7481203007518797\n",
      "test\n",
      " tn:715, fp:132, fn:148, tp:202 \n",
      "\n",
      "precision: 0.6047904191616766\n",
      "recall: 0.5771428571428572\n",
      "accuracy: 0.7660818713450293\n",
      "Starting epoch 17\n",
      "validation\n",
      " tn:517, fp:150, fn:35, tp:96 \n",
      "\n",
      "precision: 0.3902439024390244\n",
      "recall: 0.732824427480916\n",
      "accuracy: 0.768170426065163\n",
      "test\n",
      " tn:806, fp:207, fn:57, tp:127 \n",
      "\n",
      "precision: 0.38023952095808383\n",
      "recall: 0.6902173913043478\n",
      "accuracy: 0.7794486215538847\n",
      "Starting epoch 18\n",
      "validation\n",
      " tn:499, fp:132, fn:53, tp:114 \n",
      "\n",
      "precision: 0.4634146341463415\n",
      "recall: 0.6826347305389222\n",
      "accuracy: 0.768170426065163\n",
      "test\n",
      " tn:762, fp:172, fn:101, tp:162 \n",
      "\n",
      "precision: 0.48502994011976047\n",
      "recall: 0.6159695817490495\n",
      "accuracy: 0.7719298245614035\n",
      "Starting epoch 19\n",
      "validation\n",
      " tn:508, fp:161, fn:44, tp:85 \n",
      "\n",
      "precision: 0.34552845528455284\n",
      "recall: 0.6589147286821705\n",
      "accuracy: 0.7431077694235589\n",
      "test\n",
      " tn:797, fp:204, fn:66, tp:130 \n",
      "\n",
      "precision: 0.38922155688622756\n",
      "recall: 0.6632653061224489\n",
      "accuracy: 0.7744360902255639\n",
      "Starting epoch 20\n",
      "validation\n",
      " tn:522, fp:166, fn:30, tp:80 \n",
      "\n",
      "precision: 0.3252032520325203\n",
      "recall: 0.7272727272727273\n",
      "accuracy: 0.7543859649122807\n",
      "test\n",
      " tn:813, fp:226, fn:50, tp:108 \n",
      "\n",
      "precision: 0.32335329341317365\n",
      "recall: 0.6835443037974683\n",
      "accuracy: 0.7694235588972431\n",
      "Starting epoch 21\n",
      "validation\n",
      " tn:510, fp:149, fn:42, tp:97 \n",
      "\n",
      "precision: 0.3943089430894309\n",
      "recall: 0.697841726618705\n",
      "accuracy: 0.7606516290726817\n",
      "test\n",
      " tn:796, fp:202, fn:67, tp:132 \n",
      "\n",
      "precision: 0.39520958083832336\n",
      "recall: 0.6633165829145728\n",
      "accuracy: 0.7752715121136173\n",
      "Starting epoch 22\n",
      "validation\n",
      " tn:520, fp:161, fn:32, tp:85 \n",
      "\n",
      "precision: 0.34552845528455284\n",
      "recall: 0.7264957264957265\n",
      "accuracy: 0.7581453634085213\n",
      "test\n",
      " tn:807, fp:210, fn:56, tp:124 \n",
      "\n",
      "precision: 0.3712574850299401\n",
      "recall: 0.6888888888888889\n",
      "accuracy: 0.7777777777777778\n",
      "Starting epoch 23\n",
      "validation\n",
      " tn:518, fp:155, fn:34, tp:91 \n",
      "\n",
      "precision: 0.3699186991869919\n",
      "recall: 0.728\n",
      "accuracy: 0.7631578947368421\n",
      "test\n",
      " tn:794, fp:201, fn:69, tp:133 \n",
      "\n",
      "precision: 0.39820359281437123\n",
      "recall: 0.6584158415841584\n",
      "accuracy: 0.7744360902255639\n",
      "Starting epoch 24\n",
      "validation\n",
      " tn:525, fp:166, fn:27, tp:80 \n",
      "\n",
      "precision: 0.3252032520325203\n",
      "recall: 0.7476635514018691\n",
      "accuracy: 0.7581453634085213\n",
      "test\n",
      " tn:812, fp:228, fn:51, tp:106 \n",
      "\n",
      "precision: 0.31736526946107785\n",
      "recall: 0.6751592356687898\n",
      "accuracy: 0.7669172932330827\n",
      "Starting epoch 25\n",
      "validation\n",
      " tn:493, fp:134, fn:59, tp:112 \n",
      "\n",
      "precision: 0.45528455284552843\n",
      "recall: 0.6549707602339181\n",
      "accuracy: 0.7581453634085213\n",
      "test\n",
      " tn:753, fp:175, fn:110, tp:159 \n",
      "\n",
      "precision: 0.47604790419161674\n",
      "recall: 0.5910780669144982\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 26\n",
      "validation\n",
      " tn:513, fp:165, fn:39, tp:81 \n",
      "\n",
      "precision: 0.32926829268292684\n",
      "recall: 0.675\n",
      "accuracy: 0.7443609022556391\n",
      "test\n",
      " tn:805, fp:216, fn:58, tp:118 \n",
      "\n",
      "precision: 0.3532934131736527\n",
      "recall: 0.6704545454545454\n",
      "accuracy: 0.77109440267335\n",
      "Starting epoch 27\n",
      "validation\n",
      " tn:531, fp:190, fn:21, tp:56 \n",
      "\n",
      "precision: 0.22764227642276422\n",
      "recall: 0.7272727272727273\n",
      "accuracy: 0.7355889724310777\n",
      "test\n",
      " tn:821, fp:245, fn:42, tp:89 \n",
      "\n",
      "precision: 0.26646706586826346\n",
      "recall: 0.6793893129770993\n",
      "accuracy: 0.7602339181286549\n",
      "Starting epoch 28\n",
      "validation\n",
      " tn:491, fp:130, fn:61, tp:116 \n",
      "\n",
      "precision: 0.4715447154471545\n",
      "recall: 0.655367231638418\n",
      "accuracy: 0.7606516290726817\n",
      "test\n",
      " tn:752, fp:168, fn:111, tp:166 \n",
      "\n",
      "precision: 0.49700598802395207\n",
      "recall: 0.5992779783393501\n",
      "accuracy: 0.7669172932330827\n",
      "Starting epoch 29\n",
      "validation\n",
      " tn:493, fp:133, fn:59, tp:113 \n",
      "\n",
      "precision: 0.45934959349593496\n",
      "recall: 0.6569767441860465\n",
      "accuracy: 0.7593984962406015\n",
      "test\n",
      " tn:768, fp:174, fn:95, tp:160 \n",
      "\n",
      "precision: 0.47904191616766467\n",
      "recall: 0.6274509803921569\n",
      "accuracy: 0.7752715121136173\n",
      "Starting epoch 30\n",
      "validation\n",
      " tn:521, fp:166, fn:31, tp:80 \n",
      "\n",
      "precision: 0.3252032520325203\n",
      "recall: 0.7207207207207207\n",
      "accuracy: 0.7531328320802005\n",
      "test\n",
      " tn:805, fp:221, fn:58, tp:113 \n",
      "\n",
      "precision: 0.3383233532934132\n",
      "recall: 0.6608187134502924\n",
      "accuracy: 0.7669172932330827\n"
     ]
    }
   ],
   "source": [
    "## DATASETS\n",
    "dataset = Ds(X_train.values, Y_train)\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "# Initialize the MLP\n",
    "mlp = MLP(X_train.shape[1], 256)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Run the training loop\n",
    "\n",
    "niter = 30\n",
    "\n",
    "for epoch in range(0, niter): # 5 epochs at maximum\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    mlp.train()\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        \n",
    "        inputs = inputs.float()\n",
    "        target = targets.float()\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "        # Loss and optim\n",
    "        loss = loss_function(outputs.view(targets.shape).float(), targets.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mlp.eval()\n",
    "    validation(mlp, torch.tensor(X_val.values).float(), Y_val, \"validation\")\n",
    "    validation(mlp, torch.tensor(X_test.values).float(), Y_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "91a922e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "\n",
      "---------------\n",
      "\n",
      " in train \n",
      "\n",
      "---------------\n",
      " tn:2908, fp:569, fn:120, tp:453 \n",
      "\n",
      "precision: 0.4432485322896282\n",
      "recall: 0.7905759162303665\n",
      "accuracy: 0.8298765432098766\n",
      "\n",
      " \n",
      "\n",
      "---------------\n",
      "\n",
      " in test \n",
      "\n",
      "---------------\n",
      " tn:805, fp:221, fn:58, tp:113 \n",
      "\n",
      "precision: 0.3383233532934132\n",
      "recall: 0.6608187134502924\n",
      "accuracy: 0.7669172932330827\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n \\n\")\n",
    "print(\"---------------\")\n",
    "print(\"\\n in train \\n\")\n",
    "print(\"---------------\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    p = mlp(torch.tensor(X_train.values).float())\n",
    "modeleval((p>0.5).data.float(), Y_train)\n",
    "\n",
    "print(\"\\n \\n\")\n",
    "print(\"---------------\")\n",
    "print(\"\\n in test \\n\")\n",
    "print(\"---------------\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    p = mlp(torch.tensor(X_test.values).float())\n",
    "modeleval((p>0.5).data.float(), Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda056c",
   "metadata": {},
   "source": [
    "We have a higher recall but lower precision than with gradient boosting method. \n",
    "\n",
    "Training was stopped early so as not to overfit too much (see below for a long convergence experiment). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8b71efd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "validation\n",
      " tn:547, fp:239, fn:5, tp:7 \n",
      "\n",
      "precision: 0.028455284552845527\n",
      "recall: 0.5833333333333334\n",
      "accuracy: 0.6942355889724311\n",
      "test\n",
      " tn:856, fp:313, fn:7, tp:21 \n",
      "\n",
      "precision: 0.06287425149700598\n",
      "recall: 0.75\n",
      "accuracy: 0.7326649958228906\n",
      "Starting epoch 2\n",
      "validation\n",
      " tn:546, fp:229, fn:6, tp:17 \n",
      "\n",
      "precision: 0.06910569105691057\n",
      "recall: 0.7391304347826086\n",
      "accuracy: 0.7055137844611529\n",
      "test\n",
      " tn:854, fp:303, fn:9, tp:31 \n",
      "\n",
      "precision: 0.09281437125748503\n",
      "recall: 0.775\n",
      "accuracy: 0.7393483709273183\n",
      "Starting epoch 3\n",
      "validation\n",
      " tn:540, fp:217, fn:12, tp:29 \n",
      "\n",
      "precision: 0.11788617886178862\n",
      "recall: 0.7073170731707317\n",
      "accuracy: 0.7130325814536341\n",
      "test\n",
      " tn:850, fp:295, fn:13, tp:39 \n",
      "\n",
      "precision: 0.11676646706586827\n",
      "recall: 0.75\n",
      "accuracy: 0.7426900584795322\n",
      "Starting epoch 4\n",
      "validation\n",
      " tn:534, fp:206, fn:18, tp:40 \n",
      "\n",
      "precision: 0.16260162601626016\n",
      "recall: 0.6896551724137931\n",
      "accuracy: 0.7192982456140351\n",
      "test\n",
      " tn:842, fp:289, fn:21, tp:45 \n",
      "\n",
      "precision: 0.1347305389221557\n",
      "recall: 0.6818181818181818\n",
      "accuracy: 0.7410192147034252\n",
      "Starting epoch 5\n",
      "validation\n",
      " tn:514, fp:174, fn:38, tp:72 \n",
      "\n",
      "precision: 0.2926829268292683\n",
      "recall: 0.6545454545454545\n",
      "accuracy: 0.7343358395989975\n",
      "test\n",
      " tn:794, fp:228, fn:69, tp:106 \n",
      "\n",
      "precision: 0.31736526946107785\n",
      "recall: 0.6057142857142858\n",
      "accuracy: 0.7518796992481203\n",
      "Starting epoch 6\n",
      "validation\n",
      " tn:482, fp:137, fn:70, tp:109 \n",
      "\n",
      "precision: 0.44308943089430897\n",
      "recall: 0.6089385474860335\n",
      "accuracy: 0.7406015037593985\n",
      "test\n",
      " tn:729, fp:176, fn:134, tp:158 \n",
      "\n",
      "precision: 0.47305389221556887\n",
      "recall: 0.541095890410959\n",
      "accuracy: 0.7410192147034252\n",
      "Starting epoch 7\n",
      "validation\n",
      " tn:534, fp:205, fn:18, tp:41 \n",
      "\n",
      "precision: 0.16666666666666666\n",
      "recall: 0.6949152542372882\n",
      "accuracy: 0.7205513784461153\n",
      "test\n",
      " tn:838, fp:278, fn:25, tp:56 \n",
      "\n",
      "precision: 0.16766467065868262\n",
      "recall: 0.691358024691358\n",
      "accuracy: 0.7468671679197995\n",
      "Starting epoch 8\n",
      "validation\n",
      " tn:514, fp:167, fn:38, tp:79 \n",
      "\n",
      "precision: 0.32113821138211385\n",
      "recall: 0.6752136752136753\n",
      "accuracy: 0.7431077694235589\n",
      "test\n",
      " tn:793, fp:229, fn:70, tp:105 \n",
      "\n",
      "precision: 0.3143712574850299\n",
      "recall: 0.6\n",
      "accuracy: 0.7502088554720133\n",
      "Starting epoch 9\n",
      "validation\n",
      " tn:512, fp:162, fn:40, tp:84 \n",
      "\n",
      "precision: 0.34146341463414637\n",
      "recall: 0.6774193548387096\n",
      "accuracy: 0.7468671679197995\n",
      "test\n",
      " tn:793, fp:222, fn:70, tp:112 \n",
      "\n",
      "precision: 0.33532934131736525\n",
      "recall: 0.6153846153846154\n",
      "accuracy: 0.7560568086883876\n",
      "Starting epoch 10\n",
      "validation\n",
      " tn:533, fp:199, fn:19, tp:47 \n",
      "\n",
      "precision: 0.1910569105691057\n",
      "recall: 0.7121212121212122\n",
      "accuracy: 0.7268170426065163\n",
      "test\n",
      " tn:837, fp:267, fn:26, tp:67 \n",
      "\n",
      "precision: 0.20059880239520958\n",
      "recall: 0.7204301075268817\n",
      "accuracy: 0.7552213868003341\n",
      "Starting epoch 11\n",
      "validation\n",
      " tn:524, fp:188, fn:28, tp:58 \n",
      "\n",
      "precision: 0.23577235772357724\n",
      "recall: 0.6744186046511628\n",
      "accuracy: 0.7293233082706767\n",
      "test\n",
      " tn:826, fp:247, fn:37, tp:87 \n",
      "\n",
      "precision: 0.26047904191616766\n",
      "recall: 0.7016129032258065\n",
      "accuracy: 0.7627401837928154\n",
      "Starting epoch 12\n",
      "validation\n",
      " tn:530, fp:192, fn:22, tp:54 \n",
      "\n",
      "precision: 0.21951219512195122\n",
      "recall: 0.7105263157894737\n",
      "accuracy: 0.731829573934837\n",
      "test\n",
      " tn:833, fp:253, fn:30, tp:81 \n",
      "\n",
      "precision: 0.24251497005988024\n",
      "recall: 0.7297297297297297\n",
      "accuracy: 0.7635756056808688\n",
      "Starting epoch 13\n",
      "validation\n",
      " tn:529, fp:192, fn:23, tp:54 \n",
      "\n",
      "precision: 0.21951219512195122\n",
      "recall: 0.7012987012987013\n",
      "accuracy: 0.7305764411027569\n",
      "test\n",
      " tn:831, fp:253, fn:32, tp:81 \n",
      "\n",
      "precision: 0.24251497005988024\n",
      "recall: 0.7168141592920354\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 14\n",
      "validation\n",
      " tn:533, fp:193, fn:19, tp:53 \n",
      "\n",
      "precision: 0.21544715447154472\n",
      "recall: 0.7361111111111112\n",
      "accuracy: 0.7343358395989975\n",
      "test\n",
      " tn:836, fp:262, fn:27, tp:72 \n",
      "\n",
      "precision: 0.2155688622754491\n",
      "recall: 0.7272727272727273\n",
      "accuracy: 0.758563074352548\n",
      "Starting epoch 15\n",
      "validation\n",
      " tn:527, fp:180, fn:25, tp:66 \n",
      "\n",
      "precision: 0.2682926829268293\n",
      "recall: 0.7252747252747253\n",
      "accuracy: 0.7431077694235589\n",
      "test\n",
      " tn:829, fp:248, fn:34, tp:86 \n",
      "\n",
      "precision: 0.25748502994011974\n",
      "recall: 0.7166666666666667\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 16\n",
      "validation\n",
      " tn:481, fp:114, fn:71, tp:132 \n",
      "\n",
      "precision: 0.5365853658536586\n",
      "recall: 0.6502463054187192\n",
      "accuracy: 0.768170426065163\n",
      "test\n",
      " tn:744, fp:154, fn:119, tp:180 \n",
      "\n",
      "precision: 0.5389221556886228\n",
      "recall: 0.6020066889632107\n",
      "accuracy: 0.7719298245614035\n",
      "Starting epoch 17\n",
      "validation\n",
      " tn:533, fp:192, fn:19, tp:54 \n",
      "\n",
      "precision: 0.21951219512195122\n",
      "recall: 0.7397260273972602\n",
      "accuracy: 0.7355889724310777\n",
      "test\n",
      " tn:836, fp:261, fn:27, tp:73 \n",
      "\n",
      "precision: 0.218562874251497\n",
      "recall: 0.73\n",
      "accuracy: 0.7593984962406015\n",
      "Starting epoch 18\n",
      "validation\n",
      " tn:521, fp:180, fn:31, tp:66 \n",
      "\n",
      "precision: 0.2682926829268293\n",
      "recall: 0.6804123711340206\n",
      "accuracy: 0.7355889724310777\n",
      "test\n",
      " tn:818, fp:234, fn:45, tp:100 \n",
      "\n",
      "precision: 0.2994011976047904\n",
      "recall: 0.6896551724137931\n",
      "accuracy: 0.7669172932330827\n",
      "Starting epoch 19\n",
      "validation\n",
      " tn:507, fp:143, fn:45, tp:103 \n",
      "\n",
      "precision: 0.4186991869918699\n",
      "recall: 0.6959459459459459\n",
      "accuracy: 0.7644110275689223\n",
      "test\n",
      " tn:795, fp:204, fn:68, tp:130 \n",
      "\n",
      "precision: 0.38922155688622756\n",
      "recall: 0.6565656565656566\n",
      "accuracy: 0.772765246449457\n",
      "Starting epoch 20\n",
      "validation\n",
      " tn:523, fp:175, fn:29, tp:71 \n",
      "\n",
      "precision: 0.2886178861788618\n",
      "recall: 0.71\n",
      "accuracy: 0.7443609022556391\n",
      "test\n",
      " tn:824, fp:233, fn:39, tp:101 \n",
      "\n",
      "precision: 0.3023952095808383\n",
      "recall: 0.7214285714285714\n",
      "accuracy: 0.772765246449457\n",
      "Starting epoch 21\n",
      "validation\n",
      " tn:533, fp:192, fn:19, tp:54 \n",
      "\n",
      "precision: 0.21951219512195122\n",
      "recall: 0.7397260273972602\n",
      "accuracy: 0.7355889724310777\n",
      "test\n",
      " tn:834, fp:260, fn:29, tp:74 \n",
      "\n",
      "precision: 0.2215568862275449\n",
      "recall: 0.7184466019417476\n",
      "accuracy: 0.758563074352548\n",
      "Starting epoch 22\n",
      "validation\n",
      " tn:512, fp:172, fn:40, tp:74 \n",
      "\n",
      "precision: 0.3008130081300813\n",
      "recall: 0.6491228070175439\n",
      "accuracy: 0.7343358395989975\n",
      "test\n",
      " tn:811, fp:230, fn:52, tp:104 \n",
      "\n",
      "precision: 0.31137724550898205\n",
      "recall: 0.6666666666666666\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 23\n",
      "validation\n",
      " tn:521, fp:176, fn:31, tp:70 \n",
      "\n",
      "precision: 0.2845528455284553\n",
      "recall: 0.693069306930693\n",
      "accuracy: 0.7406015037593985\n",
      "test\n",
      " tn:816, fp:238, fn:47, tp:96 \n",
      "\n",
      "precision: 0.2874251497005988\n",
      "recall: 0.6713286713286714\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 24\n",
      "validation\n",
      " tn:525, fp:182, fn:27, tp:64 \n",
      "\n",
      "precision: 0.2601626016260163\n",
      "recall: 0.7032967032967034\n",
      "accuracy: 0.7380952380952381\n",
      "test\n",
      " tn:824, fp:242, fn:39, tp:92 \n",
      "\n",
      "precision: 0.2754491017964072\n",
      "recall: 0.7022900763358778\n",
      "accuracy: 0.7652464494569757\n",
      "Starting epoch 25\n",
      "validation\n",
      " tn:494, fp:132, fn:58, tp:114 \n",
      "\n",
      "precision: 0.4634146341463415\n",
      "recall: 0.6627906976744186\n",
      "accuracy: 0.7619047619047619\n",
      "test\n",
      " tn:775, fp:181, fn:88, tp:153 \n",
      "\n",
      "precision: 0.45808383233532934\n",
      "recall: 0.6348547717842323\n",
      "accuracy: 0.7752715121136173\n",
      "Starting epoch 26\n",
      "validation\n",
      " tn:489, fp:124, fn:63, tp:122 \n",
      "\n",
      "precision: 0.4959349593495935\n",
      "recall: 0.6594594594594595\n",
      "accuracy: 0.7656641604010025\n",
      "test\n",
      " tn:770, fp:167, fn:93, tp:167 \n",
      "\n",
      "precision: 0.5\n",
      "recall: 0.6423076923076924\n",
      "accuracy: 0.7827903091060986\n",
      "Starting epoch 27\n",
      "validation\n",
      " tn:496, fp:129, fn:56, tp:117 \n",
      "\n",
      "precision: 0.47560975609756095\n",
      "recall: 0.6763005780346821\n",
      "accuracy: 0.768170426065163\n",
      "test\n",
      " tn:775, fp:178, fn:88, tp:156 \n",
      "\n",
      "precision: 0.46706586826347307\n",
      "recall: 0.639344262295082\n",
      "accuracy: 0.7777777777777778\n",
      "Starting epoch 28\n",
      "validation\n",
      " tn:452, fp:111, fn:100, tp:135 \n",
      "\n",
      "precision: 0.5487804878048781\n",
      "recall: 0.574468085106383\n",
      "accuracy: 0.7355889724310777\n",
      "test\n",
      " tn:712, fp:137, fn:151, tp:197 \n",
      "\n",
      "precision: 0.5898203592814372\n",
      "recall: 0.5660919540229885\n",
      "accuracy: 0.7593984962406015\n",
      "Starting epoch 29\n",
      "validation\n",
      " tn:512, fp:160, fn:40, tp:86 \n",
      "\n",
      "precision: 0.34959349593495936\n",
      "recall: 0.6825396825396826\n",
      "accuracy: 0.7493734335839599\n",
      "test\n",
      " tn:805, fp:222, fn:58, tp:112 \n",
      "\n",
      "precision: 0.33532934131736525\n",
      "recall: 0.6588235294117647\n",
      "accuracy: 0.7660818713450293\n",
      "Starting epoch 30\n",
      "validation\n",
      " tn:512, fp:156, fn:40, tp:90 \n",
      "\n",
      "precision: 0.36585365853658536\n",
      "recall: 0.6923076923076923\n",
      "accuracy: 0.7543859649122807\n",
      "test\n",
      " tn:806, fp:220, fn:57, tp:114 \n",
      "\n",
      "precision: 0.3413173652694611\n",
      "recall: 0.6666666666666666\n",
      "accuracy: 0.7685881370091896\n",
      "Starting epoch 31\n",
      "validation\n",
      " tn:520, fp:163, fn:32, tp:83 \n",
      "\n",
      "precision: 0.33739837398373984\n",
      "recall: 0.7217391304347827\n",
      "accuracy: 0.7556390977443609\n",
      "test\n",
      " tn:816, fp:235, fn:47, tp:99 \n",
      "\n",
      "precision: 0.2964071856287425\n",
      "recall: 0.678082191780822\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      " tn:469, fp:113, fn:83, tp:133 \n",
      "\n",
      "precision: 0.540650406504065\n",
      "recall: 0.6157407407407407\n",
      "accuracy: 0.7543859649122807\n",
      "test\n",
      " tn:731, fp:153, fn:132, tp:181 \n",
      "\n",
      "precision: 0.5419161676646707\n",
      "recall: 0.5782747603833865\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 33\n",
      "validation\n",
      " tn:488, fp:128, fn:64, tp:118 \n",
      "\n",
      "precision: 0.4796747967479675\n",
      "recall: 0.6483516483516484\n",
      "accuracy: 0.7593984962406015\n",
      "test\n",
      " tn:780, fp:175, fn:83, tp:159 \n",
      "\n",
      "precision: 0.47604790419161674\n",
      "recall: 0.6570247933884298\n",
      "accuracy: 0.7844611528822055\n",
      "Starting epoch 34\n",
      "validation\n",
      " tn:514, fp:163, fn:38, tp:83 \n",
      "\n",
      "precision: 0.33739837398373984\n",
      "recall: 0.6859504132231405\n",
      "accuracy: 0.7481203007518797\n",
      "test\n",
      " tn:814, fp:223, fn:49, tp:111 \n",
      "\n",
      "precision: 0.3323353293413174\n",
      "recall: 0.69375\n",
      "accuracy: 0.772765246449457\n",
      "Starting epoch 35\n",
      "validation\n",
      " tn:534, fp:188, fn:18, tp:58 \n",
      "\n",
      "precision: 0.23577235772357724\n",
      "recall: 0.7631578947368421\n",
      "accuracy: 0.7418546365914787\n",
      "test\n",
      " tn:837, fp:258, fn:26, tp:76 \n",
      "\n",
      "precision: 0.2275449101796407\n",
      "recall: 0.7450980392156863\n",
      "accuracy: 0.7627401837928154\n",
      "Starting epoch 36\n",
      "validation\n",
      " tn:512, fp:158, fn:40, tp:88 \n",
      "\n",
      "precision: 0.35772357723577236\n",
      "recall: 0.6875\n",
      "accuracy: 0.7518796992481203\n",
      "test\n",
      " tn:804, fp:216, fn:59, tp:118 \n",
      "\n",
      "precision: 0.3532934131736527\n",
      "recall: 0.6666666666666666\n",
      "accuracy: 0.7702589807852965\n",
      "Starting epoch 37\n",
      "validation\n",
      " tn:509, fp:148, fn:43, tp:98 \n",
      "\n",
      "precision: 0.3983739837398374\n",
      "recall: 0.6950354609929078\n",
      "accuracy: 0.7606516290726817\n",
      "test\n",
      " tn:800, fp:207, fn:63, tp:127 \n",
      "\n",
      "precision: 0.38023952095808383\n",
      "recall: 0.6684210526315789\n",
      "accuracy: 0.7744360902255639\n",
      "Starting epoch 38\n",
      "validation\n",
      " tn:459, fp:114, fn:93, tp:132 \n",
      "\n",
      "precision: 0.5365853658536586\n",
      "recall: 0.5866666666666667\n",
      "accuracy: 0.7406015037593985\n",
      "test\n",
      " tn:723, fp:149, fn:140, tp:185 \n",
      "\n",
      "precision: 0.5538922155688623\n",
      "recall: 0.5692307692307692\n",
      "accuracy: 0.758563074352548\n",
      "Starting epoch 39\n",
      "validation\n",
      " tn:467, fp:116, fn:85, tp:130 \n",
      "\n",
      "precision: 0.5284552845528455\n",
      "recall: 0.6046511627906976\n",
      "accuracy: 0.7481203007518797\n",
      "test\n",
      " tn:739, fp:149, fn:124, tp:185 \n",
      "\n",
      "precision: 0.5538922155688623\n",
      "recall: 0.598705501618123\n",
      "accuracy: 0.7719298245614035\n",
      "Starting epoch 40\n",
      "validation\n",
      " tn:486, fp:126, fn:66, tp:120 \n",
      "\n",
      "precision: 0.4878048780487805\n",
      "recall: 0.6451612903225806\n",
      "accuracy: 0.7593984962406015\n",
      "test\n",
      " tn:758, fp:168, fn:105, tp:166 \n",
      "\n",
      "precision: 0.49700598802395207\n",
      "recall: 0.6125461254612546\n",
      "accuracy: 0.7719298245614035\n",
      "Starting epoch 41\n",
      "validation\n",
      " tn:505, fp:143, fn:47, tp:103 \n",
      "\n",
      "precision: 0.4186991869918699\n",
      "recall: 0.6866666666666666\n",
      "accuracy: 0.7619047619047619\n",
      "test\n",
      " tn:795, fp:200, fn:68, tp:134 \n",
      "\n",
      "precision: 0.40119760479041916\n",
      "recall: 0.6633663366336634\n",
      "accuracy: 0.7761069340016709\n",
      "Starting epoch 42\n",
      "validation\n",
      " tn:506, fp:147, fn:46, tp:99 \n",
      "\n",
      "precision: 0.4024390243902439\n",
      "recall: 0.6827586206896552\n",
      "accuracy: 0.7581453634085213\n",
      "test\n",
      " tn:801, fp:201, fn:62, tp:133 \n",
      "\n",
      "precision: 0.39820359281437123\n",
      "recall: 0.6820512820512821\n",
      "accuracy: 0.7802840434419381\n",
      "Starting epoch 43\n",
      "validation\n",
      " tn:451, fp:104, fn:101, tp:142 \n",
      "\n",
      "precision: 0.5772357723577236\n",
      "recall: 0.5843621399176955\n",
      "accuracy: 0.7431077694235589\n",
      "test\n",
      " tn:699, fp:132, fn:164, tp:202 \n",
      "\n",
      "precision: 0.6047904191616766\n",
      "recall: 0.5519125683060109\n",
      "accuracy: 0.7527151211361738\n",
      "Starting epoch 44\n",
      "validation\n",
      " tn:470, fp:115, fn:82, tp:131 \n",
      "\n",
      "precision: 0.532520325203252\n",
      "recall: 0.6150234741784038\n",
      "accuracy: 0.7531328320802005\n",
      "test\n",
      " tn:740, fp:153, fn:123, tp:181 \n",
      "\n",
      "precision: 0.5419161676646707\n",
      "recall: 0.5953947368421053\n",
      "accuracy: 0.7694235588972431\n",
      "Starting epoch 45\n",
      "validation\n",
      " tn:536, fp:202, fn:16, tp:44 \n",
      "\n",
      "precision: 0.17886178861788618\n",
      "recall: 0.7333333333333333\n",
      "accuracy: 0.7268170426065163\n",
      "test\n",
      " tn:844, fp:273, fn:19, tp:61 \n",
      "\n",
      "precision: 0.18263473053892215\n",
      "recall: 0.7625\n",
      "accuracy: 0.7560568086883876\n",
      "Starting epoch 46\n",
      "validation\n",
      " tn:461, fp:109, fn:91, tp:137 \n",
      "\n",
      "precision: 0.556910569105691\n",
      "recall: 0.6008771929824561\n",
      "accuracy: 0.7493734335839599\n",
      "test\n",
      " tn:722, fp:143, fn:141, tp:191 \n",
      "\n",
      "precision: 0.5718562874251497\n",
      "recall: 0.5753012048192772\n",
      "accuracy: 0.7627401837928154\n",
      "Starting epoch 47\n",
      "validation\n",
      " tn:435, fp:99, fn:117, tp:147 \n",
      "\n",
      "precision: 0.5975609756097561\n",
      "recall: 0.5568181818181818\n",
      "accuracy: 0.7293233082706767\n",
      "test\n",
      " tn:683, fp:124, fn:180, tp:210 \n",
      "\n",
      "precision: 0.6287425149700598\n",
      "recall: 0.5384615384615384\n",
      "accuracy: 0.746031746031746\n",
      "Starting epoch 48\n",
      "validation\n",
      " tn:513, fp:157, fn:39, tp:89 \n",
      "\n",
      "precision: 0.3617886178861789\n",
      "recall: 0.6953125\n",
      "accuracy: 0.7543859649122807\n",
      "test\n",
      " tn:808, fp:219, fn:55, tp:115 \n",
      "\n",
      "precision: 0.344311377245509\n",
      "recall: 0.6764705882352942\n",
      "accuracy: 0.77109440267335\n",
      "Starting epoch 49\n",
      "validation\n",
      " tn:473, fp:122, fn:79, tp:124 \n",
      "\n",
      "precision: 0.5040650406504065\n",
      "recall: 0.6108374384236454\n",
      "accuracy: 0.7481203007518797\n",
      "test\n",
      " tn:744, fp:153, fn:119, tp:181 \n",
      "\n",
      "precision: 0.5419161676646707\n",
      "recall: 0.6033333333333334\n",
      "accuracy: 0.772765246449457\n",
      "Starting epoch 50\n",
      "validation\n",
      " tn:510, fp:155, fn:42, tp:91 \n",
      "\n",
      "precision: 0.3699186991869919\n",
      "recall: 0.6842105263157895\n",
      "accuracy: 0.7531328320802005\n",
      "test\n",
      " tn:807, fp:218, fn:56, tp:116 \n",
      "\n",
      "precision: 0.3473053892215569\n",
      "recall: 0.6744186046511628\n",
      "accuracy: 0.77109440267335\n",
      "Starting epoch 51\n",
      "validation\n",
      " tn:527, fp:188, fn:25, tp:58 \n",
      "\n",
      "precision: 0.23577235772357724\n",
      "recall: 0.6987951807228916\n",
      "accuracy: 0.7330827067669173\n",
      "test\n",
      " tn:822, fp:249, fn:41, tp:85 \n",
      "\n",
      "precision: 0.25449101796407186\n",
      "recall: 0.6746031746031746\n",
      "accuracy: 0.7577276524644946\n",
      "Starting epoch 52\n",
      "validation\n",
      " tn:495, fp:137, fn:57, tp:109 \n",
      "\n",
      "precision: 0.44308943089430897\n",
      "recall: 0.6566265060240963\n",
      "accuracy: 0.7568922305764411\n",
      "test\n",
      " tn:775, fp:179, fn:88, tp:155 \n",
      "\n",
      "precision: 0.46407185628742514\n",
      "recall: 0.6378600823045267\n",
      "accuracy: 0.7769423558897243\n",
      "Starting epoch 53\n",
      "validation\n",
      " tn:433, fp:96, fn:119, tp:150 \n",
      "\n",
      "precision: 0.6097560975609756\n",
      "recall: 0.5576208178438662\n",
      "accuracy: 0.7305764411027569\n",
      "test\n",
      " tn:675, fp:116, fn:188, tp:218 \n",
      "\n",
      "precision: 0.6526946107784432\n",
      "recall: 0.5369458128078818\n",
      "accuracy: 0.746031746031746\n",
      "Starting epoch 54\n",
      "validation\n",
      " tn:492, fp:133, fn:60, tp:113 \n",
      "\n",
      "precision: 0.45934959349593496\n",
      "recall: 0.653179190751445\n",
      "accuracy: 0.7581453634085213\n",
      "test\n",
      " tn:773, fp:173, fn:90, tp:161 \n",
      "\n",
      "precision: 0.4820359281437126\n",
      "recall: 0.6414342629482072\n",
      "accuracy: 0.7802840434419381\n",
      "Starting epoch 55\n",
      "validation\n",
      " tn:487, fp:132, fn:65, tp:114 \n",
      "\n",
      "precision: 0.4634146341463415\n",
      "recall: 0.6368715083798883\n",
      "accuracy: 0.7531328320802005\n",
      "test\n",
      " tn:770, fp:167, fn:93, tp:167 \n",
      "\n",
      "precision: 0.5\n",
      "recall: 0.6423076923076924\n",
      "accuracy: 0.7827903091060986\n",
      "Starting epoch 56\n",
      "validation\n",
      " tn:520, fp:163, fn:32, tp:83 \n",
      "\n",
      "precision: 0.33739837398373984\n",
      "recall: 0.7217391304347827\n",
      "accuracy: 0.7556390977443609\n",
      "test\n",
      " tn:808, fp:220, fn:55, tp:114 \n",
      "\n",
      "precision: 0.3413173652694611\n",
      "recall: 0.6745562130177515\n",
      "accuracy: 0.7702589807852965\n",
      "Starting epoch 57\n",
      "validation\n",
      " tn:484, fp:132, fn:68, tp:114 \n",
      "\n",
      "precision: 0.4634146341463415\n",
      "recall: 0.6263736263736264\n",
      "accuracy: 0.7493734335839599\n",
      "test\n",
      " tn:765, fp:167, fn:98, tp:167 \n",
      "\n",
      "precision: 0.5\n",
      "recall: 0.630188679245283\n",
      "accuracy: 0.7786131996658312\n",
      "Starting epoch 58\n",
      "validation\n",
      " tn:519, fp:171, fn:33, tp:75 \n",
      "\n",
      "precision: 0.3048780487804878\n",
      "recall: 0.6944444444444444\n",
      "accuracy: 0.7443609022556391\n",
      "test\n",
      " tn:821, fp:229, fn:42, tp:105 \n",
      "\n",
      "precision: 0.3143712574850299\n",
      "recall: 0.7142857142857143\n",
      "accuracy: 0.7736006683375104\n",
      "Starting epoch 59\n",
      "validation\n",
      " tn:496, fp:138, fn:56, tp:108 \n",
      "\n",
      "precision: 0.43902439024390244\n",
      "recall: 0.6585365853658537\n",
      "accuracy: 0.7568922305764411\n",
      "test\n",
      " tn:776, fp:176, fn:87, tp:158 \n",
      "\n",
      "precision: 0.47305389221556887\n",
      "recall: 0.6448979591836734\n",
      "accuracy: 0.7802840434419381\n",
      "Starting epoch 60\n",
      "validation\n",
      " tn:511, fp:154, fn:41, tp:92 \n",
      "\n",
      "precision: 0.37398373983739835\n",
      "recall: 0.6917293233082706\n",
      "accuracy: 0.7556390977443609\n",
      "test\n",
      " tn:791, fp:204, fn:72, tp:130 \n",
      "\n",
      "precision: 0.38922155688622756\n",
      "recall: 0.6435643564356436\n",
      "accuracy: 0.7694235588972431\n",
      "Starting epoch 61\n",
      "validation\n",
      " tn:504, fp:145, fn:48, tp:101 \n",
      "\n",
      "precision: 0.4105691056910569\n",
      "recall: 0.6778523489932886\n",
      "accuracy: 0.7581453634085213\n",
      "test\n",
      " tn:792, fp:189, fn:71, tp:145 \n",
      "\n",
      "precision: 0.4341317365269461\n",
      "recall: 0.6712962962962963\n",
      "accuracy: 0.7827903091060986\n",
      "Starting epoch 62\n",
      "validation\n",
      " tn:438, fp:100, fn:114, tp:146 \n",
      "\n",
      "precision: 0.5934959349593496\n",
      "recall: 0.5615384615384615\n",
      "accuracy: 0.731829573934837\n",
      "test\n",
      " tn:687, fp:122, fn:176, tp:212 \n",
      "\n",
      "precision: 0.6347305389221557\n",
      "recall: 0.5463917525773195\n",
      "accuracy: 0.7510442773600668\n",
      "Starting epoch 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      " tn:440, fp:96, fn:112, tp:150 \n",
      "\n",
      "precision: 0.6097560975609756\n",
      "recall: 0.5725190839694656\n",
      "accuracy: 0.7393483709273183\n",
      "test\n",
      " tn:692, fp:131, fn:171, tp:203 \n",
      "\n",
      "precision: 0.6077844311377245\n",
      "recall: 0.5427807486631016\n",
      "accuracy: 0.747702589807853\n",
      "Starting epoch 64\n",
      "validation\n",
      " tn:519, fp:169, fn:33, tp:77 \n",
      "\n",
      "precision: 0.3130081300813008\n",
      "recall: 0.7\n",
      "accuracy: 0.7468671679197995\n",
      "test\n",
      " tn:810, fp:228, fn:53, tp:106 \n",
      "\n",
      "precision: 0.31736526946107785\n",
      "recall: 0.6666666666666666\n",
      "accuracy: 0.7652464494569757\n",
      "Starting epoch 65\n",
      "validation\n",
      " tn:521, fp:176, fn:31, tp:70 \n",
      "\n",
      "precision: 0.2845528455284553\n",
      "recall: 0.693069306930693\n",
      "accuracy: 0.7406015037593985\n",
      "test\n",
      " tn:822, fp:237, fn:41, tp:97 \n",
      "\n",
      "precision: 0.2904191616766467\n",
      "recall: 0.7028985507246377\n",
      "accuracy: 0.7677527151211362\n",
      "Starting epoch 66\n",
      "validation\n",
      " tn:492, fp:144, fn:60, tp:102 \n",
      "\n",
      "precision: 0.4146341463414634\n",
      "recall: 0.6296296296296297\n",
      "accuracy: 0.7443609022556391\n",
      "test\n",
      " tn:765, fp:174, fn:98, tp:160 \n",
      "\n",
      "precision: 0.47904191616766467\n",
      "recall: 0.6201550387596899\n",
      "accuracy: 0.772765246449457\n",
      "Starting epoch 67\n",
      "validation\n",
      " tn:513, fp:161, fn:39, tp:85 \n",
      "\n",
      "precision: 0.34552845528455284\n",
      "recall: 0.6854838709677419\n",
      "accuracy: 0.7493734335839599\n",
      "test\n",
      " tn:804, fp:216, fn:59, tp:118 \n",
      "\n",
      "precision: 0.3532934131736527\n",
      "recall: 0.6666666666666666\n",
      "accuracy: 0.7702589807852965\n",
      "Starting epoch 68\n",
      "validation\n",
      " tn:503, fp:150, fn:49, tp:96 \n",
      "\n",
      "precision: 0.3902439024390244\n",
      "recall: 0.6620689655172414\n",
      "accuracy: 0.7506265664160401\n",
      "test\n",
      " tn:794, fp:205, fn:69, tp:129 \n",
      "\n",
      "precision: 0.38622754491017963\n",
      "recall: 0.6515151515151515\n",
      "accuracy: 0.77109440267335\n",
      "Starting epoch 69\n",
      "validation\n",
      " tn:480, fp:125, fn:72, tp:121 \n",
      "\n",
      "precision: 0.491869918699187\n",
      "recall: 0.6269430051813472\n",
      "accuracy: 0.7531328320802005\n",
      "test\n",
      " tn:749, fp:157, fn:114, tp:177 \n",
      "\n",
      "precision: 0.5299401197604791\n",
      "recall: 0.6082474226804123\n",
      "accuracy: 0.7736006683375104\n",
      "Starting epoch 70\n",
      "validation\n",
      " tn:445, fp:104, fn:107, tp:142 \n",
      "\n",
      "precision: 0.5772357723577236\n",
      "recall: 0.570281124497992\n",
      "accuracy: 0.7355889724310777\n",
      "test\n",
      " tn:703, fp:126, fn:160, tp:208 \n",
      "\n",
      "precision: 0.6227544910179641\n",
      "recall: 0.5652173913043478\n",
      "accuracy: 0.7610693400167085\n",
      "Starting epoch 71\n",
      "validation\n",
      " tn:470, fp:125, fn:82, tp:121 \n",
      "\n",
      "precision: 0.491869918699187\n",
      "recall: 0.5960591133004927\n",
      "accuracy: 0.7406015037593985\n",
      "test\n",
      " tn:752, fp:161, fn:111, tp:173 \n",
      "\n",
      "precision: 0.5179640718562875\n",
      "recall: 0.6091549295774648\n",
      "accuracy: 0.772765246449457\n",
      "Starting epoch 72\n",
      "validation\n",
      " tn:536, fp:205, fn:16, tp:41 \n",
      "\n",
      "precision: 0.16666666666666666\n",
      "recall: 0.7192982456140351\n",
      "accuracy: 0.7230576441102757\n",
      "test\n",
      " tn:842, fp:276, fn:21, tp:58 \n",
      "\n",
      "precision: 0.17365269461077845\n",
      "recall: 0.7341772151898734\n",
      "accuracy: 0.7518796992481203\n",
      "Starting epoch 73\n",
      "validation\n",
      " tn:513, fp:162, fn:39, tp:84 \n",
      "\n",
      "precision: 0.34146341463414637\n",
      "recall: 0.6829268292682927\n",
      "accuracy: 0.7481203007518797\n",
      "test\n",
      " tn:800, fp:209, fn:63, tp:125 \n",
      "\n",
      "precision: 0.37425149700598803\n",
      "recall: 0.6648936170212766\n",
      "accuracy: 0.772765246449457\n",
      "Starting epoch 74\n",
      "validation\n",
      " tn:508, fp:160, fn:44, tp:86 \n",
      "\n",
      "precision: 0.34959349593495936\n",
      "recall: 0.6615384615384615\n",
      "accuracy: 0.7443609022556391\n",
      "test\n",
      " tn:790, fp:201, fn:73, tp:133 \n",
      "\n",
      "precision: 0.39820359281437123\n",
      "recall: 0.6456310679611651\n",
      "accuracy: 0.77109440267335\n",
      "Starting epoch 75\n",
      "validation\n",
      " tn:506, fp:151, fn:46, tp:95 \n",
      "\n",
      "precision: 0.3861788617886179\n",
      "recall: 0.6737588652482269\n",
      "accuracy: 0.7531328320802005\n",
      "test\n",
      " tn:783, fp:194, fn:80, tp:140 \n",
      "\n",
      "precision: 0.41916167664670656\n",
      "recall: 0.6363636363636364\n",
      "accuracy: 0.77109440267335\n",
      "Starting epoch 76\n",
      "validation\n",
      " tn:489, fp:135, fn:63, tp:111 \n",
      "\n",
      "precision: 0.45121951219512196\n",
      "recall: 0.6379310344827587\n",
      "accuracy: 0.7518796992481203\n",
      "test\n",
      " tn:766, fp:174, fn:97, tp:160 \n",
      "\n",
      "precision: 0.47904191616766467\n",
      "recall: 0.622568093385214\n",
      "accuracy: 0.7736006683375104\n",
      "Starting epoch 77\n",
      "validation\n",
      " tn:529, fp:185, fn:23, tp:61 \n",
      "\n",
      "precision: 0.24796747967479674\n",
      "recall: 0.7261904761904762\n",
      "accuracy: 0.7393483709273183\n",
      "test\n",
      " tn:825, fp:239, fn:38, tp:95 \n",
      "\n",
      "precision: 0.2844311377245509\n",
      "recall: 0.7142857142857143\n",
      "accuracy: 0.7685881370091896\n",
      "Starting epoch 78\n",
      "validation\n",
      " tn:509, fp:156, fn:43, tp:90 \n",
      "\n",
      "precision: 0.36585365853658536\n",
      "recall: 0.6766917293233082\n",
      "accuracy: 0.7506265664160401\n",
      "test\n",
      " tn:794, fp:201, fn:69, tp:133 \n",
      "\n",
      "precision: 0.39820359281437123\n",
      "recall: 0.6584158415841584\n",
      "accuracy: 0.7744360902255639\n",
      "Starting epoch 79\n",
      "validation\n",
      " tn:494, fp:138, fn:58, tp:108 \n",
      "\n",
      "precision: 0.43902439024390244\n",
      "recall: 0.6506024096385542\n",
      "accuracy: 0.7543859649122807\n",
      "test\n",
      " tn:773, fp:180, fn:90, tp:154 \n",
      "\n",
      "precision: 0.46107784431137727\n",
      "recall: 0.6311475409836066\n",
      "accuracy: 0.7744360902255639\n",
      "Starting epoch 80\n",
      "validation\n",
      " tn:517, fp:168, fn:35, tp:78 \n",
      "\n",
      "precision: 0.3170731707317073\n",
      "recall: 0.6902654867256637\n",
      "accuracy: 0.7456140350877193\n",
      "test\n",
      " tn:816, fp:228, fn:47, tp:106 \n",
      "\n",
      "precision: 0.31736526946107785\n",
      "recall: 0.6928104575163399\n",
      "accuracy: 0.7702589807852965\n",
      "Starting epoch 81\n",
      "validation\n",
      " tn:528, fp:192, fn:24, tp:54 \n",
      "\n",
      "precision: 0.21951219512195122\n",
      "recall: 0.6923076923076923\n",
      "accuracy: 0.7293233082706767\n",
      "test\n",
      " tn:825, fp:247, fn:38, tp:87 \n",
      "\n",
      "precision: 0.26047904191616766\n",
      "recall: 0.696\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 82\n",
      "validation\n",
      " tn:525, fp:178, fn:27, tp:68 \n",
      "\n",
      "precision: 0.2764227642276423\n",
      "recall: 0.7157894736842105\n",
      "accuracy: 0.7431077694235589\n",
      "test\n",
      " tn:816, fp:238, fn:47, tp:96 \n",
      "\n",
      "precision: 0.2874251497005988\n",
      "recall: 0.6713286713286714\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 83\n",
      "validation\n",
      " tn:493, fp:146, fn:59, tp:100 \n",
      "\n",
      "precision: 0.4065040650406504\n",
      "recall: 0.6289308176100629\n",
      "accuracy: 0.7431077694235589\n",
      "test\n",
      " tn:768, fp:173, fn:95, tp:161 \n",
      "\n",
      "precision: 0.4820359281437126\n",
      "recall: 0.62890625\n",
      "accuracy: 0.7761069340016709\n",
      "Starting epoch 84\n",
      "validation\n",
      " tn:489, fp:131, fn:63, tp:115 \n",
      "\n",
      "precision: 0.46747967479674796\n",
      "recall: 0.6460674157303371\n",
      "accuracy: 0.7568922305764411\n",
      "test\n",
      " tn:762, fp:169, fn:101, tp:165 \n",
      "\n",
      "precision: 0.4940119760479042\n",
      "recall: 0.6203007518796992\n",
      "accuracy: 0.7744360902255639\n",
      "Starting epoch 85\n",
      "validation\n",
      " tn:506, fp:157, fn:46, tp:89 \n",
      "\n",
      "precision: 0.3617886178861789\n",
      "recall: 0.6592592592592592\n",
      "accuracy: 0.7456140350877193\n",
      "test\n",
      " tn:785, fp:203, fn:78, tp:131 \n",
      "\n",
      "precision: 0.39221556886227543\n",
      "recall: 0.6267942583732058\n",
      "accuracy: 0.7652464494569757\n",
      "Starting epoch 86\n",
      "validation\n",
      " tn:492, fp:142, fn:60, tp:104 \n",
      "\n",
      "precision: 0.42276422764227645\n",
      "recall: 0.6341463414634146\n",
      "accuracy: 0.7468671679197995\n",
      "test\n",
      " tn:765, fp:185, fn:98, tp:149 \n",
      "\n",
      "precision: 0.44610778443113774\n",
      "recall: 0.6032388663967612\n",
      "accuracy: 0.7635756056808688\n",
      "Starting epoch 87\n",
      "validation\n",
      " tn:478, fp:130, fn:74, tp:116 \n",
      "\n",
      "precision: 0.4715447154471545\n",
      "recall: 0.6105263157894737\n",
      "accuracy: 0.7443609022556391\n",
      "test\n",
      " tn:741, fp:163, fn:122, tp:171 \n",
      "\n",
      "precision: 0.5119760479041916\n",
      "recall: 0.5836177474402731\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 88\n",
      "validation\n",
      " tn:488, fp:138, fn:64, tp:108 \n",
      "\n",
      "precision: 0.43902439024390244\n",
      "recall: 0.627906976744186\n",
      "accuracy: 0.7468671679197995\n",
      "test\n",
      " tn:760, fp:172, fn:103, tp:162 \n",
      "\n",
      "precision: 0.48502994011976047\n",
      "recall: 0.6113207547169811\n",
      "accuracy: 0.7702589807852965\n",
      "Starting epoch 89\n",
      "validation\n",
      " tn:475, fp:121, fn:77, tp:125 \n",
      "\n",
      "precision: 0.508130081300813\n",
      "recall: 0.6188118811881188\n",
      "accuracy: 0.7518796992481203\n",
      "test\n",
      " tn:734, fp:152, fn:129, tp:182 \n",
      "\n",
      "precision: 0.5449101796407185\n",
      "recall: 0.5852090032154341\n",
      "accuracy: 0.7652464494569757\n",
      "Starting epoch 90\n",
      "validation\n",
      " tn:517, fp:174, fn:35, tp:72 \n",
      "\n",
      "precision: 0.2926829268292683\n",
      "recall: 0.6728971962616822\n",
      "accuracy: 0.7380952380952381\n",
      "test\n",
      " tn:804, fp:226, fn:59, tp:108 \n",
      "\n",
      "precision: 0.32335329341317365\n",
      "recall: 0.6467065868263473\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 91\n",
      "validation\n",
      " tn:482, fp:140, fn:70, tp:106 \n",
      "\n",
      "precision: 0.43089430894308944\n",
      "recall: 0.6022727272727273\n",
      "accuracy: 0.7368421052631579\n",
      "test\n",
      " tn:750, fp:169, fn:113, tp:165 \n",
      "\n",
      "precision: 0.4940119760479042\n",
      "recall: 0.5935251798561151\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 92\n",
      "validation\n",
      " tn:531, fp:195, fn:21, tp:51 \n",
      "\n",
      "precision: 0.2073170731707317\n",
      "recall: 0.7083333333333334\n",
      "accuracy: 0.7293233082706767\n",
      "test\n",
      " tn:827, fp:247, fn:36, tp:87 \n",
      "\n",
      "precision: 0.26047904191616766\n",
      "recall: 0.7073170731707317\n",
      "accuracy: 0.7635756056808688\n",
      "Starting epoch 93\n",
      "validation\n",
      " tn:490, fp:144, fn:62, tp:102 \n",
      "\n",
      "precision: 0.4146341463414634\n",
      "recall: 0.6219512195121951\n",
      "accuracy: 0.7418546365914787\n",
      "test\n",
      " tn:762, fp:175, fn:101, tp:159 \n",
      "\n",
      "precision: 0.47604790419161674\n",
      "recall: 0.6115384615384616\n",
      "accuracy: 0.7694235588972431\n",
      "Starting epoch 94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      " tn:442, fp:103, fn:110, tp:143 \n",
      "\n",
      "precision: 0.5813008130081301\n",
      "recall: 0.5652173913043478\n",
      "accuracy: 0.7330827067669173\n",
      "test\n",
      " tn:692, fp:126, fn:171, tp:208 \n",
      "\n",
      "precision: 0.6227544910179641\n",
      "recall: 0.5488126649076517\n",
      "accuracy: 0.7518796992481203\n",
      "Starting epoch 95\n",
      "validation\n",
      " tn:505, fp:155, fn:47, tp:91 \n",
      "\n",
      "precision: 0.3699186991869919\n",
      "recall: 0.6594202898550725\n",
      "accuracy: 0.7468671679197995\n",
      "test\n",
      " tn:785, fp:200, fn:78, tp:134 \n",
      "\n",
      "precision: 0.40119760479041916\n",
      "recall: 0.6320754716981132\n",
      "accuracy: 0.7677527151211362\n",
      "Starting epoch 96\n",
      "validation\n",
      " tn:491, fp:150, fn:61, tp:96 \n",
      "\n",
      "precision: 0.3902439024390244\n",
      "recall: 0.6114649681528662\n",
      "accuracy: 0.7355889724310777\n",
      "test\n",
      " tn:767, fp:183, fn:96, tp:151 \n",
      "\n",
      "precision: 0.45209580838323354\n",
      "recall: 0.611336032388664\n",
      "accuracy: 0.7669172932330827\n",
      "Starting epoch 97\n",
      "validation\n",
      " tn:477, fp:130, fn:75, tp:116 \n",
      "\n",
      "precision: 0.4715447154471545\n",
      "recall: 0.6073298429319371\n",
      "accuracy: 0.7431077694235589\n",
      "test\n",
      " tn:734, fp:159, fn:129, tp:175 \n",
      "\n",
      "precision: 0.5239520958083832\n",
      "recall: 0.5756578947368421\n",
      "accuracy: 0.7593984962406015\n",
      "Starting epoch 98\n",
      "validation\n",
      " tn:513, fp:167, fn:39, tp:79 \n",
      "\n",
      "precision: 0.32113821138211385\n",
      "recall: 0.6694915254237288\n",
      "accuracy: 0.7418546365914787\n",
      "test\n",
      " tn:796, fp:215, fn:67, tp:119 \n",
      "\n",
      "precision: 0.3562874251497006\n",
      "recall: 0.6397849462365591\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 99\n",
      "validation\n",
      " tn:369, fp:60, fn:183, tp:186 \n",
      "\n",
      "precision: 0.7560975609756098\n",
      "recall: 0.5040650406504065\n",
      "accuracy: 0.6954887218045113\n",
      "test\n",
      " tn:569, fp:81, fn:294, tp:253 \n",
      "\n",
      "precision: 0.7574850299401198\n",
      "recall: 0.4625228519195612\n",
      "accuracy: 0.6867167919799498\n",
      "Starting epoch 100\n",
      "validation\n",
      " tn:513, fp:163, fn:39, tp:83 \n",
      "\n",
      "precision: 0.33739837398373984\n",
      "recall: 0.680327868852459\n",
      "accuracy: 0.7468671679197995\n",
      "test\n",
      " tn:796, fp:206, fn:67, tp:128 \n",
      "\n",
      "precision: 0.38323353293413176\n",
      "recall: 0.6564102564102564\n",
      "accuracy: 0.7719298245614035\n",
      "Starting epoch 101\n",
      "validation\n",
      " tn:520, fp:175, fn:32, tp:71 \n",
      "\n",
      "precision: 0.2886178861788618\n",
      "recall: 0.6893203883495146\n",
      "accuracy: 0.7406015037593985\n",
      "test\n",
      " tn:802, fp:233, fn:61, tp:101 \n",
      "\n",
      "precision: 0.3023952095808383\n",
      "recall: 0.6234567901234568\n",
      "accuracy: 0.7543859649122807\n",
      "Starting epoch 102\n",
      "validation\n",
      " tn:462, fp:119, fn:90, tp:127 \n",
      "\n",
      "precision: 0.516260162601626\n",
      "recall: 0.5852534562211982\n",
      "accuracy: 0.7380952380952381\n",
      "test\n",
      " tn:723, fp:146, fn:140, tp:188 \n",
      "\n",
      "precision: 0.562874251497006\n",
      "recall: 0.573170731707317\n",
      "accuracy: 0.7610693400167085\n",
      "Starting epoch 103\n",
      "validation\n",
      " tn:494, fp:147, fn:58, tp:99 \n",
      "\n",
      "precision: 0.4024390243902439\n",
      "recall: 0.6305732484076433\n",
      "accuracy: 0.7431077694235589\n",
      "test\n",
      " tn:772, fp:191, fn:91, tp:143 \n",
      "\n",
      "precision: 0.4281437125748503\n",
      "recall: 0.6111111111111112\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 104\n",
      "validation\n",
      " tn:517, fp:171, fn:35, tp:75 \n",
      "\n",
      "precision: 0.3048780487804878\n",
      "recall: 0.6818181818181818\n",
      "accuracy: 0.7418546365914787\n",
      "test\n",
      " tn:803, fp:217, fn:60, tp:117 \n",
      "\n",
      "precision: 0.3502994011976048\n",
      "recall: 0.6610169491525424\n",
      "accuracy: 0.7685881370091896\n",
      "Starting epoch 105\n",
      "validation\n",
      " tn:497, fp:150, fn:55, tp:96 \n",
      "\n",
      "precision: 0.3902439024390244\n",
      "recall: 0.6357615894039735\n",
      "accuracy: 0.7431077694235589\n",
      "test\n",
      " tn:773, fp:184, fn:90, tp:150 \n",
      "\n",
      "precision: 0.4491017964071856\n",
      "recall: 0.625\n",
      "accuracy: 0.77109440267335\n",
      "Starting epoch 106\n",
      "validation\n",
      " tn:520, fp:175, fn:32, tp:71 \n",
      "\n",
      "precision: 0.2886178861788618\n",
      "recall: 0.6893203883495146\n",
      "accuracy: 0.7406015037593985\n",
      "test\n",
      " tn:806, fp:227, fn:57, tp:107 \n",
      "\n",
      "precision: 0.3203592814371258\n",
      "recall: 0.6524390243902439\n",
      "accuracy: 0.7627401837928154\n",
      "Starting epoch 107\n",
      "validation\n",
      " tn:524, fp:180, fn:28, tp:66 \n",
      "\n",
      "precision: 0.2682926829268293\n",
      "recall: 0.7021276595744681\n",
      "accuracy: 0.7393483709273183\n",
      "test\n",
      " tn:820, fp:240, fn:43, tp:94 \n",
      "\n",
      "precision: 0.281437125748503\n",
      "recall: 0.6861313868613139\n",
      "accuracy: 0.7635756056808688\n",
      "Starting epoch 108\n",
      "validation\n",
      " tn:480, fp:137, fn:72, tp:109 \n",
      "\n",
      "precision: 0.44308943089430897\n",
      "recall: 0.6022099447513812\n",
      "accuracy: 0.7380952380952381\n",
      "test\n",
      " tn:746, fp:172, fn:117, tp:162 \n",
      "\n",
      "precision: 0.48502994011976047\n",
      "recall: 0.5806451612903226\n",
      "accuracy: 0.758563074352548\n",
      "Starting epoch 109\n",
      "validation\n",
      " tn:507, fp:164, fn:45, tp:82 \n",
      "\n",
      "precision: 0.3333333333333333\n",
      "recall: 0.6456692913385826\n",
      "accuracy: 0.7380952380952381\n",
      "test\n",
      " tn:792, fp:205, fn:71, tp:129 \n",
      "\n",
      "precision: 0.38622754491017963\n",
      "recall: 0.645\n",
      "accuracy: 0.7694235588972431\n",
      "Starting epoch 110\n",
      "validation\n",
      " tn:465, fp:133, fn:87, tp:113 \n",
      "\n",
      "precision: 0.45934959349593496\n",
      "recall: 0.565\n",
      "accuracy: 0.7243107769423559\n",
      "test\n",
      " tn:730, fp:154, fn:133, tp:180 \n",
      "\n",
      "precision: 0.5389221556886228\n",
      "recall: 0.5750798722044729\n",
      "accuracy: 0.7602339181286549\n",
      "Starting epoch 111\n",
      "validation\n",
      " tn:449, fp:117, fn:103, tp:129 \n",
      "\n",
      "precision: 0.524390243902439\n",
      "recall: 0.5560344827586207\n",
      "accuracy: 0.7243107769423559\n",
      "test\n",
      " tn:702, fp:147, fn:161, tp:187 \n",
      "\n",
      "precision: 0.5598802395209581\n",
      "recall: 0.5373563218390804\n",
      "accuracy: 0.7426900584795322\n",
      "Starting epoch 112\n",
      "validation\n",
      " tn:526, fp:182, fn:26, tp:64 \n",
      "\n",
      "precision: 0.2601626016260163\n",
      "recall: 0.7111111111111111\n",
      "accuracy: 0.7393483709273183\n",
      "test\n",
      " tn:820, fp:242, fn:43, tp:92 \n",
      "\n",
      "precision: 0.2754491017964072\n",
      "recall: 0.6814814814814815\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 113\n",
      "validation\n",
      " tn:435, fp:102, fn:117, tp:144 \n",
      "\n",
      "precision: 0.5853658536585366\n",
      "recall: 0.5517241379310345\n",
      "accuracy: 0.7255639097744361\n",
      "test\n",
      " tn:695, fp:128, fn:168, tp:206 \n",
      "\n",
      "precision: 0.6167664670658682\n",
      "recall: 0.5508021390374331\n",
      "accuracy: 0.7527151211361738\n",
      "Starting epoch 114\n",
      "validation\n",
      " tn:432, fp:100, fn:120, tp:146 \n",
      "\n",
      "precision: 0.5934959349593496\n",
      "recall: 0.5488721804511278\n",
      "accuracy: 0.7243107769423559\n",
      "test\n",
      " tn:688, fp:120, fn:175, tp:214 \n",
      "\n",
      "precision: 0.6407185628742516\n",
      "recall: 0.5501285347043702\n",
      "accuracy: 0.7535505430242272\n",
      "Starting epoch 115\n",
      "validation\n",
      " tn:500, fp:161, fn:52, tp:85 \n",
      "\n",
      "precision: 0.34552845528455284\n",
      "recall: 0.6204379562043796\n",
      "accuracy: 0.7330827067669173\n",
      "test\n",
      " tn:776, fp:197, fn:87, tp:137 \n",
      "\n",
      "precision: 0.4101796407185629\n",
      "recall: 0.6116071428571429\n",
      "accuracy: 0.7627401837928154\n",
      "Starting epoch 116\n",
      "validation\n",
      " tn:495, fp:155, fn:57, tp:91 \n",
      "\n",
      "precision: 0.3699186991869919\n",
      "recall: 0.6148648648648649\n",
      "accuracy: 0.7343358395989975\n",
      "test\n",
      " tn:773, fp:191, fn:90, tp:143 \n",
      "\n",
      "precision: 0.4281437125748503\n",
      "recall: 0.6137339055793991\n",
      "accuracy: 0.7652464494569757\n",
      "Starting epoch 117\n",
      "validation\n",
      " tn:459, fp:115, fn:93, tp:131 \n",
      "\n",
      "precision: 0.532520325203252\n",
      "recall: 0.5848214285714286\n",
      "accuracy: 0.7393483709273183\n",
      "test\n",
      " tn:717, fp:143, fn:146, tp:191 \n",
      "\n",
      "precision: 0.5718562874251497\n",
      "recall: 0.5667655786350149\n",
      "accuracy: 0.758563074352548\n",
      "Starting epoch 118\n",
      "validation\n",
      " tn:541, fp:209, fn:11, tp:37 \n",
      "\n",
      "precision: 0.15040650406504066\n",
      "recall: 0.7708333333333334\n",
      "accuracy: 0.7243107769423559\n",
      "test\n",
      " tn:847, fp:286, fn:16, tp:48 \n",
      "\n",
      "precision: 0.1437125748502994\n",
      "recall: 0.75\n",
      "accuracy: 0.747702589807853\n",
      "Starting epoch 119\n",
      "validation\n",
      " tn:514, fp:170, fn:38, tp:76 \n",
      "\n",
      "precision: 0.3089430894308943\n",
      "recall: 0.6666666666666666\n",
      "accuracy: 0.7393483709273183\n",
      "test\n",
      " tn:802, fp:216, fn:61, tp:118 \n",
      "\n",
      "precision: 0.3532934131736527\n",
      "recall: 0.659217877094972\n",
      "accuracy: 0.7685881370091896\n",
      "Starting epoch 120\n",
      "validation\n",
      " tn:474, fp:135, fn:78, tp:111 \n",
      "\n",
      "precision: 0.45121951219512196\n",
      "recall: 0.5873015873015873\n",
      "accuracy: 0.7330827067669173\n",
      "test\n",
      " tn:746, fp:174, fn:117, tp:160 \n",
      "\n",
      "precision: 0.47904191616766467\n",
      "recall: 0.5776173285198556\n",
      "accuracy: 0.7568922305764411\n",
      "Starting epoch 121\n",
      "validation\n",
      " tn:532, fp:193, fn:20, tp:53 \n",
      "\n",
      "precision: 0.21544715447154472\n",
      "recall: 0.726027397260274\n",
      "accuracy: 0.7330827067669173\n",
      "test\n",
      " tn:827, fp:256, fn:36, tp:78 \n",
      "\n",
      "precision: 0.23353293413173654\n",
      "recall: 0.6842105263157895\n",
      "accuracy: 0.7560568086883876\n",
      "Starting epoch 122\n",
      "validation\n",
      " tn:472, fp:135, fn:80, tp:111 \n",
      "\n",
      "precision: 0.45121951219512196\n",
      "recall: 0.581151832460733\n",
      "accuracy: 0.7305764411027569\n",
      "test\n",
      " tn:741, fp:168, fn:122, tp:166 \n",
      "\n",
      "precision: 0.49700598802395207\n",
      "recall: 0.5763888888888888\n",
      "accuracy: 0.7577276524644946\n",
      "Starting epoch 123\n",
      "validation\n",
      " tn:506, fp:173, fn:46, tp:73 \n",
      "\n",
      "precision: 0.2967479674796748\n",
      "recall: 0.6134453781512605\n",
      "accuracy: 0.7255639097744361\n",
      "test\n",
      " tn:798, fp:217, fn:65, tp:117 \n",
      "\n",
      "precision: 0.3502994011976048\n",
      "recall: 0.6428571428571429\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 124\n",
      "validation\n",
      " tn:432, fp:102, fn:120, tp:144 \n",
      "\n",
      "precision: 0.5853658536585366\n",
      "recall: 0.5454545454545454\n",
      "accuracy: 0.7218045112781954\n",
      "test\n",
      " tn:692, fp:126, fn:171, tp:208 \n",
      "\n",
      "precision: 0.6227544910179641\n",
      "recall: 0.5488126649076517\n",
      "accuracy: 0.7518796992481203\n",
      "Starting epoch 125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      " tn:492, fp:156, fn:60, tp:90 \n",
      "\n",
      "precision: 0.36585365853658536\n",
      "recall: 0.6\n",
      "accuracy: 0.7293233082706767\n",
      "test\n",
      " tn:770, fp:190, fn:93, tp:144 \n",
      "\n",
      "precision: 0.4311377245508982\n",
      "recall: 0.6075949367088608\n",
      "accuracy: 0.7635756056808688\n",
      "Starting epoch 126\n",
      "validation\n",
      " tn:452, fp:117, fn:100, tp:129 \n",
      "\n",
      "precision: 0.524390243902439\n",
      "recall: 0.5633187772925764\n",
      "accuracy: 0.7280701754385965\n",
      "test\n",
      " tn:717, fp:148, fn:146, tp:186 \n",
      "\n",
      "precision: 0.5568862275449101\n",
      "recall: 0.5602409638554217\n",
      "accuracy: 0.7543859649122807\n",
      "Starting epoch 127\n",
      "validation\n",
      " tn:482, fp:147, fn:70, tp:99 \n",
      "\n",
      "precision: 0.4024390243902439\n",
      "recall: 0.5857988165680473\n",
      "accuracy: 0.7280701754385965\n",
      "test\n",
      " tn:747, fp:176, fn:116, tp:158 \n",
      "\n",
      "precision: 0.47305389221556887\n",
      "recall: 0.5766423357664233\n",
      "accuracy: 0.7560568086883876\n",
      "Starting epoch 128\n",
      "validation\n",
      " tn:506, fp:166, fn:46, tp:80 \n",
      "\n",
      "precision: 0.3252032520325203\n",
      "recall: 0.6349206349206349\n",
      "accuracy: 0.7343358395989975\n",
      "test\n",
      " tn:785, fp:207, fn:78, tp:127 \n",
      "\n",
      "precision: 0.38023952095808383\n",
      "recall: 0.6195121951219512\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 129\n",
      "validation\n",
      " tn:462, fp:132, fn:90, tp:114 \n",
      "\n",
      "precision: 0.4634146341463415\n",
      "recall: 0.5588235294117647\n",
      "accuracy: 0.7218045112781954\n",
      "test\n",
      " tn:734, fp:151, fn:129, tp:183 \n",
      "\n",
      "precision: 0.5479041916167665\n",
      "recall: 0.5865384615384616\n",
      "accuracy: 0.7660818713450293\n",
      "Starting epoch 130\n",
      "validation\n",
      " tn:468, fp:129, fn:84, tp:117 \n",
      "\n",
      "precision: 0.47560975609756095\n",
      "recall: 0.582089552238806\n",
      "accuracy: 0.7330827067669173\n",
      "test\n",
      " tn:732, fp:160, fn:131, tp:174 \n",
      "\n",
      "precision: 0.5209580838323353\n",
      "recall: 0.5704918032786885\n",
      "accuracy: 0.7568922305764411\n",
      "Starting epoch 131\n",
      "validation\n",
      " tn:510, fp:170, fn:42, tp:76 \n",
      "\n",
      "precision: 0.3089430894308943\n",
      "recall: 0.6440677966101694\n",
      "accuracy: 0.7343358395989975\n",
      "test\n",
      " tn:795, fp:213, fn:68, tp:121 \n",
      "\n",
      "precision: 0.36227544910179643\n",
      "recall: 0.6402116402116402\n",
      "accuracy: 0.7652464494569757\n",
      "Starting epoch 132\n",
      "validation\n",
      " tn:510, fp:166, fn:42, tp:80 \n",
      "\n",
      "precision: 0.3252032520325203\n",
      "recall: 0.6557377049180327\n",
      "accuracy: 0.7393483709273183\n",
      "test\n",
      " tn:788, fp:218, fn:75, tp:116 \n",
      "\n",
      "precision: 0.3473053892215569\n",
      "recall: 0.6073298429319371\n",
      "accuracy: 0.7552213868003341\n",
      "Starting epoch 133\n",
      "validation\n",
      " tn:507, fp:164, fn:45, tp:82 \n",
      "\n",
      "precision: 0.3333333333333333\n",
      "recall: 0.6456692913385826\n",
      "accuracy: 0.7380952380952381\n",
      "test\n",
      " tn:799, fp:218, fn:64, tp:116 \n",
      "\n",
      "precision: 0.3473053892215569\n",
      "recall: 0.6444444444444445\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 134\n",
      "validation\n",
      " tn:500, fp:156, fn:52, tp:90 \n",
      "\n",
      "precision: 0.36585365853658536\n",
      "recall: 0.6338028169014085\n",
      "accuracy: 0.7393483709273183\n",
      "test\n",
      " tn:785, fp:200, fn:78, tp:134 \n",
      "\n",
      "precision: 0.40119760479041916\n",
      "recall: 0.6320754716981132\n",
      "accuracy: 0.7677527151211362\n",
      "Starting epoch 135\n",
      "validation\n",
      " tn:484, fp:143, fn:68, tp:103 \n",
      "\n",
      "precision: 0.4186991869918699\n",
      "recall: 0.6023391812865497\n",
      "accuracy: 0.7355889724310777\n",
      "test\n",
      " tn:761, fp:183, fn:102, tp:151 \n",
      "\n",
      "precision: 0.45209580838323354\n",
      "recall: 0.5968379446640316\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 136\n",
      "validation\n",
      " tn:460, fp:124, fn:92, tp:122 \n",
      "\n",
      "precision: 0.4959349593495935\n",
      "recall: 0.5700934579439252\n",
      "accuracy: 0.7293233082706767\n",
      "test\n",
      " tn:725, fp:156, fn:138, tp:178 \n",
      "\n",
      "precision: 0.5329341317365269\n",
      "recall: 0.5632911392405063\n",
      "accuracy: 0.7543859649122807\n",
      "Starting epoch 137\n",
      "validation\n",
      " tn:436, fp:105, fn:116, tp:141 \n",
      "\n",
      "precision: 0.573170731707317\n",
      "recall: 0.5486381322957199\n",
      "accuracy: 0.7230576441102757\n",
      "test\n",
      " tn:691, fp:133, fn:172, tp:201 \n",
      "\n",
      "precision: 0.6017964071856288\n",
      "recall: 0.5388739946380697\n",
      "accuracy: 0.7451963241436925\n",
      "Starting epoch 138\n",
      "validation\n",
      " tn:501, fp:169, fn:51, tp:77 \n",
      "\n",
      "precision: 0.3130081300813008\n",
      "recall: 0.6015625\n",
      "accuracy: 0.7243107769423559\n",
      "test\n",
      " tn:790, fp:211, fn:73, tp:123 \n",
      "\n",
      "precision: 0.36826347305389223\n",
      "recall: 0.6275510204081632\n",
      "accuracy: 0.7627401837928154\n",
      "Starting epoch 139\n",
      "validation\n",
      " tn:509, fp:167, fn:43, tp:79 \n",
      "\n",
      "precision: 0.32113821138211385\n",
      "recall: 0.6475409836065574\n",
      "accuracy: 0.7368421052631579\n",
      "test\n",
      " tn:796, fp:219, fn:67, tp:115 \n",
      "\n",
      "precision: 0.344311377245509\n",
      "recall: 0.6318681318681318\n",
      "accuracy: 0.7610693400167085\n",
      "Starting epoch 140\n",
      "validation\n",
      " tn:511, fp:179, fn:41, tp:67 \n",
      "\n",
      "precision: 0.27235772357723576\n",
      "recall: 0.6203703703703703\n",
      "accuracy: 0.7243107769423559\n",
      "test\n",
      " tn:810, fp:217, fn:53, tp:117 \n",
      "\n",
      "precision: 0.3502994011976048\n",
      "recall: 0.6882352941176471\n",
      "accuracy: 0.7744360902255639\n",
      "Starting epoch 141\n",
      "validation\n",
      " tn:485, fp:151, fn:67, tp:95 \n",
      "\n",
      "precision: 0.3861788617886179\n",
      "recall: 0.5864197530864198\n",
      "accuracy: 0.7268170426065163\n",
      "test\n",
      " tn:768, fp:186, fn:95, tp:148 \n",
      "\n",
      "precision: 0.4431137724550898\n",
      "recall: 0.6090534979423868\n",
      "accuracy: 0.7652464494569757\n",
      "Starting epoch 142\n",
      "validation\n",
      " tn:435, fp:108, fn:117, tp:138 \n",
      "\n",
      "precision: 0.5609756097560976\n",
      "recall: 0.5411764705882353\n",
      "accuracy: 0.7180451127819549\n",
      "test\n",
      " tn:697, fp:139, fn:166, tp:195 \n",
      "\n",
      "precision: 0.5838323353293413\n",
      "recall: 0.5401662049861495\n",
      "accuracy: 0.7451963241436925\n",
      "Starting epoch 143\n",
      "validation\n",
      " tn:481, fp:143, fn:71, tp:103 \n",
      "\n",
      "precision: 0.4186991869918699\n",
      "recall: 0.5919540229885057\n",
      "accuracy: 0.731829573934837\n",
      "test\n",
      " tn:750, fp:170, fn:113, tp:164 \n",
      "\n",
      "precision: 0.49101796407185627\n",
      "recall: 0.592057761732852\n",
      "accuracy: 0.7635756056808688\n",
      "Starting epoch 144\n",
      "validation\n",
      " tn:500, fp:162, fn:52, tp:84 \n",
      "\n",
      "precision: 0.34146341463414637\n",
      "recall: 0.6176470588235294\n",
      "accuracy: 0.731829573934837\n",
      "test\n",
      " tn:786, fp:205, fn:77, tp:129 \n",
      "\n",
      "precision: 0.38622754491017963\n",
      "recall: 0.6262135922330098\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 145\n",
      "validation\n",
      " tn:517, fp:181, fn:35, tp:65 \n",
      "\n",
      "precision: 0.26422764227642276\n",
      "recall: 0.65\n",
      "accuracy: 0.7293233082706767\n",
      "test\n",
      " tn:818, fp:238, fn:45, tp:96 \n",
      "\n",
      "precision: 0.2874251497005988\n",
      "recall: 0.6808510638297872\n",
      "accuracy: 0.7635756056808688\n",
      "Starting epoch 146\n",
      "validation\n",
      " tn:512, fp:173, fn:40, tp:73 \n",
      "\n",
      "precision: 0.2967479674796748\n",
      "recall: 0.6460176991150443\n",
      "accuracy: 0.7330827067669173\n",
      "test\n",
      " tn:803, fp:222, fn:60, tp:112 \n",
      "\n",
      "precision: 0.33532934131736525\n",
      "recall: 0.6511627906976745\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 147\n",
      "validation\n",
      " tn:472, fp:130, fn:80, tp:116 \n",
      "\n",
      "precision: 0.4715447154471545\n",
      "recall: 0.5918367346938775\n",
      "accuracy: 0.7368421052631579\n",
      "test\n",
      " tn:739, fp:165, fn:124, tp:169 \n",
      "\n",
      "precision: 0.5059880239520959\n",
      "recall: 0.5767918088737202\n",
      "accuracy: 0.758563074352548\n",
      "Starting epoch 148\n",
      "validation\n",
      " tn:483, fp:152, fn:69, tp:94 \n",
      "\n",
      "precision: 0.3821138211382114\n",
      "recall: 0.5766871165644172\n",
      "accuracy: 0.7230576441102757\n",
      "test\n",
      " tn:762, fp:182, fn:101, tp:152 \n",
      "\n",
      "precision: 0.4550898203592814\n",
      "recall: 0.6007905138339921\n",
      "accuracy: 0.7635756056808688\n",
      "Starting epoch 149\n",
      "validation\n",
      " tn:479, fp:139, fn:73, tp:107 \n",
      "\n",
      "precision: 0.4349593495934959\n",
      "recall: 0.5944444444444444\n",
      "accuracy: 0.7343358395989975\n",
      "test\n",
      " tn:749, fp:174, fn:114, tp:160 \n",
      "\n",
      "precision: 0.47904191616766467\n",
      "recall: 0.583941605839416\n",
      "accuracy: 0.7593984962406015\n",
      "Starting epoch 150\n",
      "validation\n",
      " tn:503, fp:168, fn:49, tp:78 \n",
      "\n",
      "precision: 0.3170731707317073\n",
      "recall: 0.6141732283464567\n",
      "accuracy: 0.7280701754385965\n",
      "test\n",
      " tn:790, fp:210, fn:73, tp:124 \n",
      "\n",
      "precision: 0.3712574850299401\n",
      "recall: 0.6294416243654822\n",
      "accuracy: 0.7635756056808688\n",
      "Starting epoch 151\n",
      "validation\n",
      " tn:498, fp:162, fn:54, tp:84 \n",
      "\n",
      "precision: 0.34146341463414637\n",
      "recall: 0.6086956521739131\n",
      "accuracy: 0.7293233082706767\n",
      "test\n",
      " tn:783, fp:204, fn:80, tp:130 \n",
      "\n",
      "precision: 0.38922155688622756\n",
      "recall: 0.6190476190476191\n",
      "accuracy: 0.7627401837928154\n",
      "Starting epoch 152\n",
      "validation\n",
      " tn:511, fp:180, fn:41, tp:66 \n",
      "\n",
      "precision: 0.2682926829268293\n",
      "recall: 0.616822429906542\n",
      "accuracy: 0.7230576441102757\n",
      "test\n",
      " tn:810, fp:225, fn:53, tp:109 \n",
      "\n",
      "precision: 0.3263473053892216\n",
      "recall: 0.6728395061728395\n",
      "accuracy: 0.7677527151211362\n",
      "Starting epoch 153\n",
      "validation\n",
      " tn:476, fp:149, fn:76, tp:97 \n",
      "\n",
      "precision: 0.3943089430894309\n",
      "recall: 0.5606936416184971\n",
      "accuracy: 0.7180451127819549\n",
      "test\n",
      " tn:746, fp:176, fn:117, tp:158 \n",
      "\n",
      "precision: 0.47305389221556887\n",
      "recall: 0.5745454545454546\n",
      "accuracy: 0.7552213868003341\n",
      "Starting epoch 154\n",
      "validation\n",
      " tn:438, fp:111, fn:114, tp:135 \n",
      "\n",
      "precision: 0.5487804878048781\n",
      "recall: 0.5421686746987951\n",
      "accuracy: 0.7180451127819549\n",
      "test\n",
      " tn:685, fp:128, fn:178, tp:206 \n",
      "\n",
      "precision: 0.6167664670658682\n",
      "recall: 0.5364583333333334\n",
      "accuracy: 0.7443609022556391\n",
      "Starting epoch 155\n",
      "validation\n",
      " tn:504, fp:168, fn:48, tp:78 \n",
      "\n",
      "precision: 0.3170731707317073\n",
      "recall: 0.6190476190476191\n",
      "accuracy: 0.7293233082706767\n",
      "test\n",
      " tn:784, fp:210, fn:79, tp:124 \n",
      "\n",
      "precision: 0.3712574850299401\n",
      "recall: 0.6108374384236454\n",
      "accuracy: 0.758563074352548\n",
      "Starting epoch 156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      " tn:472, fp:141, fn:80, tp:105 \n",
      "\n",
      "precision: 0.4268292682926829\n",
      "recall: 0.5675675675675675\n",
      "accuracy: 0.7230576441102757\n",
      "test\n",
      " tn:744, fp:179, fn:119, tp:155 \n",
      "\n",
      "precision: 0.46407185628742514\n",
      "recall: 0.5656934306569343\n",
      "accuracy: 0.7510442773600668\n",
      "Starting epoch 157\n",
      "validation\n",
      " tn:495, fp:159, fn:57, tp:87 \n",
      "\n",
      "precision: 0.35365853658536583\n",
      "recall: 0.6041666666666666\n",
      "accuracy: 0.7293233082706767\n",
      "test\n",
      " tn:759, fp:200, fn:104, tp:134 \n",
      "\n",
      "precision: 0.40119760479041916\n",
      "recall: 0.5630252100840336\n",
      "accuracy: 0.746031746031746\n",
      "Starting epoch 158\n",
      "validation\n",
      " tn:510, fp:176, fn:42, tp:70 \n",
      "\n",
      "precision: 0.2845528455284553\n",
      "recall: 0.625\n",
      "accuracy: 0.7268170426065163\n",
      "test\n",
      " tn:809, fp:222, fn:54, tp:112 \n",
      "\n",
      "precision: 0.33532934131736525\n",
      "recall: 0.6746987951807228\n",
      "accuracy: 0.7694235588972431\n",
      "Starting epoch 159\n",
      "validation\n",
      " tn:520, fp:181, fn:32, tp:65 \n",
      "\n",
      "precision: 0.26422764227642276\n",
      "recall: 0.6701030927835051\n",
      "accuracy: 0.7330827067669173\n",
      "test\n",
      " tn:818, fp:240, fn:45, tp:94 \n",
      "\n",
      "precision: 0.281437125748503\n",
      "recall: 0.6762589928057554\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 160\n",
      "validation\n",
      " tn:512, fp:179, fn:40, tp:67 \n",
      "\n",
      "precision: 0.27235772357723576\n",
      "recall: 0.6261682242990654\n",
      "accuracy: 0.7255639097744361\n",
      "test\n",
      " tn:808, fp:228, fn:55, tp:106 \n",
      "\n",
      "precision: 0.31736526946107785\n",
      "recall: 0.6583850931677019\n",
      "accuracy: 0.7635756056808688\n",
      "Starting epoch 161\n",
      "validation\n",
      " tn:495, fp:159, fn:57, tp:87 \n",
      "\n",
      "precision: 0.35365853658536583\n",
      "recall: 0.6041666666666666\n",
      "accuracy: 0.7293233082706767\n",
      "test\n",
      " tn:768, fp:196, fn:95, tp:138 \n",
      "\n",
      "precision: 0.41317365269461076\n",
      "recall: 0.592274678111588\n",
      "accuracy: 0.7568922305764411\n",
      "Starting epoch 162\n",
      "validation\n",
      " tn:471, fp:144, fn:81, tp:102 \n",
      "\n",
      "precision: 0.4146341463414634\n",
      "recall: 0.5573770491803278\n",
      "accuracy: 0.7180451127819549\n",
      "test\n",
      " tn:744, fp:166, fn:119, tp:168 \n",
      "\n",
      "precision: 0.5029940119760479\n",
      "recall: 0.5853658536585366\n",
      "accuracy: 0.7619047619047619\n",
      "Starting epoch 163\n",
      "validation\n",
      " tn:521, fp:175, fn:31, tp:71 \n",
      "\n",
      "precision: 0.2886178861788618\n",
      "recall: 0.696078431372549\n",
      "accuracy: 0.7418546365914787\n",
      "test\n",
      " tn:812, fp:231, fn:51, tp:103 \n",
      "\n",
      "precision: 0.3083832335329341\n",
      "recall: 0.6688311688311688\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 164\n",
      "validation\n",
      " tn:478, fp:150, fn:74, tp:96 \n",
      "\n",
      "precision: 0.3902439024390244\n",
      "recall: 0.5647058823529412\n",
      "accuracy: 0.7192982456140351\n",
      "test\n",
      " tn:752, fp:180, fn:111, tp:154 \n",
      "\n",
      "precision: 0.46107784431137727\n",
      "recall: 0.5811320754716981\n",
      "accuracy: 0.7568922305764411\n",
      "Starting epoch 165\n",
      "validation\n",
      " tn:522, fp:185, fn:30, tp:61 \n",
      "\n",
      "precision: 0.24796747967479674\n",
      "recall: 0.6703296703296703\n",
      "accuracy: 0.7305764411027569\n",
      "test\n",
      " tn:821, fp:247, fn:42, tp:87 \n",
      "\n",
      "precision: 0.26047904191616766\n",
      "recall: 0.6744186046511628\n",
      "accuracy: 0.758563074352548\n",
      "Starting epoch 166\n",
      "validation\n",
      " tn:524, fp:186, fn:28, tp:60 \n",
      "\n",
      "precision: 0.24390243902439024\n",
      "recall: 0.6818181818181818\n",
      "accuracy: 0.731829573934837\n",
      "test\n",
      " tn:823, fp:249, fn:40, tp:85 \n",
      "\n",
      "precision: 0.25449101796407186\n",
      "recall: 0.68\n",
      "accuracy: 0.758563074352548\n",
      "Starting epoch 167\n",
      "validation\n",
      " tn:503, fp:165, fn:49, tp:81 \n",
      "\n",
      "precision: 0.32926829268292684\n",
      "recall: 0.6230769230769231\n",
      "accuracy: 0.731829573934837\n",
      "test\n",
      " tn:794, fp:201, fn:69, tp:133 \n",
      "\n",
      "precision: 0.39820359281437123\n",
      "recall: 0.6584158415841584\n",
      "accuracy: 0.7744360902255639\n",
      "Starting epoch 168\n",
      "validation\n",
      " tn:489, fp:160, fn:63, tp:86 \n",
      "\n",
      "precision: 0.34959349593495936\n",
      "recall: 0.5771812080536913\n",
      "accuracy: 0.7205513784461153\n",
      "test\n",
      " tn:755, fp:190, fn:108, tp:144 \n",
      "\n",
      "precision: 0.4311377245508982\n",
      "recall: 0.5714285714285714\n",
      "accuracy: 0.7510442773600668\n",
      "Starting epoch 169\n",
      "validation\n",
      " tn:469, fp:139, fn:83, tp:107 \n",
      "\n",
      "precision: 0.4349593495934959\n",
      "recall: 0.5631578947368421\n",
      "accuracy: 0.7218045112781954\n",
      "test\n",
      " tn:743, fp:174, fn:120, tp:160 \n",
      "\n",
      "precision: 0.47904191616766467\n",
      "recall: 0.5714285714285714\n",
      "accuracy: 0.7543859649122807\n",
      "Starting epoch 170\n",
      "validation\n",
      " tn:491, fp:162, fn:61, tp:84 \n",
      "\n",
      "precision: 0.34146341463414637\n",
      "recall: 0.5793103448275863\n",
      "accuracy: 0.7205513784461153\n",
      "test\n",
      " tn:777, fp:203, fn:86, tp:131 \n",
      "\n",
      "precision: 0.39221556886227543\n",
      "recall: 0.6036866359447005\n",
      "accuracy: 0.758563074352548\n",
      "Starting epoch 171\n",
      "validation\n",
      " tn:525, fp:191, fn:27, tp:55 \n",
      "\n",
      "precision: 0.22357723577235772\n",
      "recall: 0.6707317073170732\n",
      "accuracy: 0.7268170426065163\n",
      "test\n",
      " tn:826, fp:256, fn:37, tp:78 \n",
      "\n",
      "precision: 0.23353293413173654\n",
      "recall: 0.6782608695652174\n",
      "accuracy: 0.7552213868003341\n",
      "Starting epoch 172\n",
      "validation\n",
      " tn:488, fp:158, fn:64, tp:88 \n",
      "\n",
      "precision: 0.35772357723577236\n",
      "recall: 0.5789473684210527\n",
      "accuracy: 0.7218045112781954\n",
      "test\n",
      " tn:767, fp:198, fn:96, tp:136 \n",
      "\n",
      "precision: 0.40718562874251496\n",
      "recall: 0.5862068965517241\n",
      "accuracy: 0.7543859649122807\n",
      "Starting epoch 173\n",
      "validation\n",
      " tn:470, fp:144, fn:82, tp:102 \n",
      "\n",
      "precision: 0.4146341463414634\n",
      "recall: 0.5543478260869565\n",
      "accuracy: 0.7167919799498746\n",
      "test\n",
      " tn:737, fp:184, fn:126, tp:150 \n",
      "\n",
      "precision: 0.4491017964071856\n",
      "recall: 0.5434782608695652\n",
      "accuracy: 0.7410192147034252\n",
      "Starting epoch 174\n",
      "validation\n",
      " tn:459, fp:131, fn:93, tp:115 \n",
      "\n",
      "precision: 0.46747967479674796\n",
      "recall: 0.5528846153846154\n",
      "accuracy: 0.7192982456140351\n",
      "test\n",
      " tn:713, fp:151, fn:150, tp:183 \n",
      "\n",
      "precision: 0.5479041916167665\n",
      "recall: 0.5495495495495496\n",
      "accuracy: 0.7485380116959064\n",
      "Starting epoch 175\n",
      "validation\n",
      " tn:485, fp:164, fn:67, tp:82 \n",
      "\n",
      "precision: 0.3333333333333333\n",
      "recall: 0.5503355704697986\n",
      "accuracy: 0.7105263157894737\n",
      "test\n",
      " tn:768, fp:195, fn:95, tp:139 \n",
      "\n",
      "precision: 0.4161676646706587\n",
      "recall: 0.594017094017094\n",
      "accuracy: 0.7577276524644946\n",
      "Starting epoch 176\n",
      "validation\n",
      " tn:472, fp:139, fn:80, tp:107 \n",
      "\n",
      "precision: 0.4349593495934959\n",
      "recall: 0.5721925133689839\n",
      "accuracy: 0.7255639097744361\n",
      "test\n",
      " tn:741, fp:175, fn:122, tp:159 \n",
      "\n",
      "precision: 0.47604790419161674\n",
      "recall: 0.5658362989323843\n",
      "accuracy: 0.7518796992481203\n",
      "Starting epoch 177\n",
      "validation\n",
      " tn:469, fp:138, fn:83, tp:108 \n",
      "\n",
      "precision: 0.43902439024390244\n",
      "recall: 0.5654450261780105\n",
      "accuracy: 0.7230576441102757\n",
      "test\n",
      " tn:742, fp:171, fn:121, tp:163 \n",
      "\n",
      "precision: 0.4880239520958084\n",
      "recall: 0.573943661971831\n",
      "accuracy: 0.7560568086883876\n",
      "Starting epoch 178\n",
      "validation\n",
      " tn:499, fp:168, fn:53, tp:78 \n",
      "\n",
      "precision: 0.3170731707317073\n",
      "recall: 0.5954198473282443\n",
      "accuracy: 0.7230576441102757\n",
      "test\n",
      " tn:784, fp:207, fn:79, tp:127 \n",
      "\n",
      "precision: 0.38023952095808383\n",
      "recall: 0.616504854368932\n",
      "accuracy: 0.7610693400167085\n",
      "Starting epoch 179\n",
      "validation\n",
      " tn:456, fp:124, fn:96, tp:122 \n",
      "\n",
      "precision: 0.4959349593495935\n",
      "recall: 0.5596330275229358\n",
      "accuracy: 0.7243107769423559\n",
      "test\n",
      " tn:718, fp:149, fn:145, tp:185 \n",
      "\n",
      "precision: 0.5538922155688623\n",
      "recall: 0.5606060606060606\n",
      "accuracy: 0.7543859649122807\n",
      "Starting epoch 180\n",
      "validation\n",
      " tn:509, fp:176, fn:43, tp:70 \n",
      "\n",
      "precision: 0.2845528455284553\n",
      "recall: 0.6194690265486725\n",
      "accuracy: 0.7255639097744361\n",
      "test\n",
      " tn:797, fp:221, fn:66, tp:113 \n",
      "\n",
      "precision: 0.3383233532934132\n",
      "recall: 0.6312849162011173\n",
      "accuracy: 0.7602339181286549\n",
      "Starting epoch 181\n",
      "validation\n",
      " tn:413, fp:112, fn:139, tp:134 \n",
      "\n",
      "precision: 0.5447154471544715\n",
      "recall: 0.4908424908424908\n",
      "accuracy: 0.6854636591478697\n",
      "test\n",
      " tn:650, fp:131, fn:213, tp:203 \n",
      "\n",
      "precision: 0.6077844311377245\n",
      "recall: 0.4879807692307692\n",
      "accuracy: 0.7126148705096074\n",
      "Starting epoch 182\n",
      "validation\n",
      " tn:476, fp:134, fn:76, tp:112 \n",
      "\n",
      "precision: 0.45528455284552843\n",
      "recall: 0.5957446808510638\n",
      "accuracy: 0.7368421052631579\n",
      "test\n",
      " tn:746, fp:163, fn:117, tp:171 \n",
      "\n",
      "precision: 0.5119760479041916\n",
      "recall: 0.59375\n",
      "accuracy: 0.7660818713450293\n",
      "Starting epoch 183\n",
      "validation\n",
      " tn:447, fp:121, fn:105, tp:125 \n",
      "\n",
      "precision: 0.508130081300813\n",
      "recall: 0.5434782608695652\n",
      "accuracy: 0.7167919799498746\n",
      "test\n",
      " tn:700, fp:145, fn:163, tp:189 \n",
      "\n",
      "precision: 0.5658682634730539\n",
      "recall: 0.5369318181818182\n",
      "accuracy: 0.7426900584795322\n",
      "Starting epoch 184\n",
      "validation\n",
      " tn:462, fp:148, fn:90, tp:98 \n",
      "\n",
      "precision: 0.3983739837398374\n",
      "recall: 0.5212765957446809\n",
      "accuracy: 0.7017543859649122\n",
      "test\n",
      " tn:739, fp:173, fn:124, tp:161 \n",
      "\n",
      "precision: 0.4820359281437126\n",
      "recall: 0.5649122807017544\n",
      "accuracy: 0.7518796992481203\n",
      "Starting epoch 185\n",
      "validation\n",
      " tn:486, fp:164, fn:66, tp:82 \n",
      "\n",
      "precision: 0.3333333333333333\n",
      "recall: 0.5540540540540541\n",
      "accuracy: 0.7117794486215538\n",
      "test\n",
      " tn:764, fp:193, fn:99, tp:141 \n",
      "\n",
      "precision: 0.4221556886227545\n",
      "recall: 0.5875\n",
      "accuracy: 0.7560568086883876\n",
      "Starting epoch 186\n",
      "validation\n",
      " tn:494, fp:161, fn:58, tp:85 \n",
      "\n",
      "precision: 0.34552845528455284\n",
      "recall: 0.5944055944055944\n",
      "accuracy: 0.7255639097744361\n",
      "test\n",
      " tn:777, fp:192, fn:86, tp:142 \n",
      "\n",
      "precision: 0.4251497005988024\n",
      "recall: 0.6228070175438597\n",
      "accuracy: 0.7677527151211362\n",
      "Starting epoch 187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      " tn:500, fp:165, fn:52, tp:81 \n",
      "\n",
      "precision: 0.32926829268292684\n",
      "recall: 0.6090225563909775\n",
      "accuracy: 0.7280701754385965\n",
      "test\n",
      " tn:784, fp:195, fn:79, tp:139 \n",
      "\n",
      "precision: 0.4161676646706587\n",
      "recall: 0.6376146788990825\n",
      "accuracy: 0.77109440267335\n",
      "Starting epoch 188\n",
      "validation\n",
      " tn:445, fp:136, fn:107, tp:110 \n",
      "\n",
      "precision: 0.44715447154471544\n",
      "recall: 0.5069124423963134\n",
      "accuracy: 0.6954887218045113\n",
      "test\n",
      " tn:705, fp:152, fn:158, tp:182 \n",
      "\n",
      "precision: 0.5449101796407185\n",
      "recall: 0.5352941176470588\n",
      "accuracy: 0.7410192147034252\n",
      "Starting epoch 189\n",
      "validation\n",
      " tn:464, fp:145, fn:88, tp:101 \n",
      "\n",
      "precision: 0.4105691056910569\n",
      "recall: 0.5343915343915344\n",
      "accuracy: 0.7080200501253133\n",
      "test\n",
      " tn:733, fp:171, fn:130, tp:163 \n",
      "\n",
      "precision: 0.4880239520958084\n",
      "recall: 0.5563139931740614\n",
      "accuracy: 0.7485380116959064\n",
      "Starting epoch 190\n",
      "validation\n",
      " tn:504, fp:175, fn:48, tp:71 \n",
      "\n",
      "precision: 0.2886178861788618\n",
      "recall: 0.5966386554621849\n",
      "accuracy: 0.7205513784461153\n",
      "test\n",
      " tn:790, fp:209, fn:73, tp:125 \n",
      "\n",
      "precision: 0.37425149700598803\n",
      "recall: 0.6313131313131313\n",
      "accuracy: 0.7644110275689223\n",
      "Starting epoch 191\n",
      "validation\n",
      " tn:464, fp:151, fn:88, tp:95 \n",
      "\n",
      "precision: 0.3861788617886179\n",
      "recall: 0.5191256830601093\n",
      "accuracy: 0.7005012531328321\n",
      "test\n",
      " tn:729, fp:167, fn:134, tp:167 \n",
      "\n",
      "precision: 0.5\n",
      "recall: 0.5548172757475083\n",
      "accuracy: 0.7485380116959064\n",
      "Starting epoch 192\n",
      "validation\n",
      " tn:465, fp:144, fn:87, tp:102 \n",
      "\n",
      "precision: 0.4146341463414634\n",
      "recall: 0.5396825396825397\n",
      "accuracy: 0.7105263157894737\n",
      "test\n",
      " tn:734, fp:171, fn:129, tp:163 \n",
      "\n",
      "precision: 0.4880239520958084\n",
      "recall: 0.5582191780821918\n",
      "accuracy: 0.7493734335839599\n",
      "Starting epoch 193\n",
      "validation\n",
      " tn:458, fp:136, fn:94, tp:110 \n",
      "\n",
      "precision: 0.44715447154471544\n",
      "recall: 0.5392156862745098\n",
      "accuracy: 0.7117794486215538\n",
      "test\n",
      " tn:721, fp:160, fn:142, tp:174 \n",
      "\n",
      "precision: 0.5209580838323353\n",
      "recall: 0.5506329113924051\n",
      "accuracy: 0.747702589807853\n",
      "Starting epoch 194\n",
      "validation\n",
      " tn:496, fp:166, fn:56, tp:80 \n",
      "\n",
      "precision: 0.3252032520325203\n",
      "recall: 0.5882352941176471\n",
      "accuracy: 0.7218045112781954\n",
      "test\n",
      " tn:780, fp:207, fn:83, tp:127 \n",
      "\n",
      "precision: 0.38023952095808383\n",
      "recall: 0.6047619047619047\n",
      "accuracy: 0.7577276524644946\n",
      "Starting epoch 195\n",
      "validation\n",
      " tn:470, fp:147, fn:82, tp:99 \n",
      "\n",
      "precision: 0.4024390243902439\n",
      "recall: 0.5469613259668509\n",
      "accuracy: 0.7130325814536341\n",
      "test\n",
      " tn:738, fp:167, fn:125, tp:167 \n",
      "\n",
      "precision: 0.5\n",
      "recall: 0.571917808219178\n",
      "accuracy: 0.7560568086883876\n",
      "Starting epoch 196\n",
      "validation\n",
      " tn:500, fp:165, fn:52, tp:81 \n",
      "\n",
      "precision: 0.32926829268292684\n",
      "recall: 0.6090225563909775\n",
      "accuracy: 0.7280701754385965\n",
      "test\n",
      " tn:784, fp:209, fn:79, tp:125 \n",
      "\n",
      "precision: 0.37425149700598803\n",
      "recall: 0.6127450980392157\n",
      "accuracy: 0.7593984962406015\n",
      "Starting epoch 197\n",
      "validation\n",
      " tn:434, fp:111, fn:118, tp:135 \n",
      "\n",
      "precision: 0.5487804878048781\n",
      "recall: 0.5335968379446641\n",
      "accuracy: 0.7130325814536341\n",
      "test\n",
      " tn:688, fp:139, fn:175, tp:195 \n",
      "\n",
      "precision: 0.5838323353293413\n",
      "recall: 0.527027027027027\n",
      "accuracy: 0.7376775271512114\n",
      "Starting epoch 198\n",
      "validation\n",
      " tn:517, fp:186, fn:35, tp:60 \n",
      "\n",
      "precision: 0.24390243902439024\n",
      "recall: 0.631578947368421\n",
      "accuracy: 0.7230576441102757\n",
      "test\n",
      " tn:812, fp:230, fn:51, tp:104 \n",
      "\n",
      "precision: 0.31137724550898205\n",
      "recall: 0.6709677419354839\n",
      "accuracy: 0.7652464494569757\n",
      "Starting epoch 199\n",
      "validation\n",
      " tn:495, fp:171, fn:57, tp:75 \n",
      "\n",
      "precision: 0.3048780487804878\n",
      "recall: 0.5681818181818182\n",
      "accuracy: 0.7142857142857143\n",
      "test\n",
      " tn:776, fp:211, fn:87, tp:123 \n",
      "\n",
      "precision: 0.36826347305389223\n",
      "recall: 0.5857142857142857\n",
      "accuracy: 0.7510442773600668\n",
      "Starting epoch 200\n",
      "validation\n",
      " tn:463, fp:137, fn:89, tp:109 \n",
      "\n",
      "precision: 0.44308943089430897\n",
      "recall: 0.5505050505050505\n",
      "accuracy: 0.7167919799498746\n",
      "test\n",
      " tn:729, fp:165, fn:134, tp:169 \n",
      "\n",
      "precision: 0.5059880239520959\n",
      "recall: 0.5577557755775577\n",
      "accuracy: 0.7502088554720133\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the MLP\n",
    "mlp2 = MLP(X_train.shape[1], 256)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(mlp2.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "\n",
    "# Run the training loop\n",
    "\n",
    "niter = 200\n",
    "\n",
    "for epoch in range(0, niter): # 5 epochs at maximum\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    mlp2.train()\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        \n",
    "        inputs = inputs.float()\n",
    "        target = targets.float()\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Perform forward pass\n",
    "        outputs = mlp2(inputs)\n",
    "        # Loss and optim\n",
    "        loss = loss_function(outputs.view(targets.shape).float(), targets.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mlp2.eval()\n",
    "    validation(mlp2, torch.tensor(X_val.values).float(), Y_val, \"validation\")\n",
    "    validation(mlp2, torch.tensor(X_test.values).float(), Y_test, \"test\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6da3577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "\n",
      "---------------\n",
      "\n",
      " in train \n",
      "\n",
      "---------------\n",
      " tn:2860, fp:216, fn:168, tp:806 \n",
      "\n",
      "precision: 0.7886497064579256\n",
      "recall: 0.8275154004106776\n",
      "accuracy: 0.9051851851851852\n",
      "\n",
      " \n",
      "\n",
      "---------------\n",
      "\n",
      " in test \n",
      "\n",
      "---------------\n",
      " tn:729, fp:165, fn:134, tp:169 \n",
      "\n",
      "precision: 0.5059880239520959\n",
      "recall: 0.5577557755775577\n",
      "accuracy: 0.7502088554720133\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n \\n\")\n",
    "print(\"---------------\")\n",
    "print(\"\\n in train \\n\")\n",
    "print(\"---------------\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    p = mlp2(torch.tensor(X_train.values).float())\n",
    "modeleval((p>0.5).data.float(), Y_train)\n",
    "\n",
    "print(\"\\n \\n\")\n",
    "print(\"---------------\")\n",
    "print(\"\\n in test \\n\")\n",
    "print(\"---------------\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    p = mlp2(torch.tensor(X_test.values).float())\n",
    "modeleval((p>0.5).data.float(), Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
